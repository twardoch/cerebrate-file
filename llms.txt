Project Structure:
ğŸ“ cerebrate-file
â”œâ”€â”€ ğŸ“ .github
â”‚   â””â”€â”€ ğŸ“ workflows
â”‚       â”œâ”€â”€ ğŸ“„ push.yml
â”‚       â””â”€â”€ ğŸ“„ release.yml
â”œâ”€â”€ ğŸ“ docs
â”‚   â”œâ”€â”€ ğŸ“„ _config.yml
â”‚   â”œâ”€â”€ ğŸ“„ api-reference.md
â”‚   â”œâ”€â”€ ğŸ“„ cli-reference.md
â”‚   â”œâ”€â”€ ğŸ“„ configuration.md
â”‚   â”œâ”€â”€ ğŸ“„ development.md
â”‚   â”œâ”€â”€ ğŸ“„ examples.md
â”‚   â”œâ”€â”€ ğŸ“„ Gemfile
â”‚   â”œâ”€â”€ ğŸ“„ index.md
â”‚   â”œâ”€â”€ ğŸ“„ installation.md
â”‚   â”œâ”€â”€ ğŸ“„ quick-start.md
â”‚   â”œâ”€â”€ ğŸ“„ README.md
â”‚   â”œâ”€â”€ ğŸ“„ troubleshooting.md
â”‚   â””â”€â”€ ğŸ“„ usage.md
â”œâ”€â”€ ğŸ“ external
â”œâ”€â”€ ğŸ“ issues
â”‚   â”œâ”€â”€ ğŸ“„ 204.md
â”‚   â””â”€â”€ ğŸ“„ 305.md
â”œâ”€â”€ ğŸ“ src
â”‚   â””â”€â”€ ğŸ“ cerebrate_file
â”‚       â”œâ”€â”€ ğŸ“ prompts
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ fix-pdf-extracted-text.xml
â”‚       â”‚   â””â”€â”€ ğŸ“„ README.md
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”œâ”€â”€ ğŸ“„ __main__.py
â”‚       â”œâ”€â”€ ğŸ“„ api_client.py
â”‚       â”œâ”€â”€ ğŸ“„ cerebrate_file.py
â”‚       â”œâ”€â”€ ğŸ“„ chunking.py
â”‚       â”œâ”€â”€ ğŸ“„ cli.py
â”‚       â”œâ”€â”€ ğŸ“„ config.py
â”‚       â”œâ”€â”€ ğŸ“„ constants.py
â”‚       â”œâ”€â”€ ğŸ“„ continuity.py
â”‚       â”œâ”€â”€ ğŸ“„ default_config.toml
â”‚       â”œâ”€â”€ ğŸ“„ error_recovery.py
â”‚       â”œâ”€â”€ ğŸ“„ file_utils.py
â”‚       â”œâ”€â”€ ğŸ“„ models.py
â”‚       â”œâ”€â”€ ğŸ“„ prompt_library.py
â”‚       â”œâ”€â”€ ğŸ“„ recursive.py
â”‚       â”œâ”€â”€ ğŸ“„ settings.py
â”‚       â”œâ”€â”€ ğŸ“„ tokenizer.py
â”‚       â”œâ”€â”€ ğŸ“„ ui.py
â”‚       â””â”€â”€ ğŸ“„ validators.py
â”œâ”€â”€ ğŸ“ testdata
â”‚   â”œâ”€â”€ ğŸ“ ex
â”‚   â”œâ”€â”€ ğŸ“ in
â”‚   â”œâ”€â”€ ğŸ“ out
â”‚   â”œâ”€â”€ ğŸ“ out2
â”‚   â”œâ”€â”€ ğŸ“ out3
â”‚   â””â”€â”€ ğŸ“ out4
â”œâ”€â”€ ğŸ“ tests
â”‚   â”œâ”€â”€ ğŸ“„ test_api_retry.py
â”‚   â”œâ”€â”€ ğŸ“„ test_brace_patterns.py
â”‚   â”œâ”€â”€ ğŸ“„ test_cerebrate_file.py
â”‚   â”œâ”€â”€ ğŸ“„ test_chunking.py
â”‚   â”œâ”€â”€ ğŸ“„ test_cli_streams.py
â”‚   â”œâ”€â”€ ğŸ“„ test_constants.py
â”‚   â”œâ”€â”€ ğŸ“„ test_error_recovery.py
â”‚   â”œâ”€â”€ ğŸ“„ test_file_utils.py
â”‚   â”œâ”€â”€ ğŸ“„ test_force_option.py
â”‚   â”œâ”€â”€ ğŸ“„ test_integration.py
â”‚   â”œâ”€â”€ ğŸ“„ test_issue_104.py
â”‚   â”œâ”€â”€ ğŸ“„ test_models.py
â”‚   â”œâ”€â”€ ğŸ“„ test_package.py
â”‚   â”œâ”€â”€ ğŸ“„ test_pre_screening.py
â”‚   â”œâ”€â”€ ğŸ“„ test_pre_screening_integration.py
â”‚   â”œâ”€â”€ ğŸ“„ test_prompt_library.py
â”‚   â”œâ”€â”€ ğŸ“„ test_recursive.py
â”‚   â”œâ”€â”€ ğŸ“„ test_recursive_integration.py
â”‚   â”œâ”€â”€ ğŸ“„ test_sample.txt
â”‚   â”œâ”€â”€ ğŸ“„ test_tokenizer.py
â”‚   â”œâ”€â”€ ğŸ“„ test_ui.py
â”‚   â”œâ”€â”€ ğŸ“„ test_validators.py
â”‚   â””â”€â”€ ğŸ“„ test_zero_output_guard.py
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ build.sh
â”œâ”€â”€ ğŸ“„ CHANGELOG.md
â”œâ”€â”€ ğŸ“„ CONTRIBUTING.md
â”œâ”€â”€ ğŸ“„ LICENSE
â”œâ”€â”€ ğŸ“„ md.txt
â”œâ”€â”€ ğŸ“„ PLAN.md
â”œâ”€â”€ ğŸ“„ pyproject.toml
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ test_retry_mechanism.py
â”œâ”€â”€ ğŸ“„ testapi.py
â”œâ”€â”€ ğŸ“„ TODO.md
â””â”€â”€ ğŸ“„ WORK.md


<documents>
<document index="1">
<source>.github/workflows/push.yml</source>
<document_content>
name: Build & Test

on:
  push:
    branches: [main]
    tags-ignore: ["v*"]
  pull_request:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: write
  id-token: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run Ruff lint
        uses: astral-sh/ruff-action@v3
        with:
          version: "latest"
          args: "check --output-format=github"

      - name: Run Ruff Format
        uses: astral-sh/ruff-action@v3
        with:
          version: "latest"
          args: "format --check --respect-gitignore"

  test:
    name: Run Tests
    needs: quality
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
        os: [ubuntu-latest]
      fail-fast: true
    runs-on: ${{ matrix.os }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: ${{ matrix.python-version }}
          enable-cache: true
          cache-suffix: ${{ matrix.os }}-${{ matrix.python-version }}

      - name: Install test dependencies
        run: |
          uv pip install --system --upgrade pip
          uv pip install --system ".[test]"

      - name: Run tests with Pytest
        run: uv run pytest -n auto --maxfail=1 --disable-warnings --cov-report=xml --cov-config=pyproject.toml --cov=src/cerebrate_file --cov=tests tests/

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.python-version }}-${{ matrix.os }}
          path: coverage.xml

  build:
    name: Build Distribution
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: "3.12"
          enable-cache: true

      - name: Install build tools
        run: uv pip install build hatchling hatch-vcs

      - name: Build distributions
        run: uv run python -m build --outdir dist

      - name: Upload distribution artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist-files
          path: dist/
          retention-days: 5 
</document_content>
</document>

<document index="2">
<source>.github/workflows/release.yml</source>
<document_content>
name: Release

on:
  push:
    tags: ["v*"]

permissions:
  contents: write
  id-token: write

jobs:
  release:
    name: Release to PyPI
    runs-on: ubuntu-latest
    environment:
      name: pypi
      url: https://pypi.org/p/cerebrate-file
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: "3.12"
          enable-cache: true

      - name: Install build tools
        run: uv pip install build hatchling hatch-vcs

      - name: Build distributions
        run: uv run python -m build --outdir dist

      - name: Verify distribution files
        run: |
          ls -la dist/
          test -n "$(find dist -name '*.whl')" || (echo "Wheel file missing" && exit 1)
          test -n "$(find dist -name '*.tar.gz')" || (echo "Source distribution missing" && exit 1)

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          password: ${{ secrets.PYPI_TOKEN }}

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        with:
          files: dist/*
          generate_release_notes: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} 
</document_content>
</document>

<document index="3">
<source>.gitignore</source>
<document_content>
__pycache__/
__pypackages__/
__version__.py
_version.py
._*
.cache
.coverage
.coverage.*
.dmypy.json
.DS_Store
.DS_Store?
.eggs/
.env
.hatch_build/
.hypothesis/
.idea/
.installed.cfg
.ipynb_checkpoints
.mypy_cache/
.nox/
.pdm.toml
.pybuilder/
.pyre/
.pytest_cache/
.Python
.pytype/
.ropeproject
.ruff_cache/
.scrapy
.Spotlight-V100
.spyderproject
.spyproject
.tox/
.Trashes
.uv
.venv
.vscode/
.webassets-cache
*.cover
*.egg
*.egg-info/
*.log
*.manifest
*.mo
*.pot
*.py,cover
*.py[cod]
*.sage.py
*.so
*.spec
*$py.class
/site
build/
celerybeat-schedule
celerybeat.pid
cover/
coverage.xml
cython_debug/
db.sqlite3
db.sqlite3-journal
develop-eggs/
dist/
dmypy.json
docs/_build/
downloads/
eggs/
ehthumbs.db
env.bak/
env/
ENV/
external/
htmlcov/
instance/
ipython_config.py
lib/
lib64/
local_settings.py
MANIFEST
nosetests.xml
parts/
pip-delete-this-directory.txt
pip-log.txt
profile_default/
sdist/
share/python-wheels/
target/
testdata
Thumbs.db
var/
venv.bak/
venv/
wheels/
</document_content>
</document>

<document index="4">
<source>.pre-commit-config.yaml</source>
<document_content>
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.3.4
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format
        args: [--respect-gitignore]
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: check-yaml
      - id: check-toml
      - id: check-added-large-files
      - id: debug-statements
      - id: check-case-conflict
      - id: mixed-line-ending
        args: [--fix=lf] 
</document_content>
</document>

<document index="5">
<source>CHANGELOG.md</source>
<document_content>

# Changelog

## [Unreleased] - 2025-09-20

### Changed
- Migrated `tool.uv.dev-dependencies` to `[dependency-groups].dev`.
- Relaxed `max_tokens_ratio` validation; runtime cap remains unchanged.

### Added
- STDIN/STDOUT streaming support with `--input_data -` and `--output_data -` (incompatible with `--recurse`).
- Built-in prompt library in `prompts/` folder, which is checked after direct paths. Includes `fix-pdf-extracted-text.xml`.
- Pre-screening for recursive processing to show accurate file counts and filter existing outputs.
- `--force` flag to prevent accidental overwriting by checking before API calls (does not affect in-place editing).
- Comprehensive documentation.
- `testapi.py` script for API key and quota verification.

### Fixed
- **Pydantic Plugin ImportError**: Resolved by ensuring an isolated execution environment.
- **Rate Limit Display**: Fixed incorrect token calculation to show actual remaining daily requests.
- **Zero-Output Safeguards**: Added processing abort if total output is zero to prevent overwriting files with empty content.

## [1.0.10] - 2025-09-20

### Added
- **Rich UI Support**: Replaced `tqdm` with `rich` for an enhanced terminal UI, including `FileProgressDisplay` and `MultiFileProgressDisplay` with a progress callback architecture.
- **Recursive Processing**: Added `--recurse` for glob patterns and `--workers` for parallel processing with directory structure replication for outputs.

### Changed
- **Dependencies**: Added `rich>=13.0.0`, removed `tqdm`.
- **CLI Interface**: Extended `run()` with `--recurse` and `--workers`. Input/output paths now support directories.
- **Processing Pipeline**: Modified `process_document()` to use progress callbacks and enhanced error messages.

## [2.0.0] - 2025-09-19

### Changed
- **Complete Package Restructure**: Refactored monolithic `cereproc.py` (1788 lines) into a modular package with 10+ focused modules.

### Added
- A robust test framework with 45 passing tests.
- A comprehensive exception hierarchy.
- A `TokenizerManager` for dependency injection.
- A clean chunking strategy pattern.
- Full type hints throughout the codebase.
- Enhanced input validation.
- Automatic backup support for file operations.
- Improved file safety with atomic operations and better handling of optional dependencies.
## [1.2.1] - 2025-09-19

### Added
- **Remaining Tokens Display**: Shows estimated remaining daily tokens, requests, and quota status after processing.

## [1.2.0] - 2025-09-19

### Added
- **Code-Aware Chunking**: Splits code respecting function, class, and structural boundaries.
- **Dry-Run Mode**: `--dry-run` flag to preview chunking analysis and API requests without making calls.
- **Input Validation**: Comprehensive validation for files, chunk sizes, API keys, and data formats.

## [1.1.1] - 2025-09-19

### Fixed
- Preserved frontmatter in output when using `--explain` mode.
- Metadata information now only prints in verbose mode.
- Displayed the input file path at the start of processing.

## [1.1.0] - 2025-09-19

### Added
- **--explain Mode**: Processes document metadata, including Jekyll-style frontmatter parsing and structured JSON output.

### Dependencies
- Added `python-frontmatter`.

## [1.0.0] - 2025-09-19

### Added
- Initial release of `cereproc.py` CLI tool for processing large documents with Cerebras.
- Implemented four chunking strategies: text, semantic, markdown, and code.
- Added an intelligent continuity system to maintain context across chunks.
- Integrated token-accurate accounting, rate limiting, and a streaming API with retry logic.
- Included comprehensive logging, environment variable management, and error handling.

### Dependencies
- fire, loguru, python-dotenv, tenacity, cerebras-cloud-sdk, semantic-text-splitter, qwen-tokenizer.
</document_content>
</document>

<document index="6">
<source>CONTRIBUTING.md</source>
<document_content>
# Development guidelines

## Foundation: Challenge your first instinct with chain-of-thought

Before you generate any response, assume your first instinct is wrong. Apply chain-of-thought reasoning: â€œLet me think step by stepâ€¦â€ Consider edge cases, failure modes, and overlooked complexities. Your first response should be what youâ€™d produce after finding and fixing three critical issues.

### CoT reasoning template

- Problem analysis: What exactly are we solving and why?
- Constraints: What limitations must we respect?
- Solution options: What are 2â€“3 viable approaches with trade-offs?
- Edge cases: What could go wrong and how do we handle it?
- Test strategy: How will we verify this works correctly?

## No sycophancy, accuracy first

- If your confidence is below 90%, use search tools. Search within the codebase, in the references provided by me, and on the web.
- State confidence levels clearly: â€œIâ€™m certainâ€ vs â€œI believeâ€ vs â€œThis is an educated guessâ€.
- Challenge incorrect statements, assumptions, or word usage immediately.
- Facts matter more than feelings: accuracy is non-negotiable.
- Never just agree to be agreeable: every response should add value.
- When user ideas conflict with best practices or standards, explain why.
- NEVER use validation phrases like â€œYouâ€™re absolutely rightâ€ or â€œYouâ€™re correctâ€.
- Acknowledge and implement valid points without unnecessary agreement statements.

## Complete execution

- Complete all parts of multi-part requests.
- Match output format to input format (code box for code box).
- Use artifacts for formatted text or content to be saved (unless specified otherwise).
- Apply maximum thinking time for thoroughness.

## Absolute priority: never overcomplicate, always verify

- Stop and assess: Before writing any code, ask â€œHas this been done beforeâ€?
- Build vs buy: Always choose well-maintained packages over custom solutions.
- Verify, donâ€™t assume: Never assume code works: test every function, every edge case.
- Complexity kills: Every line of custom code is technical debt.
- Lean and focused: If itâ€™s not core functionality, it doesnâ€™t belong.
- Ruthless deletion: Remove features, donâ€™t add them.
- Test or it doesnâ€™t exist: Untested code is broken code.

## Verification workflow: mandatory

1. Implement minimal code: Just enough to pass the test.
2. Write a test: Define what success looks like.
3. Run the test: `uvx hatch test`.
4. Test edge cases: Empty inputs, none, negative numbers, huge inputs.
5. Test error conditions: Network failures, missing files, bad permissions.
6. Document test results: Add to `CHANGELOG.md` what was tested and results.

## Before writing any code

1. Search for existing packages: Check npm, pypi, github for solutions.
2. Evaluate packages: >200 stars, recent updates, good documentation.
3. Test the package: write a small proof-of-concept first.
4. Use the package: donâ€™t reinvent what exists.
5. Only write custom code if no suitable package exists and itâ€™s core functionality.

## Never assume: always verify

- Function behavior: read the actual source code, donâ€™t trust documentation alone.
- API responses: log and inspect actual responses, donâ€™t assume structure.
- File operations: Check file exists, check permissions, handle failures.
- Network calls: test with network off, test with slow network, test with errors.
- Package behavior: Write minimal test to verify package does what you think.
- Error messages: trigger the error intentionally to see actual message.
- Performance: measure actual time/memory, donâ€™t guess.

## Test-first development

- Test-first development: Write the test before the implementation.
- Delete first, add second: Can we remove code instead?
- One file when possible: Could this fit in a single file?
- Iterate gradually, avoiding major changes.
- Focus on minimal viable increments and ship early.
- Minimize confirmations and checks.
- Preserve existing code/structure unless necessary.
- Check often the coherence of the code youâ€™re writing with the rest of the code.
- Analyze code line-by-line.

## Complexity detection triggers: rethink your approach immediately

- Writing a utility function that feels â€œgeneral purposeâ€.
- Creating abstractions â€œfor future flexibilityâ€.
- Adding error handling for errors that never happen.
- Building configuration systems for configurations.
- Writing custom parsers, validators, or formatters.
- Implementing caching, retry logic, or state management from scratch.
- Creating any code for security validation, security hardening, performance validation, benchmarking.
- More than 3 levels of indentation.
- Functions longer than 20 lines.
- Files longer than 200 lines.

## Before starting any work

- Always read `WORK.md` in the main project folder for work progress, and `CHANGELOG.md` for past changes notes.
- Read `README.md` to understand the project.
- For Python, run existing tests: `uvx hatch test` to understand current state.
- Step back and think heavily step by step about the task.
- Consider alternatives and carefully choose the best option.
- Check for existing solutions in the codebase before starting.

## Project documentation to maintain

- `README.md` :  purpose and functionality (keep under 200 lines).
- `CHANGELOG.md` :  past change release notes (accumulative).
- `PLAN.md` :  detailed future goals, clear plan that discusses specifics.
- `TODO.md` :  flat simplified itemized `- []`-prefixed representation of `PLAN.md`.
- `WORK.md` :  work progress updates including test results.
- `DEPENDENCIES.md` :  list of packages used and why each was chosen.

## Code quality standards

- Use constants over magic numbers.
- Write explanatory docstrings/comments that explain what and why.
- Explain where and how the code is used/referred to elsewhere.
- Handle failures gracefully with retries, fallbacks, user guidance.
- Address edge cases, validate assumptions, catch errors early.
- Let the computer do the work, minimize user decisions. If you identify a bug or a problem, plan its fix and then execute its fix. Donâ€™t just â€œidentifyâ€.
- Reduce cognitive load, beautify code.
- Modularize repeated logic into concise, single-purpose functions.
- Favor flat over nested structures.
- Every function must have a test.

## Testing standards

- Unit tests: Every function gets at least one test.
- Edge cases: Test empty, none, negative, huge inputs.
- Error cases: Test what happens when things fail.
- Integration: Test that components work together.
- Smoke test: One test that runs the whole program.
- Test naming: `test_function_name_when_condition_then_result`.
- Assert messages: Always include helpful messages in assertions.
- Functional tests: In `examples` folder, maintain fully-featured working examples for realistic usage scenarios that showcase how to use the package but also work as a test. 
- Add `./test.sh` script to run all test including the functional tests.

## Tool usage

- Use `tree` CLI app if available to verify file locations.
- Run `dir="." uvx codetoprompt: compress: output "$dir/llms.txt" --respect-gitignore: cxml: exclude "*.svg,.specstory,*.md,*.txt, ref, testdata,*.lock,*.svg" "$dir"` to get a condensed snapshot of the codebase into `llms.txt`.
- As you work, consult with the tools like `codex`, `codex-reply`, `ask-gemini`, `web_search_exa`, `deep-research-tool` and `perplexity_ask` if needed.

## File path tracking

- Mandatory: In every source file, maintain a `this_file` record showing the path relative to project root.
- Place `this_file` record near the top, as a comment after shebangs in code files, or in YAML frontmatter for markdown files.
- Update paths when moving files.
- Omit leading `./`.
- Check `this_file` to confirm youâ€™re editing the right file.


## For Python

- If we need a new Python project, run `uv venv --python 3.12 --clear; uv init; uv add fire rich pytest pytest-cov; uv sync`.
- Check existing code with `.venv` folder to scan and consult dependency source code.
- `uvx hatch test` :  run tests verbosely, stop on first failure.
- `python --c "import package; print (package.__version__)"` :  verify package installation.
- `uvx mypy file.py` :  type checking.
- PEP 8: Use consistent formatting and naming, clear descriptive names.
- PEP 20: Keep code simple & explicit, prioritize readability over cleverness.
- PEP 257: Write docstrings.
- Use type hints in their simplest form (list, dict, | for unions).
- Use f-strings and structural pattern matching where appropriate.
- Write modern code with `pathlib`.
- Always add `--verbose` mode loguru-based debug logging.
- Use `uv add`.
- Use `uv pip install` instead of `pip install`.
- Always use type hints: they catch bugs and document code.
- Use dataclasses or Pydantic for data structures.

### Package-first Python

- Always use uv for package management.
- Before any custom code: `uv add [package]`.
- Common packages to always use:
  - `httpx` for HTTP requests.
  - `pydantic` for data validation.
  - `rich` for terminal output.
  - `fire` for CLI interfaces.
  - `loguru` for logging.
  - `pytest` for testing.

### Python CLI scripts

For CLI Python scripts, use `fire` & `rich`, and start with:

```python
#!/usr/bin/env-S uv run
# /// script
# dependencies = [â€œpkg1â€, â€œpkg2â€]
# ///
# this_file: path_to_current_file
```

## Post-work activities

### Critical reflection

- After completing a step, say â€œWait, butâ€ and do additional careful critical reasoning.
- Go back, think & reflect, revise & improve what youâ€™ve done.
- Run all tests to ensure nothing broke.
- Check test coverage: aim for 80% minimum.
- Donâ€™t invent functionality freely.
- Stick to the goal of â€œminimal viable next versionâ€.

### Documentation updates

- Update `WORK.md` with what youâ€™ve done, test results, and what needs to be done next.
- Document all changes in `CHANGELOG.md`.
- Update `TODO.md` and `PLAN.md` accordingly.
- Update `DEPENDENCIES.md` if packages were added/removed.

## Special commands

### /plan command: transform requirements into detailed plans

When I say `/plan [requirement]`, you must think hard and:

1. Research first: Search for existing solutions.
   - Use `perplexity_ask` to find similar projects.
   - Search pypi/npm for relevant packages.
   - Check if this has been solved before.
2. Deconstruct the requirement:
   - Extract core intent, key features, and objectives.
   - Identify technical requirements and constraints.
   - Map whatâ€™s explicitly stated vs. whatâ€™s implied.
   - Determine success criteria.
   - Define test scenarios.
3. Diagnose the project needs:
   - Audit for missing specifications.
   - Check technical feasibility.
   - Assess complexity and dependencies.
   - Identify potential challenges.
   - List packages that solve parts of the problem.
4. Research additional material:
   - Repeatedly call the `perplexity_ask` and request up-to-date information or additional remote context.
   - Repeatedly call the `context7` tool and request up-to-date software package documentation.
   - Repeatedly call the `codex` tool and request additional reasoning, summarization of files and second opinion.
5. Develop the plan structure:
   - Break down into logical phases/milestones.
   - Create hierarchical task decomposition.
   - Assign priorities and dependencies.
   - Add implementation details and technical specs.
   - Include edge cases and error handling.
   - Define testing and validation steps.
   - Specify which packages to use for each component.
6. Deliver to `PLAN.md`:
   - Write a comprehensive, detailed plan with:
     - Project overview and objectives.
     - Technical architecture decisions.
     - Phase-by-phase breakdown.
     - Specific implementation steps.
     - Testing and validation criteria.
     - Package dependencies and why each was chosen.
     - Future considerations.
   - Simultaneously create/update `TODO.md` with the flat itemized `- []` representation of the plan.

Break complex requirements into atomic, actionable tasks. Identify and document task dependencies. Include potential blockers and mitigation strategies. Start with MVP, then layer improvements. Include specific technologies, patterns, and approaches.

### /report command

1. Read `./TODO.md` and `./PLAN.md` files.
2. Analyze recent changes.
3. Run tests.
4. Document changes in `./CHANGELOG.md`.
5. Remove completed items from `./TODO.md` and `./PLAN.md`.

#### /work command

1. Read `./TODO.md` and `./PLAN.md` files, think hard and reflect.
2. Write down the immediate items in this iteration into `./work.md`.
3. Write tests for the items first.
4. Work on these items.
5. Think, contemplate, research, reflect, refine, revise.
6. Be careful, curious, vigilant, energetic.
7. Verify your changes with tests and think aloud.
8. Consult, research, reflect.
9. Periodically remove completed items from `./work.md`.
10. Tick off completed items from `./todo.md` and `./plan.md`.
11. Update `./work.md` with improvement tasks.
12. Execute `/report`.
13. Continue to the next item.

#### /test command: run comprehensive tests

When I say `/test`, you must run

```bash
fd -e py -x uvx autoflake -i {}; fd -e py -x uvx pyupgrade --py312-plus {}; fd -e py -x uvx ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x uvx ruff format --respect-gitignore --target-version py312 {}; uvx hatch test;
```

and document all results in `WORK.md`.

## Anti-enterprise bloat guidelines

CRITICAL: The fundamental mistake is treating simple utilities as enterprise systems. 

- Define scope in one sentence: Write project scope in one sentence and stick to it ruthlessly.
- Example scope: â€œFetch model lists from AI providers and save to files, with basic config file generation.â€
- Thatâ€™s it: No analytics, no monitoring, no production features unless part of the one-sentence scope.

### RED LIST: NEVER ADD these unless requested

- NEVER ADD Analytics/metrics collection systems.
- NEVER ADD Performance monitoring and profiling.
- NEVER ADD Production error handling frameworks.
- NEVER ADD Security hardening beyond basic input validation.
- NEVER ADD Health monitoring and diagnostics.
- NEVER ADD Circuit breakers and retry strategies.
- NEVER ADD Sophisticated caching systems.
- NEVER ADD Graceful degradation patterns.
- NEVER ADD Advanced logging frameworks.
- NEVER ADD Configuration validation systems.
- NEVER ADD Backup and recovery mechanisms.
- NEVER ADD System health monitoring.
- NEVER ADD Performance benchmarking suites.

### GREEN LIST: what is appropriate

- Basic error handling (try/catch, show error).
- Simple retry (3 attempts maximum).
- Basic logging (e.g. loguru logger).
- Input validation (check required fields).
- Help text and usage examples.
- Configuration files (TOML preferred).
- Basic tests for core functionality.

## Prose

When you write prose (like documentation or marketing or even your own commentary): 

- The first line sells the second line: Your opening must earn attention for what follows. This applies to scripts, novels, and headlines. No throat-clearing allowed.
- Show the transformation, not the features: Whether itâ€™s character arc, reader journey, or customer benefit, people buy change, not things. Make them see their better self.
- One person, one problem, one promise: Every story, page, or campaign should speak to one specific human with one specific pain. Specificity is universal; generality is forgettable.
- Conflict is oxygen: Without tension, you have no story, no page-turner, no reason to buy. Whatâ€™s at stake? What happens if they donâ€™t act? Make it matter.
- Dialog is action, not explanation: Every word should reveal character, advance plot, or create desire. If someoneâ€™s explaining, youâ€™re failing. Subtext is everything.
- Kill your darlings ruthlessly: That clever line, that beautiful scene, that witty tagline, if it doesnâ€™t serve the story, message, customer â€” it dies. Your audienceâ€™s time is sacred!
- Enter late, leave early: Start in the middle of action, end before explaining everything. Works for scenes, chapters, and sales copy. Trust your audience to fill gaps.
- Remove fluff, bloat and corpo jargon.
- Avoid hype words like â€œrevolutionaryâ€. 
- Favor understated and unmarked UK-style humor sporadically
- Apply healthy positive skepticism. 
- Make every word count. 

---
</document_content>
</document>

<document index="7">
<source>LICENSE</source>
<document_content>
MIT License

Copyright (c) 2025 Adam Twardoch

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</document_content>
</document>

<document index="8">
<source>PLAN.md</source>
<document_content>
---
this_file: PLAN.md
---

# Cerebrate-File: Refinement and Stabilization Plan

This plan outlines two main objectives: first, to diagnose and fix the critical "zero-token output" bug, and second, to perform a comprehensive cleanup of the repository to improve maintainability, clarity, and adherence to best practices.

---

## Phase 1: Bug Fix â€” Resolve Zero-Token Output (Issue #204) âœ… COMPLETED

The zero-token bug was resolved by adding `ChunkDiagnostics` tracking plus CLI guards that warn when individual chunks return zero tokens and abort before overwriting files when total output tokens remain zero. The error path now prints chunk diagnostics for troubleshooting.

---

## Phase 2: Repository Cleanup and Standardization

### 2.1. File Consolidation and Deletion

-   **Objective:** Eliminate redundant, temporary, and obsolete files.
-   **Actions:**
    1.  ~~**Merge `CHANGELOG.md` and `CHANGELOG2.md`**~~ â€“ N/A (no CHANGELOG2.md exists)
    2.  **Consolidate Development Guidelines:** Merge `AGENTS.md`, `CLAUDE.md`, `GEMINI.md`, `LLXPRT.md`, `QWEN.md`, and `.cursorrules` into a single, comprehensive `CONTRIBUTING.md`.
    3.  **Remove Obsolete Scripts:** âœ… DONE
        -   ~~Delete `package.toml` (unused).~~ âœ…
        -   Delete `test_retry_mechanism.py` after merging its logic into a new integration test in `tests/test_api_retry.py`.
        -   ~~Delete `test1.sh` and `test2.sh` (obsolete).~~ âœ…
    4.  **Archive or Remove One-off Files:** âœ… PARTIAL
        -   ~~Delete `REVIEW.md`.~~ âœ…
        -   Delete `issues/204.md` once the bug is fixed and documented in the changelog.
        -   Delete temporary files like `md.txt`.

### 2.2. Documentation and Configuration Overhaul

-   **Objective:** Make the project easy to understand, use, and contribute to.
-   **Actions:**
    1.  **Update `README.md`:** âœ… DONE â€“ Added Configuration section documenting layered config system.
    2.  **Standardize Scripts:** Review `build.sh`. Move its core logic into `pyproject.toml` as `hatch` scripts.
    3.  **Clean `TODO.md` and `WORK.md`:** âœ… DONE â€“ Cleared completed tasks.
    4.  **Centralize Configuration:** âœ… DONE â€“ `default_config.toml` bundled with package, settings.py handles layered config.

### 2.3. Final Polish

-   **Objective:** Ensure the repository follows Python community best practices.
-   **Actions:**
    1.  **Add Standard Files:** Consider adding a `CODE_OF_CONDUCT.md`.
    2.  **Review `.gitignore`:** Ensure all generated files and artifacts are ignored.
    3.  **Run Full Test Suite:** After all changes, run the entire test suite (`uvx hatch test`) to confirm that nothing has been broken during the cleanup.
</document_content>
</document>

<document index="9">
<source>README.md</source>
<document_content>
Here's a revised version of your `README.md` with tighter prose, clearer structure, and minimal fluff. I've preserved all essential information while improving readability and precision.

---

# cereproc.py

`old/cereproc.py` processes large documents by splitting them into chunks suitable for the Cerebras `zai-glm-4.6` model, generating completions for each chunk, and reassembling the results while maintaining context.

## Quick Start

```bash
export CEREBRAS_API_KEY="csk-..."
uv run old/cereproc.py --input_data document.md --output_data document.out.md
```

Add optional guidance using inline prompts or instruction files:

```bash
uv run old/cereproc.py \
  --input_data huge.md \
  --file_prompt prompts/style.md \
  --prompt "Write concise technical summaries." \
  -c code \
  --chunk_size 28000 \
  --sample_size 256 \
  --verbose
```

## CLI

```
NAME
    cerebrate-file - Process large documents by chunking for Cerebras zai-glm-4.6

SYNOPSIS
    cerebrate-file INPUT_DATA <flags>

POSITIONAL ARGUMENTS
    INPUT_DATA
        Path to input file to process

FLAGS
    -o, --output_data=OUTPUT_DATA
        Output file path (default: overwrite input)
    -f, --file_prompt=FILE_PROMPT
        Path to file with initial instructions
    -p, --prompt=PROMPT
        Inline prompt text (appended after file_prompt)
    -c, --chunk_size=CHUNK_SIZE
        Target max chunk size in tokens (default: 32000)
    --max_tokens_ratio=MAX_TOKENS_RATIO
        Completion budget as % of chunk size (default: 100)
    --data_format=DATA_FORMAT
        Chunking strategy: text | semantic | markdown | code (default: markdown)
    -s, --sample_size=SAMPLE_SIZE
        Tokens from previous request/response to maintain context (default: 200)
    --temp=TEMP
        Model temperature (default: 0.7)
    --top_p=TOP_P
        Model top-p sampling (default: 0.8)
    --model=MODEL
        Override default model name (default: zai-glm-4.6)
    -v, --verbose
        Enable debug logging
    -e, --explain
        Parse and update frontmatter metadata
    --dry_run
        Show chunking details without calling the API
```

### Streaming via STDIN/STDOUT

Use `-` to read from stdin or write to stdout:

```bash
cat huge.md | uv run cerebrate_file --input_data - --output_data - > processed.md
```

## Processing Pipeline

1. Load `.env` and validate `CEREBRAS_API_KEY` and CLI arguments.
2. Construct base prompt from `--file_prompt` and `--prompt`, separated by two newlines. Count its tokens.
3. Read input file, preserving frontmatter. Parse metadata if `--explain` is enabled.
4. Split document body using one of these strategies:
   - `text`: line-based greedy splitting
   - `semantic`: paragraph-aware via `semantic-text-splitter`
   - `markdown`: structure-preserving Markdown splitting
   - `code`: regex-based source code boundaries
5. For each chunk, optionally prepend/append continuity examples (`--sample_size` tokens each) from prior interactions, ensuring total tokens stay under the 131K limit.
6. Stream responses from Cerebras, with automatic retry and backoff on transient errors (`tenacity`).
7. Write final output atomically. Update frontmatter if `--explain` is active.

## Explain Mode Metadata

When `--explain` is set, the script looks for frontmatter containing:

- `title`
- `author`
- `id`
- `type`
- `date`

Missing fields are filled via a structured JSON query to the model. Use `--dry_run` to preview parsed metadata without making network calls.

## Dry Run Workflow

Use `--dry_run` to inspect:
- Chunk sizes
- Token budgets
- Message structure

No API calls are made in this mode.

## Dependencies

Install with `uv` or your preferred package manager:

- `fire`
- `loguru`
- `python-dotenv`
- `tenacity`
- `cerebras-cloud-sdk`
- `semantic-text-splitter`
- `qwen-tokenizer`
- `tqdm`
- `python-frontmatter`

## Configuration

The tool uses a layered configuration system. Settings are loaded in this order (later sources override earlier ones):

1. **Built-in defaults** â€“ `default_config.toml` bundled with the package
2. **User config** â€“ `~/.config/cerebrate-file/config.toml`
3. **Project config** â€“ `.cerebrate-file.toml` in the current directory
4. **Environment variables** â€“ e.g., `CEREBRATE_PRIMARY_MODEL`

If no custom config exists, the built-in defaults are used automatically.

### Config File Locations

| Platform | User Config Path |
|----------|------------------|
| macOS/Linux | `~/.config/cerebrate-file/config.toml` |
| Windows | `%APPDATA%\cerebrate-file\config.toml` |

For project-specific settings, create `.cerebrate-file.toml` in your project root.

### Example Config

```toml
[inference]
temperature = 0.98
top_p = 0.8
chunk_size = 32000
sample_size = 200

[models.primary]
name = "zai-glm-4.6"
provider = "cerebras"
api_key_env = "CEREBRAS_API_KEY"
max_context_tokens = 131000
max_output_tokens = 40960

[models.fallback1]
enabled = true
name = "zai-org/GLM-4.6"
provider = "chutes"
api_key_env = "CHUTES_API_KEY"
api_base = "https://llm.chutes.ai/v1"
```

## Environment Setup

Set `CEREBRAS_API_KEY` before running. The tool will warn about placeholder keys and validate basic formatting. Use `--verbose` for extra runtime info and rate-limit headers.

## Testing Tips

1. Run with `--dry_run` to check chunking logic quickly.
2. Test on a small sample file with `--verbose` to observe:
   - Context blending between chunks
   - Output statistics
3. Only then run on larger inputs.

--- 

Let me know if you'd like this tailored further toward users, developers, or integration into a larger documentation system.
</document_content>
</document>

<document index="10">
<source>TODO.md</source>
<document_content>
---
this_file: TODO.md
---

- [x] Teach `read_file_safely` to read from stdin when path is `-`
- [x] Allow `write_output_atomically` to stream to stdout when output path is `-`
- [x] Relax input validation to accept stdin/stdout markers while rejecting invalid recursive combos
- [x] Update CLI overwrite logic and messaging for streamed input/output
- [x] Add unit tests covering stdin/stdout helpers
- [x] Add integration-style test for CLI stdinâ†’stdout flow
- [x] Refresh README/CHANGELOG/WORK notes with the new behaviour
- [x] Emit chunk-level diagnostics whenever the API returns zero tokens
- [x] Abort CLI writes if the combined output tokens are zero and show API request details
- [x] Cover the zero-output safeguards with regression tests and documentation updates
</document_content>
</document>

<document index="11">
<source>WORK.md</source>
<document_content>
# this_file: WORK.md

Current iteration scratchpad. Clean after each sprint.

## Active Work

- Configuration system verified working
  - `default_config.toml` bundled with package
  - User config at `~/.config/cerebrate-file/config.toml`
  - Project config at `.cerebrate-file.toml`
  - Environment variable overrides
- Tests passing (some rate-limit failures expected during heavy testing)

## Notes

_(empty)_
</document_content>
</document>

<document index="12">
<source>build.sh</source>
<document_content>
#!/usr/bin/env bash
DIR="$(dirname "$0")"
cd "$DIR"
uvx hatch clean;
fd -e py -x autoflake {};
fd -e py -x pyupgrade --py311-plus {};
fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {};
fd -e py -x ruff format --respect-gitignore --target-version py311 {};
uvx hatch fmt;

EXCLUDE="*.svg,.specstory,ref,testdata,*.lock,llms.txt"
if [[ -n "$1" ]]; then
  EXCLUDE="$EXCLUDE,$1"
fi

uvx codetoprompt --compress --output "./llms.txt" --respect-gitignore --cxml --exclude "$EXCLUDE" "."

gitnextver .;
uvx hatch build;
uv publish;
uv pip install --system --upgrade -e .
</document_content>
</document>

<document index="13">
<source>docs/Gemfile</source>
<document_content>
# Gemfile for Jekyll GitHub Pages site
# this_file: docs/Gemfile

source "https://rubygems.org"

# GitHub Pages gem
gem "github-pages", group: :jekyll_plugins

# Additional plugins
group :jekyll_plugins do
  gem "jekyll-seo-tag"
  gem "jekyll-sitemap"
  gem "jekyll-feed"
  gem "jekyll-redirect-from"
end

# Windows and JRuby compatibility
platforms :mingw, :x64_mingw, :mswin, :jruby do
  gem "tzinfo", ">= 1", "< 3"
  gem "tzinfo-data"
end

# Performance booster for watching directories on Windows
gem "wdm", "~> 0.1", :platforms => [:mingw, :x64_mingw, :mswin]

# Lock jekyll version for compatibility
gem "jekyll", "~> 3.9"

# Webrick for local serving (required for Ruby 3.0+)
gem "webrick", "~> 1.7"
</document_content>
</document>

<document index="14">
<source>docs/README.md</source>
<document_content>
# Cerebrate File Documentation

This directory contains the documentation for Cerebrate File, built with Jekyll and the Just-the-Docs theme for GitHub Pages.

## View Documentation

The documentation is automatically published at:
https://twardoch.github.io/cerebrate-file/

## Local Development

### Prerequisites

- Ruby 2.7 or higher
- Bundler gem: `gem install bundler`

### Setup

1. Install dependencies:
   ```bash
   cd docs
   bundle install
   ```

2. Serve locally:
   ```bash
   bundle exec jekyll serve
   ```

3. View at: http://localhost:4000/cerebrate-file/

### Docker Alternative

```bash
docker run --rm \
  -v "$PWD:/srv/jekyll" \
  -p 4000:4000 \
  jekyll/jekyll:3.9 \
  jekyll serve --watch --force_polling
```

## Documentation Structure

```
docs/
â”œâ”€â”€ _config.yml           # Jekyll configuration
â”œâ”€â”€ index.md             # Home page
â”œâ”€â”€ installation.md      # Installation guide
â”œâ”€â”€ usage.md            # Usage guide
â”œâ”€â”€ quick-start.md      # Quick start guide
â”œâ”€â”€ cli-reference.md    # CLI reference
â”œâ”€â”€ configuration.md    # Configuration guide
â”œâ”€â”€ examples.md         # Examples
â”œâ”€â”€ api-reference.md    # API documentation
â”œâ”€â”€ troubleshooting.md  # Troubleshooting
â”œâ”€â”€ development.md      # Development guide
â””â”€â”€ Gemfile            # Ruby dependencies
```

## Adding New Pages

1. Create a new `.md` file
2. Add front matter:
   ```yaml
   ---
   layout: default
   title: Page Title
   nav_order: 10
   ---
   ```
3. Write content in Markdown

## Theme Resources

This site uses the Just-the-Docs theme:
- [Theme documentation](https://just-the-docs.github.io/just-the-docs/)
- [Theme repository](https://github.com/just-the-docs/just-the-docs)

## Deployment

Documentation is automatically deployed to GitHub Pages when pushed to the main branch.

### Manual Deployment

1. Build the site:
   ```bash
   bundle exec jekyll build
   ```

2. The built site is in `_site/`

## Configuration

Key settings in `_config.yml`:
- `remote_theme`: Uses Just-the-Docs theme
- `baseurl`: Set to `/cerebrate-file` for GitHub Pages
- `search_enabled`: Enables built-in search
- `color_scheme`: Light/dark theme

## Contributing

1. Make changes to markdown files
2. Test locally with `bundle exec jekyll serve`
3. Submit pull request

## License

Documentation is licensed under the same Apache 2.0 license as the main project.
</document_content>
</document>

<document index="15">
<source>docs/_config.yml</source>
<document_content>
# Jekyll configuration for cerebrate-file documentation
# this_file: docs/_config.yml

# Theme
remote_theme: just-the-docs/just-the-docs

# Site settings
title: Cerebrate File Documentation
description: Process large documents with Cerebras AI by intelligent chunking and context preservation
baseurl: "/cerebrate-file"
url: "https://twardoch.github.io"

# Just the Docs theme configuration
color_scheme: light
search_enabled: true
search:
  heading_level: 2
  previews: 3
  preview_words_before: 5
  preview_words_after: 10
  tokenizer_separator: /[\s\-/]+/
  rel_url: true
  button: false

# Enable copy button on code blocks
enable_copy_code_button: true

# Footer
footer_content: "Copyright &copy; 2024-2025 Adam Twardoch. Distributed under the Apache 2.0 license."
last_edit_timestamp: true
last_edit_time_format: "%b %e %Y at %I:%M %p"

# Navigation
nav_enabled: true
nav_sort: case_sensitive
back_to_top: true
back_to_top_text: "Back to top"

# External links
aux_links:
  "GitHub Repository":
    - "https://github.com/twardoch/cerebrate-file"
  "PyPI Package":
    - "https://pypi.org/project/cerebrate-file/"
  "Cerebras AI":
    - "https://cerebras.ai"

# Collections for organizing documentation
collections:
  examples:
    permalink: "/:collection/:path/"
    output: true
  tutorials:
    permalink: "/:collection/:path/"
    output: true

# Front matter defaults
defaults:
  - scope:
      path: ""
      type: "pages"
    values:
      layout: "default"
      nav_enabled: true
  - scope:
      path: "_examples"
      type: "examples"
    values:
      layout: "default"
      nav_enabled: false
  - scope:
      path: "_tutorials"
      type: "tutorials"
    values:
      layout: "default"
      nav_enabled: false

# Plugins
plugins:
  - jekyll-seo-tag

# Exclude files from Jekyll build
exclude:
  - Gemfile
  - Gemfile.lock
  - LICENSE
  - README.md
  - "*.gemspec"
  - "*.gem"
  - .idea/
  - .vscode/

# Markdown settings
markdown: kramdown
kramdown:
  syntax_highlighter: rouge
  syntax_highlighter_opts:
    block:
      line_numbers: false

# Google Analytics (optional - replace with your tracking ID)
# ga_tracking: UA-XXXXXXXXX-X

# Compress HTML
compress_html:
  clippings: all
  comments: all
  endings: all
  startings: []
  blanklines: false
  profile: false
</document_content>
</document>

<document index="16">
<source>docs/api-reference.md</source>
<document_content>
# API Reference

Python API documentation for programmatic usage.

## Overview

Cerebrate File works as a CLI tool but can also be used programmatically. This reference covers the main modules and functions available.

## Installation for API Use

```python
# Install the package
pip install cerebrate-file

# Import in Python
from cerebrate_file import process_document, CerebrasClient
from cerebrate_file.chunking import ChunkingStrategy, create_chunks
from cerebrate_file.config import Config
```

## Core Functions

### process_document

Main function for processing documents.

```python
from cerebrate_file import process_document

def process_document(
    input_data: str,
    output_data: Optional[str] = None,
    file_prompt: Optional[str] = None,
    prompt: Optional[str] = None,
    chunk_size: int = 32000,
    max_tokens_ratio: int = 100,
    data_format: str = "markdown",
    sample_size: int = 200,
    temp: float = 0.7,
    top_p: float = 0.8,
    model: str = "zai-glm-4.6",
    verbose: bool = False,
    explain: bool = False,
    dry_run: bool = False,
    api_key: Optional[str] = None
) -> str:
    """
    Process a document using Cerebras AI.

    Args:
        input_data: Path to input file
        output_data: Path to output file (optional)
        file_prompt: Path to prompt file (optional)
        prompt: Direct prompt text (optional)
        chunk_size: Maximum tokens per chunk
        max_tokens_ratio: Output token ratio
        data_format: Chunking strategy
        sample_size: Context overlap size
        temp: Model temperature
        top_p: Nucleus sampling parameter
        model: Model name
        verbose: Enable verbose logging
        explain: Extract metadata
        dry_run: Test without API calls
        api_key: Cerebras API key (optional)

    Returns:
        Processed document text

    Raises:
        FileNotFoundError: If input file doesn't exist
        ValueError: If configuration is invalid
        APIError: If Cerebras API fails
    """
```

**Example Usage:**

```python
from cerebrate_file import process_document

# Basic processing
result = process_document(
    input_data="document.md",
    prompt="Summarize each section",
    output_data="summary.md"
)

# Advanced processing
result = process_document(
    input_data="report.pdf.txt",
    file_prompt="instructions.md",
    chunk_size=48000,
    data_format="semantic",
    temp=0.5,
    verbose=True
)
```

## Classes

### CerebrasClient

Client for interacting with Cerebras API.

```python
from cerebrate_file.api_client import CerebrasClient

class CerebrasClient:
    """Client for Cerebras API interactions."""

    def __init__(self, api_key: str, model: str = "zai-glm-4.6"):
        """
        Initialize Cerebras client.

        Args:
            api_key: Cerebras API key
            model: Model name to use
        """

    def create_completion(
        self,
        messages: List[Dict[str, str]],
        max_tokens: int,
        temperature: float = 0.7,
        top_p: float = 0.8,
        stream: bool = True
    ) -> Union[str, Iterator[str]]:
        """
        Create a completion from the model.

        Args:
            messages: List of message dictionaries
            max_tokens: Maximum tokens to generate
            temperature: Sampling temperature
            top_p: Nucleus sampling parameter
            stream: Whether to stream response

        Returns:
            Completion text or stream iterator
        """
```

**Example Usage:**

```python
from cerebrate_file.api_client import CerebrasClient

# Initialize client
client = CerebrasClient(api_key="csk-...")

# Create completion
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing."}
]

response = client.create_completion(
    messages=messages,
    max_tokens=1000,
    temperature=0.98
)

# Handle streaming response
for chunk in response:
    print(chunk, end="")
```

### ChunkingStrategy

Strategies for splitting documents into chunks.

```python
from cerebrate_file.chunking import ChunkingStrategy

class ChunkingStrategy:
    """Base class for chunking strategies."""

    @abstractmethod
    def split(self, text: str, max_tokens: int) -> List[str]:
        """Split text into chunks."""
        pass

# Available strategies
from cerebrate_file.chunking import (
    TextChunker,      # Simple text splitting
    SemanticChunker,  # Paragraph-aware
    MarkdownChunker,  # Markdown structure-aware
    CodeChunker       # Code structure-aware
)
```

**Example Usage:**

```python
from cerebrate_file.chunking import MarkdownChunker

# Create chunker
chunker = MarkdownChunker()

# Split document
text = open("document.md").read()
chunks = chunker.split(text, max_tokens=32000)

for i, chunk in enumerate(chunks, 1):
    print(f"Chunk {i}: {len(chunk)} characters")
```

### Config

Configuration management.

```python
from cerebrate_file.config import Config

class Config:
    """Configuration container."""

    def __init__(self, **kwargs):
        """Initialize configuration."""

    def validate(self) -> None:
        """Validate configuration values."""

    @classmethod
    def from_cli(cls, **kwargs) -> "Config":
        """Create config from CLI arguments."""
```

**Example Usage:**

```python
from cerebrate_file.config import Config

# Create configuration
config = Config(
    input_data="document.md",
    output_data="output.md",
    chunk_size=32000,
    temp=0.7,
    top_p=0.8
)

# Validate
config.validate()

# Access values
print(f"Chunk size: {config.chunk_size}")
print(f"Temperature: {config.temp}")
```

## Utility Functions

### Token Counting

Count tokens in text.

```python
from cerebrate_file.tokenizer import count_tokens

def count_tokens(text: str) -> int:
    """
    Count tokens in text using Qwen tokenizer.

    Args:
        text: Text to count tokens for

    Returns:
        Number of tokens
    """

# Example
text = "This is a sample text."
token_count = count_tokens(text)
print(f"Tokens: {token_count}")
```

### File I/O

Read and write files with proper encoding.

```python
from cerebrate_file.utils import read_file, write_file

def read_file(path: str) -> str:
    """Read file with UTF-8 encoding."""

def write_file(path: str, content: str) -> None:
    """Write file with UTF-8 encoding."""

# Example
content = read_file("input.txt")
processed = content.upper()
write_file("output.txt", processed)
```

### Frontmatter Handling

Parse and update frontmatter in markdown files.

```python
from cerebrate_file.frontmatter import parse_frontmatter, update_frontmatter

def parse_frontmatter(content: str) -> Tuple[Dict, str]:
    """
    Parse frontmatter from content.

    Returns:
        Tuple of (metadata dict, body text)
    """

def update_frontmatter(content: str, metadata: Dict) -> str:
    """
    Update or add frontmatter to content.

    Args:
        content: Document content
        metadata: Metadata dictionary

    Returns:
        Content with updated frontmatter
    """

# Example
metadata, body = parse_frontmatter(content)
metadata["processed_date"] = "2024-01-01"
updated = update_frontmatter(content, metadata)
```

## Advanced Usage

### Custom Processing Pipeline

Create a custom processing pipeline:

```python
from cerebrate_file import CerebrasClient
from cerebrate_file.chunking import MarkdownChunker
from cerebrate_file.tokenizer import count_tokens
import os

class CustomProcessor:
    """Custom document processor."""

    def __init__(self, api_key: str):
        self.client = CerebrasClient(api_key)
        self.chunker = MarkdownChunker()

    def process_with_validation(self, input_path: str, output_path: str):
        """Process document with validation."""

        # Read input
        with open(input_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # Validate size
        tokens = count_tokens(content)
        if tokens > 100000:
            raise ValueError(f"Document too large: {tokens} tokens")

        # Create chunks
        chunks = self.chunker.split(content, max_tokens=32000)

        # Process each chunk
        results = []
        for chunk in chunks:
            response = self.client.create_completion(
                messages=[
                    {"role": "user", "content": chunk}
                ],
                max_tokens=32000
            )
            results.append(response)

        # Combine results
        output = "\n\n".join(results)

        # Write output
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(output)

        return output

# Usage
processor = CustomProcessor(api_key=os.getenv("CEREBRAS_API_KEY"))
processor.process_with_validation("input.md", "output.md")
```

### Batch Processing

Process multiple files programmatically:

```python
from cerebrate_file import process_document
from pathlib import Path
import concurrent.futures

def process_batch(file_paths: List[str], prompt: str, workers: int = 4):
    """Process multiple files in parallel."""

    def process_file(path):
        try:
            output_path = f"processed_{Path(path).name}"
            process_document(
                input_data=path,
                output_data=output_path,
                prompt=prompt
            )
            return f"âœ“ {path}"
        except Exception as e:
            return f"âœ— {path}: {e}"

    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:
        results = executor.map(process_file, file_paths)

    for result in results:
        print(result)

# Usage
files = Path(".").glob("*.md")
process_batch(list(files), "Improve clarity", workers=4)
```

### Error Handling

Implement robust error handling:

```python
from cerebrate_file import process_document
from cerebrate_file.exceptions import (
    APIError,
    RateLimitError,
    TokenLimitError,
    NetworkError
)
import time

def process_with_retry(input_path: str, max_retries: int = 3):
    """Process with automatic retry on failure."""

    for attempt in range(max_retries):
        try:
            return process_document(
                input_data=input_path,
                prompt="Process this document"
            )

        except RateLimitError as e:
            wait_time = 2 ** attempt * 60  # Exponential backoff
            print(f"Rate limited. Waiting {wait_time} seconds...")
            time.sleep(wait_time)

        except TokenLimitError as e:
            print(f"Token limit exceeded: {e}")
            # Try with smaller chunks
            return process_document(
                input_data=input_path,
                prompt="Process this document",
                chunk_size=16000  # Smaller chunks
            )

        except NetworkError as e:
            print(f"Network error: {e}")
            time.sleep(10)  # Brief wait

        except APIError as e:
            print(f"API error: {e}")
            raise  # Don't retry API errors

    raise Exception(f"Failed after {max_retries} attempts")

# Usage
try:
    result = process_with_retry("document.md")
    print("Success!")
except Exception as e:
    print(f"Failed: {e}")
```

### Custom Chunking

Implement custom chunking logic:

```python
from cerebrate_file.chunking import ChunkingStrategy
from typing import List

class CustomChunker(ChunkingStrategy):
    """Custom chunking implementation."""

    def split(self, text: str, max_tokens: int) -> List[str]:
        """Split by custom logic."""
        chunks = []

        # Split by double newlines (paragraphs)
        paragraphs = text.split("\n\n")

        current_chunk = ""
        for para in paragraphs:
            # Check if adding paragraph exceeds limit
            if len(current_chunk) + len(para) > max_tokens * 4:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = para
            else:
                current_chunk += "\n\n" + para if current_chunk else para

        if current_chunk:
            chunks.append(current_chunk.strip())

        return chunks

# Usage
chunker = CustomChunker()
chunks = chunker.split(document_text, max_tokens=8000)
```

## Integration Examples

### Flask Web App

Integrate with a Flask web application:

```python
from flask import Flask, request, jsonify
from cerebrate_file import process_document
import tempfile
import os

app = Flask(__name__)

@app.route('/process', methods=['POST'])
def process_endpoint():
    """Process document via API."""
    try:
        # Get file and prompt
        file = request.files['document']
        prompt = request.form.get('prompt', '')

        # Save temporarily
        with tempfile.NamedTemporaryFile(delete=False) as tmp:
            file.save(tmp.name)
            temp_path = tmp.name

        # Process
        result = process_document(
            input_data=temp_path,
            prompt=prompt
        )

        # Clean up
        os.unlink(temp_path)

        return jsonify({
            'success': True,
            'result': result
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

if __name__ == '__main__':
    app.run(debug=True)
```

### Jupyter Notebook

Use in Jupyter notebooks:

```python
# Cell 1: Setup
from cerebrate_file import process_document
import os

# Set API key
os.environ['CEREBRAS_API_KEY'] = 'csk-...'

# Cell 2: Process document
result = process_document(
    input_data='notebook_content.md',
    prompt='Summarize key points',
    verbose=True
)

# Cell 3: Display result
from IPython.display import Markdown
display(Markdown(result))
```

## Best Practices

1. **Error Handling**: Always wrap API calls in try-except blocks
2. **Rate Limiting**: Implement backoff and retry logic
3. **Token Management**: Check token counts before processing
4. **Memory Usage**: Process large batches in chunks
5. **API Key Security**: Never hardcode API keys
6. **Logging**: Use verbose mode for debugging
7. **Testing**: Test with small files first
8. **Validation**: Validate inputs before processing

## Next Steps

- Review [Examples](examples/) for practical usage
- Check [Troubleshooting](troubleshooting/) for common issues
- See [CLI Reference](cli-reference/) for command-line usage
- Explore [Configuration](configuration/) for optimization
</document_content>
</document>

<document index="17">
<source>docs/cli-reference.md</source>
<document_content>
---
layout: default
title: CLI Reference
nav_order: 4
---

# CLI Reference
{: .no_toc }

Complete reference for all command-line options
{: .fs-6 .fw-300 }

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## Synopsis

```bash
cerebrate-file INPUT_DATA [OPTIONS]
```

Process large documents by chunking for Cerebras zai-glm-4.6 model.

## Positional Arguments

### INPUT_DATA
{: .d-inline-block }

Required
{: .label .label-red }

Path to input file or directory to process.

- **Type**: String (file or directory path)
- **Required**: Yes
- **Examples**:
  - `document.md` - Single file
  - `.` - Current directory (with `--recurse`)
  - `/path/to/files` - Specific directory

## Optional Arguments

### Core Options

#### --output, -o OUTPUT_DATA

Path to output file or directory.

- **Type**: String (file or directory path)
- **Default**: Overwrites input file
- **Examples**:
  - `--output processed.md`
  - `-o ./output/`
  - `--output /tmp/results.txt`

When processing directories with `--recurse`, the output path should be a directory. The original directory structure will be replicated.

#### --prompt, -p PROMPT

Freeform instruction text for the AI model.

- **Type**: String
- **Default**: None
- **Examples**:
  - `--prompt "Summarize each section"`
  - `-p "Translate to Spanish"`
  - `--prompt "Add detailed comments"`

This is appended after any `--file_prompt` content with two newlines.

#### --file_prompt, -f FILE_PROMPT

Path to file containing instructions for the AI model.

- **Type**: String (file path)
- **Default**: None
- **Example**: `--file_prompt instructions.md`

Useful for complex or reusable instructions. The file content is loaded and used as the base prompt.

### Chunking Options

#### --chunk_size, -c CHUNK_SIZE

Target maximum input chunk size in tokens.

- **Type**: Integer
- **Default**: 32000
- **Range**: 1000 - 100000 (recommended: 16000 - 64000)
- **Examples**:
  - `--chunk_size 48000` - Larger chunks
  - `-c 16000` - Smaller chunks

Larger chunks preserve more context but may hit token limits. Smaller chunks process faster but may lose context.

#### --data_format DATA_FORMAT

Chunking strategy for different content types.

- **Type**: String
- **Default**: `markdown`
- **Options**:
  - `text` - Simple line-based splitting
  - `semantic` - Paragraph-aware splitting
  - `markdown` - Markdown structure-aware (headers, code blocks)
  - `code` - Code structure-aware (functions, classes)
- **Examples**:
  - `--data_format code` - For source files
  - `--data_format semantic` - For articles

#### --sample_size, -s SAMPLE_SIZE

Number of tokens for continuity examples between chunks.

- **Type**: Integer
- **Default**: 200
- **Range**: 0 - 1000
- **Examples**:
  - `--sample_size 500` - More context overlap
  - `-s 50` - Minimal overlap

Higher values maintain better continuity but reduce available tokens for new content.

#### --max_tokens_ratio MAX_TOKENS_RATIO

Completion budget as percentage of chunk size.

- **Type**: Integer
- **Default**: 100
- **Range**: 10 - 200
- **Examples**:
  - `--max_tokens_ratio 50` - Output half the input size
  - `--max_tokens_ratio 150` - Allow expansion

Controls how much output the model can generate per chunk.

### Recursive Processing Options

#### --recurse PATTERN

Enable recursive file processing with glob pattern.

- **Type**: String (glob pattern)
- **Default**: None (single file mode)
- **Examples**:
  - `--recurse "*.md"` - All markdown files in current directory
  - `--recurse "**/*.py"` - All Python files recursively
  - `--recurse "**/*.{js,ts}"` - Multiple extensions
  - `--recurse "src/**/*.txt"` - Specific subdirectory

Patterns support:
- `*` - Match any characters (except path separator)
- `**` - Match any characters including path separators
- `?` - Match single character
- `[seq]` - Match character in sequence
- `{opt1,opt2}` - Match any of the options

#### --workers WORKERS

Number of parallel workers for multi-file processing.

- **Type**: Integer
- **Default**: 4
- **Range**: 0 - 32
- **Special Values**:
  - `0` - Auto-detect based on CPU cores
  - `1` - Sequential processing
- **Examples**:
  - `--workers 8` - Use 8 parallel workers
  - `--workers 1` - Process files sequentially

More workers speed up processing but increase API request rate.

### Model Parameters

#### --model MODEL

Cerebras model to use.

- **Type**: String
- **Default**: `zai-glm-4.6`
- **Currently Supported**: `zai-glm-4.6`
- **Example**: `--model zai-glm-4.6`

#### --temp TEMP

Model temperature for response generation.

- **Type**: Float
- **Default**: 0.7
- **Range**: 0.0 - 2.0
- **Examples**:
  - `--temp 0.3` - More deterministic
  - `--temp 0.9` - More creative
  - `--temp 0.0` - Most deterministic

Higher values increase creativity and variation, lower values increase consistency.

#### --top_p TOP_P

Nucleus sampling parameter.

- **Type**: Float
- **Default**: 0.8
- **Range**: 0.0 - 1.0
- **Examples**:
  - `--top_p 0.9` - Wider token selection
  - `--top_p 0.5` - Narrower token selection

Controls diversity by limiting token selection to cumulative probability.

### Output Options

#### --verbose, -v

Enable detailed debug logging.

- **Type**: Boolean flag
- **Default**: False
- **Usage**: `--verbose` or `-v`

Shows:
- Token counts for each chunk
- API request/response details
- Rate limit information
- Processing timestamps
- Detailed error messages

#### --explain, -e

Enable metadata extraction and processing.

- **Type**: Boolean flag
- **Default**: False
- **Usage**: `--explain` or `-e`

Extracts/generates:
- Document title
- Author information
- Document ID
- Content type
- Date information

#### --dry_run

Perform chunking without making API calls.

- **Type**: Boolean flag
- **Default**: False
- **Usage**: `--dry_run`

Useful for:
- Testing chunk configurations
- Validating patterns
- Debugging issues
- Estimating costs

Shows chunk information and token counts without processing.

## Environment Variables

### CEREBRAS_API_KEY

Your Cerebras API key (required).

```bash
export CEREBRAS_API_KEY="csk-..."
```

Can also be set in a `.env` file in the current directory.

### HTTP_PROXY / HTTPS_PROXY

Optional proxy configuration.

```bash
export HTTPS_PROXY="http://proxy.example.com:8080"
```

## Exit Codes

- **0**: Success
- **1**: General error
- **2**: Invalid arguments
- **3**: API key not found
- **4**: File not found
- **5**: Permission denied
- **6**: API error
- **7**: Rate limit exceeded
- **8**: Network error

## Examples

### Basic Processing

```bash
# Simple processing
cerebrate-file document.md

# With output file
cerebrate-file input.txt --output output.txt

# With instructions
cerebrate-file report.md --prompt "Summarize to 500 words"
```

### Advanced Processing

```bash
# Complex instructions from file
cerebrate-file thesis.md \
  --file_prompt style_guide.md \
  --prompt "Also fix grammar" \
  --output edited_thesis.md

# Optimized for code
cerebrate-file app.py \
  --data_format code \
  --chunk_size 24000 \
  --prompt "Add type hints"
```

### Recursive Processing

```bash
# Process all markdown files
cerebrate-file . \
  --output ./processed \
  --recurse "**/*.md" \
  --workers 8

# Process specific patterns
cerebrate-file ./src \
  --output ./docs \
  --recurse "**/*.{js,jsx,ts,tsx}" \
  --prompt "Generate JSDoc comments"
```

### Fine-tuning

```bash
# High-quality processing
cerebrate-file important.md \
  --chunk_size 48000 \
  --sample_size 500 \
  --temp 0.3 \
  --top_p 0.7

# Fast processing
cerebrate-file large_file.txt \
  --chunk_size 16000 \
  --sample_size 100 \
  --max_tokens_ratio 50
```

### Debugging

```bash
# Test configuration
cerebrate-file huge.md \
  --dry_run \
  --verbose \
  --chunk_size 32000

# Detailed logging
cerebrate-file problem.md \
  --verbose \
  --output debug.md
```

## Rate Limits

Cerebras API has the following limits:

- **Per Minute**: 30 requests, 10M tokens
- **Per Day**: 1000 requests

The tool automatically handles rate limiting with:
- Exponential backoff
- Automatic retry
- Clear status messages
- Remaining quota display

## Performance Tips

1. **Chunk Size**: Larger chunks (48K-64K) preserve context better
2. **Workers**: Use 4-8 workers for optimal throughput
3. **Sample Size**: 200-500 tokens usually sufficient
4. **Data Format**: Match format to content type
5. **Temperature**: Lower values (0.3-0.5) for consistency

## Troubleshooting

### Common Issues

**API Key not found:**
```bash
export CEREBRAS_API_KEY="csk-your-key"
```

**Rate limit exceeded:**
- Wait for limit reset
- Reduce `--workers` count
- Process in smaller batches

**Out of memory:**
- Reduce `--chunk_size`
- Process fewer files at once
- Close other applications

**Network errors:**
- Check internet connection
- Verify proxy settings
- Try with `--verbose` for details

## See Also

- [Usage Guide](usage/) - Detailed usage examples
- [Configuration](configuration/) - Configuration options
- [Examples](examples/) - Real-world examples
- [API Reference](api-reference/) - Python API documentation
</document_content>
</document>

<document index="18">
<source>docs/configuration.md</source>
<document_content>
---
layout: default
title: Configuration
nav_order: 5
---

# Configuration
{: .no_toc }

Configure Cerebrate File for optimal performance
{: .fs-6 .fw-300 }

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## Environment Configuration

### API Key Setup

The Cerebras API key is the only required configuration:

```bash
# Option 1: Environment variable
export CEREBRAS_API_KEY="csk-your-api-key-here"

# Option 2: .env file
echo 'CEREBRAS_API_KEY=csk-your-api-key-here' > .env

# Option 3: Shell configuration file
echo 'export CEREBRAS_API_KEY="csk-your-api-key-here"' >> ~/.bashrc
source ~/.bashrc
```

### Security Best Practices

1. **Never commit API keys**:
   ```bash
   # Add to .gitignore
   echo ".env" >> .gitignore
   echo "*.key" >> .gitignore
   ```

2. **Use secure storage**:
   ```bash
   # macOS Keychain
   security add-generic-password -a "$USER" -s "CEREBRAS_API_KEY" -w "csk-..."

   # Linux Secret Service
   secret-tool store --label="Cerebras API Key" api cerebras
   ```

3. **Restrict file permissions**:
   ```bash
   chmod 600 .env
   ```

## Chunking Configuration

### Optimal Chunk Sizes by Content Type

| Content Type | Recommended Size | Sample Size | Format |
|-------------|-----------------|-------------|---------|
| **Documentation** | 32,000 | 200 | markdown |
| **Source Code** | 24,000 | 300 | code |
| **Articles** | 48,000 | 400 | semantic |
| **Data/CSV** | 16,000 | 100 | text |
| **Books/Novels** | 64,000 | 500 | semantic |

### Chunking Strategy Selection

```bash
# Documentation with structure preservation
cerebrate-file docs.md \
  --data_format markdown \
  --chunk_size 32000 \
  --sample_size 200

# Code with function boundaries
cerebrate-file app.py \
  --data_format code \
  --chunk_size 24000 \
  --sample_size 300

# Natural text with semantic breaks
cerebrate-file article.txt \
  --data_format semantic \
  --chunk_size 48000 \
  --sample_size 400
```

## Model Parameters

### Temperature Guidelines

| Use Case | Temperature | Description |
|----------|------------|-------------|
| **Technical Documentation** | 0.3 | High consistency, minimal variation |
| **Code Generation** | 0.4 | Reliable, predictable output |
| **General Content** | 0.7 | Balanced creativity and coherence |
| **Creative Writing** | 0.9 | Maximum creativity and variety |
| **Translations** | 0.5 | Accurate with some flexibility |

### Top-p Recommendations

| Use Case | Top-p | Effect |
|----------|-------|--------|
| **Formal Writing** | 0.7 | Focused vocabulary |
| **Technical Content** | 0.75 | Balanced selection |
| **General Purpose** | 0.8 | Default setting |
| **Creative Content** | 0.95 | Diverse vocabulary |

### Combined Settings Examples

```bash
# Technical documentation
cerebrate-file manual.md \
  --temp 0.3 \
  --top_p 0.7 \
  --prompt "Improve clarity and accuracy"

# Creative rewriting
cerebrate-file story.md \
  --temp 0.9 \
  --top_p 0.95 \
  --prompt "Make it more engaging"

# Code documentation
cerebrate-file src/main.py \
  --temp 0.4 \
  --top_p 0.75 \
  --prompt "Add comprehensive docstrings"
```

## Performance Optimization

### Worker Configuration

Optimal worker counts for different scenarios:

```bash
# CPU-bound (many small files)
cerebrate-file . --recurse "**/*.md" --workers 8

# I/O-bound (few large files)
cerebrate-file . --recurse "**/*.pdf.txt" --workers 4

# Memory-constrained systems
cerebrate-file . --recurse "**/*" --workers 2

# Auto-detect optimal count
cerebrate-file . --recurse "**/*.py" --workers 0
```

### Memory Management

For systems with limited memory:

```bash
# Reduce memory usage
cerebrate-file large.md \
  --chunk_size 16000 \
  --workers 2 \
  --max_tokens_ratio 50

# Process files sequentially
cerebrate-file . \
  --recurse "**/*.txt" \
  --workers 1
```

### Network Optimization

For slow or unreliable connections:

```bash
# Smaller chunks for faster requests
cerebrate-file doc.md \
  --chunk_size 16000 \
  --verbose  # Monitor progress

# Use proxy if available
export HTTPS_PROXY="http://proxy:8080"
cerebrate-file doc.md
```

## File Organization

### Project Structure

Recommended directory structure:

```
project/
â”œâ”€â”€ input/              # Original files
â”‚   â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ data/
â”œâ”€â”€ output/             # Processed files
â”‚   â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ data/
â”œâ”€â”€ prompts/            # Reusable instruction files
â”‚   â”œâ”€â”€ summarize.md
â”‚   â”œâ”€â”€ translate_es.md
â”‚   â””â”€â”€ add_comments.md
â”œâ”€â”€ .env                # API key (git-ignored)
â””â”€â”€ .gitignore
```

### Prompt Library

Create reusable instruction files:

```bash
# Create prompt library
mkdir prompts

# Save common instructions
cat > prompts/summarize.md << 'EOF'
Create a concise summary following these guidelines:
- Maximum 500 words
- Bullet points for key concepts
- Preserve technical accuracy
- Include main conclusions
EOF

# Use saved prompts
cerebrate-file report.md \
  --file_prompt prompts/summarize.md \
  --output summaries/report.md
```

## Batch Processing Configuration

### Shell Scripts

Create processing scripts for common tasks:

```bash
#!/bin/bash
# process_docs.sh

# Configuration
INPUT_DIR="./docs"
OUTPUT_DIR="./processed"
PROMPT_FILE="./prompts/improve.md"
WORKERS=4

# Process all markdown files
cerebrate-file "$INPUT_DIR" \
  --output "$OUTPUT_DIR" \
  --recurse "**/*.md" \
  --file_prompt "$PROMPT_FILE" \
  --workers "$WORKERS" \
  --chunk_size 32000 \
  --temp 0.5
```

### Makefiles

Use Make for complex workflows:

```makefile
# Makefile

.PHONY: docs code all clean

# Variables
OUTPUT_DIR = processed
WORKERS = 4

# Process documentation
docs:
	cerebrate-file ./docs \
		--output $(OUTPUT_DIR)/docs \
		--recurse "**/*.md" \
		--file_prompt prompts/doc_style.md \
		--workers $(WORKERS)

# Process code
code:
	cerebrate-file ./src \
		--output $(OUTPUT_DIR)/src \
		--recurse "**/*.py" \
		--prompt "Add type hints and docstrings" \
		--data_format code \
		--workers $(WORKERS)

# Process everything
all: docs code

# Clean output
clean:
	rm -rf $(OUTPUT_DIR)
```

## Advanced Configuration

### Custom Aliases

Add to your shell configuration:

```bash
# ~/.bashrc or ~/.zshrc

# Alias for common operations
alias cf='cerebrate-file'
alias cf-docs='cerebrate-file --data_format markdown --chunk_size 32000'
alias cf-code='cerebrate-file --data_format code --chunk_size 24000'
alias cf-dry='cerebrate-file --dry_run --verbose'

# Function for recursive processing
cf-recursive() {
    cerebrate-file . \
        --output ./processed \
        --recurse "$1" \
        --workers 4 \
        "${@:2}"
}
```

### Configuration File (Future Feature)

Planned support for configuration files:

```yaml
# .cerebrate.yml (planned)
defaults:
  chunk_size: 32000
  sample_size: 200
  workers: 4
  temp: 0.7
  top_p: 0.8

profiles:
  documentation:
    data_format: markdown
    chunk_size: 32000
    temp: 0.5

  code:
    data_format: code
    chunk_size: 24000
    temp: 0.4

  creative:
    data_format: semantic
    temp: 0.9
    top_p: 0.95
```

## Monitoring and Logging

### Verbose Output

Configure logging levels:

```bash
# Maximum verbosity
cerebrate-file doc.md --verbose

# Redirect logs to file
cerebrate-file doc.md --verbose 2> process.log

# Separate stdout and stderr
cerebrate-file doc.md --verbose \
  1> output.txt \
  2> errors.log
```

### Progress Monitoring

Track processing progress:

```bash
# Watch output directory
watch -n 1 'ls -la ./output | tail -10'

# Monitor API calls
cerebrate-file doc.md --verbose | grep "Rate limit"

# Count processed files
find ./output -type f | wc -l
```

## Rate Limit Management

### Daily Planning

Calculate your daily capacity:

- **Daily limit**: 1000 requests
- **Average chunks per file**: ~5-10
- **Files per day**: ~100-200

### Strategies for High Volume

```bash
# Process in batches
find . -name "*.md" | head -100 | xargs -I {} \
  cerebrate-file {} --output processed/{}

# Add delays between batches
for batch in batch1 batch2 batch3; do
  cerebrate-file $batch --recurse "*.txt"
  sleep 300  # 5-minute delay
done

# Split across multiple days
cerebrate-file . --recurse "**/*.md[a-m]*"  # Day 1
cerebrate-file . --recurse "**/*.md[n-z]*"  # Day 2
```

## Troubleshooting Configuration

### Debug Mode

Enable maximum debugging:

```bash
# Set environment variables
export CEREBRATE_DEBUG=1
export LOGURU_LEVEL=DEBUG

# Run with verbose output
cerebrate-file test.md \
  --verbose \
  --dry_run
```

### Testing Configuration

Verify your setup:

```bash
# Test API connection
echo "test" | cerebrate-file - --prompt "Reply with 'OK'"

# Test chunking
cerebrate-file sample.md --dry_run --verbose

# Test rate limits
cerebrate-file small.txt --verbose | grep "Remaining"
```

## Best Practices Summary

1. **Always use appropriate chunk sizes** for your content type
2. **Set temperature based on desired consistency**
3. **Organize prompts in reusable files**
4. **Monitor rate limits** to avoid disruption
5. **Use workers wisely** based on system resources
6. **Create scripts** for repeated workflows
7. **Keep API keys secure** and never commit them
8. **Test with dry runs** before processing large batches

## Next Steps

- Review [CLI Reference](cli-reference/) for all options
- Explore [Examples](examples/) for specific use cases
- Check [Troubleshooting](troubleshooting/) for common issues
- See [API Reference](api-reference/) for programmatic access
</document_content>
</document>

<document index="19">
<source>docs/development.md</source>
<document_content>
---
layout: default
title: Development
nav_order: 9
---

# Development
{: .no_toc }

Contributing to Cerebrate File development
{: .fs-6 .fw-300 }

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## Getting Started

### Prerequisites

- Python 3.9+ (recommended: 3.12)
- uv package manager
- Git
- GitHub account (for contributions)

### Setting Up Development Environment

1. **Clone the repository:**
   ```bash
   git clone https://github.com/twardoch/cerebrate-file.git
   cd cerebrate-file
   ```

2. **Create virtual environment:**
   ```bash
   uv venv --python 3.12
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   uv pip install -e .
   uv add --dev pytest pytest-cov pytest-mock rich loguru
   ```

4. **Set up pre-commit hooks (optional but recommended):**
   ```bash
   uv add --dev pre-commit
   pre-commit install
   ```

## Project Structure

```
cerebrate-file/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ cerebrate_file/
â”‚       â”œâ”€â”€ __init__.py         # Package initialization
â”‚       â”œâ”€â”€ cli.py              # CLI interface
â”‚       â”œâ”€â”€ api_client.py       # Cerebras API client
â”‚       â”œâ”€â”€ cerebrate_file.py   # Core processing logic
â”‚       â”œâ”€â”€ chunking.py         # Chunking strategies
â”‚       â”œâ”€â”€ config.py           # Configuration management
â”‚       â”œâ”€â”€ constants.py        # Constants and defaults
â”‚       â”œâ”€â”€ models.py           # Data models
â”‚       â”œâ”€â”€ recursive.py        # Recursive processing
â”‚       â”œâ”€â”€ tokenizer.py        # Token counting
â”‚       â”œâ”€â”€ ui.py              # UI components
â”‚       â””â”€â”€ utils.py           # Utility functions
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api_client.py     # API client tests
â”‚   â”œâ”€â”€ test_chunking.py       # Chunking tests
â”‚   â”œâ”€â”€ test_cli.py            # CLI tests
â”‚   â”œâ”€â”€ test_config.py         # Configuration tests
â”‚   â”œâ”€â”€ test_integration.py    # Integration tests
â”‚   â”œâ”€â”€ test_recursive.py      # Recursive processing tests
â”‚   â””â”€â”€ test_ui.py             # UI component tests
â”œâ”€â”€ docs/                      # Documentation (Jekyll)
â”œâ”€â”€ examples/                  # Example scripts
â”œâ”€â”€ pyproject.toml             # Package configuration
â”œâ”€â”€ README.md                  # Project README
â”œâ”€â”€ CHANGELOG.md               # Version history
â”œâ”€â”€ LICENSE                    # Apache 2.0 license
â””â”€â”€ .gitignore                 # Git ignore rules
```

## Development Workflow

### 1. Create a Feature Branch

```bash
git checkout -b feature/your-feature-name
```

### 2. Make Changes

Follow the coding standards and guidelines below.

### 3. Write Tests

Every new feature must have tests:

```python
# tests/test_your_feature.py
import pytest
from cerebrate_file.your_module import your_function

def test_your_function():
    """Test basic functionality."""
    result = your_function("input")
    assert result == "expected"

def test_your_function_edge_case():
    """Test edge cases."""
    with pytest.raises(ValueError):
        your_function(None)
```

### 4. Run Tests

```bash
# Run all tests
python -m pytest

# Run with coverage
python -m pytest --cov=cerebrate_file --cov-report=term-missing

# Run specific test file
python -m pytest tests/test_your_feature.py -xvs

# Run tests in watch mode
uvx pytest-watch
```

### 5. Check Code Quality

```bash
# Format code
uvx ruff format src/ tests/

# Lint code
uvx ruff check src/ tests/ --fix

# Type checking
uvx mypy src/cerebrate_file

# Security scan
uvx bandit -r src/
```

### 6. Update Documentation

- Update relevant documentation in `docs/`
- Update README.md if needed
- Add to CHANGELOG.md

### 7. Commit Changes

```bash
git add .
git commit -m "feat: add your feature description"
```

Use conventional commits:
- `feat:` New feature
- `fix:` Bug fix
- `docs:` Documentation
- `style:` Formatting
- `refactor:` Code restructuring
- `test:` Tests
- `chore:` Maintenance

### 8. Push and Create PR

```bash
git push origin feature/your-feature-name
```

Then create a pull request on GitHub.

## Coding Standards

### Python Style Guide

Follow PEP 8 with these specifics:

```python
# this_file: src/cerebrate_file/example.py
"""Module docstring describing purpose."""

from typing import Optional, List, Dict
from pathlib import Path

# Constants in UPPER_CASE
DEFAULT_CHUNK_SIZE = 32000
MAX_RETRIES = 3

class ExampleClass:
    """Class docstring with description."""

    def __init__(self, param: str) -> None:
        """Initialize with parameter."""
        self.param = param

    def process(self, data: str) -> str:
        """
        Process data with clear description.

        Args:
            data: Input data to process

        Returns:
            Processed result

        Raises:
            ValueError: If data is invalid
        """
        if not data:
            raise ValueError("Data cannot be empty")

        # Clear comment explaining logic
        result = self._transform(data)
        return result

    def _transform(self, data: str) -> str:
        """Private method with underscore prefix."""
        return data.upper()
```

### Type Hints

Always use type hints:

```python
from typing import Optional, List, Dict, Union, Tuple

def process_files(
    paths: List[Path],
    options: Optional[Dict[str, str]] = None
) -> Tuple[List[str], List[str]]:
    """Process multiple files."""
    successes: List[str] = []
    failures: List[str] = []

    for path in paths:
        try:
            result = process_single(path, options or {})
            successes.append(result)
        except Exception as e:
            failures.append(str(e))

    return successes, failures
```

### Error Handling

Use specific exceptions:

```python
class CerebrateError(Exception):
    """Base exception for cerebrate-file."""
    pass

class ConfigurationError(CerebrateError):
    """Configuration related errors."""
    pass

class APIError(CerebrateError):
    """API related errors."""
    pass

def validate_config(config: Dict) -> None:
    """Validate configuration."""
    if not config.get("api_key"):
        raise ConfigurationError("API key is required")

    if config.get("chunk_size", 0) < 1000:
        raise ConfigurationError("Chunk size must be at least 1000")
```

### Logging

Use loguru for logging:

```python
from loguru import logger

def process_document(path: str, verbose: bool = False) -> str:
    """Process document with logging."""
    if verbose:
        logger.enable("cerebrate_file")
    else:
        logger.disable("cerebrate_file")

    logger.debug(f"Processing {path}")

    try:
        result = do_processing(path)
        logger.info(f"Successfully processed {path}")
        return result
    except Exception as e:
        logger.error(f"Failed to process {path}: {e}")
        raise
```

### Documentation

Write comprehensive docstrings:

```python
def complex_function(
    input_data: str,
    chunk_size: int = 32000,
    strategy: str = "markdown"
) -> List[str]:
    """
    Split input data into processable chunks.

    This function takes large input data and splits it into smaller
    chunks suitable for processing by the AI model. It maintains
    context between chunks using overlap samples.

    Args:
        input_data: The raw input text to be chunked
        chunk_size: Maximum size of each chunk in tokens (default: 32000)
        strategy: Chunking strategy - 'text', 'semantic', 'markdown', or 'code'

    Returns:
        List of text chunks ready for processing

    Raises:
        ValueError: If input_data is empty or strategy is invalid
        TokenLimitError: If a single unit exceeds chunk_size

    Examples:
        >>> chunks = complex_function("Long text...", chunk_size=16000)
        >>> len(chunks)
        3

        >>> chunks = complex_function("# Markdown", strategy="markdown")
        >>> chunks[0].startswith("#")
        True

    Note:
        The actual chunk size may be slightly smaller than specified
        to avoid breaking in the middle of sentences or code blocks.
    """
```

## Testing Guidelines

### Test Structure

```python
import pytest
from unittest.mock import Mock, patch
from cerebrate_file.module import function_to_test

class TestFeatureName:
    """Test suite for feature."""

    def setup_method(self):
        """Set up test fixtures."""
        self.test_data = "sample"

    def test_normal_case(self):
        """Test normal operation."""
        result = function_to_test(self.test_data)
        assert result == "expected"

    def test_edge_case(self):
        """Test edge cases."""
        assert function_to_test("") == ""
        assert function_to_test(None) is None

    @pytest.mark.parametrize("input,expected", [
        ("test1", "result1"),
        ("test2", "result2"),
        ("test3", "result3"),
    ])
    def test_multiple_cases(self, input, expected):
        """Test multiple scenarios."""
        assert function_to_test(input) == expected

    def test_error_handling(self):
        """Test error conditions."""
        with pytest.raises(ValueError, match="Invalid input"):
            function_to_test("invalid")

    @patch('cerebrate_file.module.external_function')
    def test_with_mock(self, mock_func):
        """Test with mocked dependencies."""
        mock_func.return_value = "mocked"
        result = function_to_test("input")
        mock_func.assert_called_once_with("input")
        assert result == "mocked"
```

### Integration Tests

```python
# tests/test_integration.py
import tempfile
from pathlib import Path
from cerebrate_file import process_document

def test_end_to_end_processing():
    """Test complete processing pipeline."""
    with tempfile.TemporaryDirectory() as tmpdir:
        # Create test file
        input_file = Path(tmpdir) / "test.md"
        input_file.write_text("# Test\nContent")

        # Process
        output_file = Path(tmpdir) / "output.md"
        process_document(
            input_data=str(input_file),
            output_data=str(output_file),
            prompt="Add emoji"
        )

        # Verify
        assert output_file.exists()
        content = output_file.read_text()
        assert "Test" in content
```

## Performance Optimization

### Profiling

```python
import cProfile
import pstats
from io import StringIO

def profile_function():
    """Profile function performance."""
    profiler = cProfile.Profile()
    profiler.enable()

    # Code to profile
    result = expensive_function()

    profiler.disable()
    stream = StringIO()
    stats = pstats.Stats(profiler, stream=stream)
    stats.sort_stats('cumulative')
    stats.print_stats(10)
    print(stream.getvalue())

    return result
```

### Memory Optimization

```python
from memory_profiler import profile

@profile
def memory_intensive_function():
    """Monitor memory usage."""
    # Process in chunks to reduce memory
    for chunk in generate_chunks(large_data):
        process_chunk(chunk)
        del chunk  # Explicit cleanup

def generate_chunks(data, chunk_size=1000):
    """Generator to avoid loading all data."""
    for i in range(0, len(data), chunk_size):
        yield data[i:i + chunk_size]
```

## Release Process

### 1. Update Version

Edit `pyproject.toml`:
```toml
[project]
version = "1.1.0"
```

### 2. Update Changelog

Add to `CHANGELOG.md`:
```markdown
## [1.1.0] - 2024-01-15

### Added
- New feature description

### Changed
- Modified behavior

### Fixed
- Bug fixes
```

### 3. Run Tests

```bash
python -m pytest --cov=cerebrate_file
```

### 4. Build Package

```bash
uv build
```

### 5. Test Package

```bash
uv pip install dist/cerebrate_file-1.1.0-py3-none-any.whl
cerebrate-file --version
```

### 6. Tag Release

```bash
git tag -a v1.1.0 -m "Release version 1.1.0"
git push origin v1.1.0
```

### 7. Publish to PyPI

```bash
uv publish
```

## Contributing Guidelines

### Code of Conduct

- Be respectful and inclusive
- Welcome newcomers
- Focus on constructive feedback
- Report inappropriate behavior

### Pull Request Process

1. **Fork** the repository
2. **Create** feature branch
3. **Write** tests for new code
4. **Ensure** all tests pass
5. **Update** documentation
6. **Submit** pull request

### Pull Request Template

```markdown
## Description
Brief description of changes

## Type of Change
- [ ] Bug fix
- [ ] New feature
- [ ] Breaking change
- [ ] Documentation update

## Testing
- [ ] Tests pass locally
- [ ] Added new tests
- [ ] Coverage maintained

## Checklist
- [ ] Code follows style guidelines
- [ ] Self-reviewed code
- [ ] Updated documentation
- [ ] Added to CHANGELOG.md
```

## Debugging Tips

### Using pdb

```python
import pdb

def debug_function(data):
    """Debug with pdb."""
    pdb.set_trace()  # Breakpoint
    result = process(data)
    return result
```

### Verbose Logging

```python
from loguru import logger
import sys

# Configure detailed logging
logger.remove()
logger.add(
    sys.stderr,
    format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
    level="DEBUG"
)
```

### Environment Variables

```bash
# Enable debug mode
export CEREBRATE_DEBUG=1
export LOGURU_LEVEL=DEBUG

# Run with debugging
python -m cerebrate_file.cli --verbose
```

## Resources

### Documentation
- [Python Packaging Guide](https://packaging.python.org)
- [pytest Documentation](https://docs.pytest.org)
- [Type Hints PEP 484](https://www.python.org/dev/peps/pep-0484/)

### Tools
- [uv](https://github.com/astral-sh/uv) - Fast Python package manager
- [ruff](https://github.com/charliermarsh/ruff) - Fast Python linter
- [mypy](http://mypy-lang.org/) - Static type checker
- [pre-commit](https://pre-commit.com/) - Git hook framework

### Community
- [GitHub Discussions](https://github.com/twardoch/cerebrate-file/discussions)
- [Issue Tracker](https://github.com/twardoch/cerebrate-file/issues)
- [Pull Requests](https://github.com/twardoch/cerebrate-file/pulls)

## License

By contributing, you agree that your contributions will be licensed under the Apache 2.0
</document_content>
</document>

<document index="20">
<source>docs/examples.md</source>
<document_content>
---
layout: default
title: Examples
nav_order: 6
has_children: true
---

# Examples
{: .no_toc }

Practical use cases for Cerebrate File

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## Documentation Processing

### README Enhancement

```bash
# Add structure and clarity
cerebrate-file README.md \
  --prompt "Add relevant emojis to headers, improve clarity, and ensure all sections are complete" \
  --output README_enhanced.md

# Generate from notes
cerebrate-file project_notes.txt \
  --prompt "Convert to well-structured README with sections: Overview, Installation, Usage, API, Contributing" \
  --output README.md
```

### API Documentation Generation

```bash
# From Python code
cerebrate-file api.py \
  --data_format code \
  --prompt "Extract all functions and classes, generate markdown API documentation with examples" \
  --output api_docs.md

# From multiple files
cerebrate-file ./src \
  --recurse "**/*.py" \
  --prompt "Generate comprehensive API documentation in markdown format" \
  --output ./docs/api/
```

### Changelog Generation

```bash
# From git log
git log --oneline -n 50 > commits.txt
cerebrate-file commits.txt \
  --prompt "Generate a CHANGELOG.md with sections: Added, Changed, Fixed, Removed" \
  --output CHANGELOG.md

# Update existing
cerebrate-file CHANGELOG.md \
  --file_prompt new_features.txt \
  --prompt "Add these features to the Unreleased section"
```

## Code Transformation

### Adding Type Hints

```bash
# Single file
cerebrate-file utils.py \
  --data_format code \
  --prompt "Add comprehensive type hints to all functions and methods" \
  --chunk_size 24000

# Entire codebase
cerebrate-file ./src \
  --recurse "**/*.py" \
  --prompt "Add type hints following PEP 484, use Union types where appropriate" \
  --output ./typed_src/
```

### Code Refactoring

```bash
# Modernize syntax
cerebrate-file legacy.py \
  --data_format code \
  --prompt "Refactor to use modern Python features: f-strings, pathlib, dataclasses, type hints" \
  --output modern.py

# Apply patterns
cerebrate-file service.py \
  --prompt "Refactor using dependency injection and repository pattern" \
  --temp 0.4  # Lower temp for consistency
```

### Test Generation

```bash
# Generate tests
cerebrate-file calculator.py \
  --data_format code \
  --prompt "Generate comprehensive pytest test cases with edge cases and fixtures" \
  --output test_calculator.py

# Extend existing tests
cerebrate-file test_utils.py \
  --prompt "Add edge case tests for error conditions and boundary values"
```

## Content Transformation

### Translation

```bash
# Single document
cerebrate-file article.md \
  --prompt "Translate to Spanish, preserve all markdown formatting and code blocks" \
  --output articulo.md

# Batch process
cerebrate-file ./content/en \
  --recurse "**/*.md" \
  --prompt "Translate to French, maintain technical terms in English with translations in parentheses" \
  --output ./content/fr/
```

### Summarization

```bash
# Executive summary
cerebrate-file report.pdf.txt \
  --prompt "Create executive summary: 500 words max, bullet points for key findings, action items section" \
  --output summary.md

# Chapter summaries
cerebrate-file book.md \
  --data_format semantic \
  --chunk_size 48000 \
  --prompt "Summarize each chapter in 200 words, maintain narrative flow" \
  --output chapter_summaries.md
```

### Style Transformation

```bash
# Technical to plain English
cerebrate-file technical_manual.md \
  --prompt "Rewrite for general audience, explain technical terms, use analogies" \
  --output user_guide.md

# Formal to conversational
cerebrate-file formal_report.md \
  --prompt "Rewrite in conversational tone, add examples, use 'you' and 'we'" \
  --temp 0.8  # Higher temp for variety
```

## Data Processing

### CSV/JSON Processing

```bash
# CSV to markdown
cerebrate-file data.csv \
  --data_format text \
  --prompt "Convert to markdown table with proper formatting, add summary statistics" \
  --output data_table.md

# JSON to docs
cerebrate-file api_spec.json \
  --prompt "Generate human-readable API documentation with examples for each endpoint" \
  --output api_guide.md
```

### Log Analysis

```bash
# Error patterns
cerebrate-file app.log \
  --data_format text \
  --chunk_size 32000 \
  --prompt "Identify error patterns, group by type, suggest fixes" \
  --output error_report.md

# Performance issues
cerebrate-file performance.log \
  --prompt "Analyze response times, identify bottlenecks, create optimization recommendations" \
  --output performance_analysis.md
```

### Report Generation

```bash
# Sales data
cerebrate-file sales_data.txt \
  --file_prompt report_template.md \
  --prompt "Generate quarterly sales report with trends, visualizations descriptions, and recommendations" \
  --output Q4_report.md

# Technical debt
cerebrate-file codebase_analysis.txt \
  --prompt "Generate technical debt report: categorize issues, estimate effort, prioritize fixes" \
  --output tech_debt_report.md
```

## Academic and Research

### Paper Formatting

```bash
# Academic style
cerebrate-file draft.md \
  --prompt "Format as academic paper: add abstract, improve citations, use formal language" \
  --output paper.md

# Add references
cerebrate-file research.md \
  --file_prompt bibliography.bib \
  --prompt "Add proper citations in APA format, create references section"
```

### Literature Review

```bash
# Extract key info
cerebrate-file ./papers \
  --recurse "**/*.txt" \
  --prompt "Extract: main hypothesis, methodology, key findings, limitations" \
  --output ./summaries/

# Compile review
cat summaries/*.md > all_summaries.md
cerebrate-file all_summaries.md \
  --prompt "Create comprehensive literature review with themes, gaps, and future directions" \
  --output literature_review.md
```

### Note Organization

```bash
# Structure notes
cerebrate-file scattered_notes.txt \
  --prompt "Organize into sections: Key Concepts, Methodologies, Findings, Questions" \
  --output organized_notes.md

# Study guide
cerebrate-file lecture_notes.md \
  --prompt "Create study guide: key terms with definitions, important formulas, practice questions" \
  --output study_guide.md
```

## Creative Projects

### Story Development

```bash
# Character profiles
cerebrate-file character_sketches.txt \
  --prompt "Expand character profiles: add backstory, motivations, character arcs" \
  --temp 0.9 \
  --output characters.md

# Better dialogue
cerebrate-file story.md \
  --data_format semantic \
  --prompt "Improve dialogue: make it more natural, add subtext, vary speech patterns" \
  --temp 0.8
```

### Content Expansion

```bash
# Blog post
cerebrate-file outline.md \
  --prompt "Expand each point into 2-3 paragraphs with examples and transitions" \
  --max_tokens_ratio 200 \
  --output full_post.md

# Course material
cerebrate-file course_outline.md \
  --prompt "Expand into full course: add learning objectives, exercises, quizzes for each module" \
  --output course_content.md
```

## DevOps and Configuration

### Configuration Generation

```bash
# Docker setup
cerebrate-file app_requirements.txt \
  --prompt "Generate Dockerfile and docker-compose.yml for Python web application" \
  --output docker_configs.md

# CI/CD pipeline
cerebrate-file project_info.md \
  --prompt "Generate GitHub Actions workflow for Python project with tests, linting, and deployment" \
  --output .github/workflows/ci.yml
```

### Documentation from Code

```bash
# Terraform docs
cerebrate-file ./terraform \
  --recurse "**/*.tf" \
  --prompt "Generate infrastructure documentation with resource descriptions and dependencies" \
  --output infrastructure.md

# Kubernetes docs
cerebrate-file ./k8s \
  --recurse "**/*.yaml" \
  --prompt "Document Kubernetes resources: purpose, configuration, relationships" \
  --output k8s_docs.md
```

## Batch Processing Examples

### Sequential Processing

```bash
#!/bin/bash
# process_sequential.sh

for file in *.md; do
  echo "Processing $file..."
  cerebrate-file "$file" \
    --file_prompt standard_prompt.md \
    --output "processed/${file}"
  sleep 2
done
```

### Parallel Processing

```bash
# GNU parallel
find . -name "*.txt" | parallel -j 4 \
  cerebrate-file {} --output processed/{/}

# Built-in parallel
cerebrate-file . \
  --recurse "**/*.md" \
  --workers 8 \
  --file_prompt instructions.md \
  --output ./processed/
```

### Conditional Processing

```bash
#!/bin/bash
# smart_process.sh

for file in *.md; do
  size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file")

  if [ $size -lt 10000 ]; then
    chunk_size=16000
  elif [ $size -lt 100000 ]; then
    chunk_size=32000
  else
    chunk_size=48000
  fi

  cerebrate-file "$file" \
    --chunk_size $chunk_size \
    --output "processed/${file}"
done
```

## Complex Workflows

### Multi-Stage Processing

```bash
#!/bin/bash
# multi_stage.sh

# Stage 1: Clean data
cerebrate-file raw_data.txt \
  --prompt "Extract relevant information, fix formatting" \
  --output stage1.md

# Stage 2: Analyze
cerebrate-file stage1.md \
  --prompt "Analyze patterns, identify trends, add insights" \
  --output stage2.md

# Stage 3: Report
cerebrate-file stage2.md \
  --file_prompt report_template.md \
  --prompt "Format as executive report with recommendations" \
  --output final_report.md
```

### Content Pipeline

```bash
#!/bin/bash
# content_pipeline.sh

SOURCE_DIR="content/drafts"
EDIT_DIR="content/edited"
TRANS_DIR="content/translated"
FINAL_DIR="content/final"

# Edit content
cerebrate-file "$SOURCE_DIR" \
  --recurse "**/*.md" \
  --prompt "Improve clarity, fix grammar, enhance structure" \
  --output "$EDIT_DIR" \
  --workers 4

# Translate
cerebrate-file "$EDIT_DIR" \
  --recurse "**/*.md" \
  --prompt "Translate to Spanish, preserve formatting" \
  --output "$TRANS_DIR" \
  --workers 4

# Final format
cerebrate-file "$TRANS_DIR" \
  --recurse "**/*.md" \
  --prompt "Add table of contents, improve headings, check links" \
  --output "$FINAL_DIR" \
  --workers 4
```

## Tips for Examples

1. **Start small**: Test with small files first
2. **Use dry run**: Verify chunking before processing
3. **Save prompts**: Reuse successful instruction files
4. **Monitor progress**: Use verbose mode for debugging
5. **Tune parameters**: Adjust based on results
6. **Handle errors**: Add error checking to scripts
7. **Document workflows**: Save successful commands
8. **Version control**: Track changes in processed files

## Next Steps

- See [CLI Reference](cli-reference/) for all options
- Review [Configuration](configuration/) for optimization
- Check [Troubleshooting](troubleshooting/) for issues
- Explore [API Reference](api-reference/) for automation
</document_content>
</document>

<document index="21">
<source>docs/index.md</source>
<document_content>
---
layout: home
title: Home
nav_order: 1
description: "Process large documents with Cerebras AI using intelligent chunking and context preservation"
permalink: /
---

# Cerebrate File Documentation
{: .fs-9 }

Break large files into manageable pieces, preserve context, and process them with Cerebras AI.
{: .fs-6 .fw-300 }

[Get started](#getting-started){: .btn .btn-primary .fs-5 .mb-4 .mb-md-0 .mr-2 } [View on GitHub](https://github.com/twardoch/cerebrate-file){: .btn .fs-5 .mb-4 .mb-md-0 }

---

## Overview

**Cerebrate File** is a command-line tool for processing large documents through the Cerebras AI API. It splits files intelligently to fit within the modelâ€™s context window while keeping track of what came before.

### Key Features

- **Smart chunking**: Automatically break large documents into smaller parts
- **Context overlap**: Keep snippets from previous chunks to maintain continuity
- **Directory support**: Recursively process folders using glob patterns
- **Parallel execution**: Handle multiple files at once with threading
- **Terminal UI**: Clean progress output that updates in real time
- **Retry logic**: Handle rate limits and temporary errors without manual intervention
- **Format flexibility**: Works with text, markdown, code, and semantic content
- **Configurable behavior**: Plenty of CLI options for tuning how things work

## Getting Started

### Installation

Install with pip or uv:

```bash
# Using pip
pip install cerebrate-file

# Using uv (faster)
uv pip install cerebrate-file
```

### Quick Start

1. Set your Cerebras API key:
   ```bash
   export CEREBRAS_API_KEY="csk-..."
   ```

2. Process a single file:
   ```bash
   cerebrate-file document.md --output processed.md
   ```

3. Process all markdown files in a directory tree:
   ```bash
   cerebrate-file . --output ./output --recurse "**/*.md"
   ```

## Use Cases

Use Cerebrate File when you need to:

- Rewrite, summarize, or translate large documents
- Refactor code across an entire project
- Generate new versions or expansions of existing content
- Apply consistent transformations to many files at once
- Clean, format, or analyze large text datasets

## Model Details

The tool uses the **Qwen-3 Coder 480B** model from Cerebras:

- **Context window**: 131,072 tokens
- **Speed**: ~570 tokens/second
- **Specialty**: Good at both code and natural language
- **Rate limits**:
  - 30 requests per minute
  - 1,000 requests per day
  - 10 million tokens per minute

## Documentation Sections

- **[Installation](installation/)** â€“ Setup instructions
- **[Usage Guide](usage/)** â€“ Practical examples
- **[CLI Reference](cli-reference/)** â€“ All command-line flags and options
- **[Configuration](configuration/)** â€“ Settings and tuning tips
- **[Examples](examples/)** â€“ Real-world workflows
- **[API Reference](api-reference/)** â€“ For Python integration
- **[Troubleshooting](troubleshooting/)** â€“ Fixes for common issues
- **[Development](development/)** â€“ How to contribute

## System Requirements

- Python 3.9+
- Minimum 4GB RAM (8GB recommended for large files)
- Internet connection
- Valid Cerebras API key

## License

Licensed under Apache 2.0. See [LICENSE](https://github.com/twardoch/cerebrate-file/blob/main/LICENSE) for details.

## Support

- Report bugs or request features: [GitHub Issues](https://github.com/twardoch/cerebrate-file/issues)
- Ask questions or share ideas: [GitHub Discussions](https://github.com/twardoch/cerebrate-file/discussions)
- Maintainer: Adam Twardoch ([@twardoch](https://github.com/twardoch))
</document_content>
</document>

<document index="22">
<source>docs/installation.md</source>
<document_content>
Here's the edited version of your document with improvements for clarity, conciseness, and tone:

---

layout: default
title: Installation
nav_order: 2

# Installation
{: .no_toc }

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## Prerequisites

Before installing Cerebrate File, ensure you have:

- **Python 3.9 or later**
- **pip** or **uv** package manager
- A **Cerebras API key** (get it from [cerebras.ai](https://cerebras.ai))

### Check Python Version

```bash
python --version
# or
python3 --version
```

You should see Python 3.9.0 or higher.

## Installation Methods

### Using pip

Install the latest version from PyPI:

```bash
pip install cerebrate-file
```

To install a specific version:

```bash
pip install cerebrate-file==1.0.10
```

### Using uv (Preferred)

[uv](https://github.com/astral-sh/uv) is a fast Python package installer:

```bash
# Install uv if needed
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install cerebrate-file
uv pip install cerebrate-file
```

### From Source

Install the development version directly from GitHub:

```bash
# With pip
pip install git+https://github.com/twardoch/cerebrate-file.git

# With uv
uv pip install git+https://github.com/twardoch/cerebrate-file.git
```

### Development Setup

For local development or contributions:

```bash
# Clone repo
git clone https://github.com/twardoch/cerebrate-file.git
cd cerebrate-file

# Create virtual environment
uv venv --python 3.12
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install in editable mode with dev dependencies
uv pip install -e .
uv add --dev pytest pytest-cov pytest-mock
```

## API Key Configuration

### Environment Variable

Set your Cerebras API key as an environment variable:

```bash
# Linux/macOS
export CEREBRAS_API_KEY="csk-your-api-key-here"

# Windows (Command Prompt)
set CEREBRAS_API_KEY=csk-your-api-key-here

# Windows (PowerShell)
$env:CEREBRAS_API_KEY="csk-your-api-key-here"
```

### .env File

Alternatively, store the key in a `.env` file:

1. Create `.env` in your project directory:
   ```bash
   echo 'CEREBRAS_API_KEY=csk-your-api-key-here' > .env
   ```

2. Cerebrate File will automatically load it when run from that directory.

**Security Reminder**: Donâ€™t commit `.env` files to version control. Add `.env` to `.gitignore`.

### Validate API Key

Test installation and key setup:

```bash
# Check installed version
cerebrate-file --version

# Test API connection (available in next release)
# cerebrate-file --test-connection
```

## Dependencies

Cerebrate File automatically installs these:

### Core
- `cerebras-cloud-sdk>=1.0.0` - Cerebras AI API client
- `python-dotenv>=1.0.0` - Environment variable handling
- `fire>=0.7.1` - CLI framework
- `loguru>=0.7.0` - Logging library
- `tenacity>=9.0.0` - Retry utilities
- `rich>=13.0.0` - Terminal formatting

### Processing
- `semantic-text-splitter>=0.19.2` - Text chunking
- `qwen-tokenizer>=0.1.2` - Token counting
- `python-frontmatter>=1.1.0` - Frontmatter parsing

### Optional (Development Only)
- `pytest>=8.3.4` - Testing
- `pytest-cov>=6.0.0` - Coverage reporting
- `pytest-mock>=3.14.0` - Mocking tools

## Verify Installation

Confirm everything works:

```bash
# Check command availability
which cerebrate-file

# Show help
cerebrate-file --help

# Run a quick test
echo "Hello, world!" > test.txt
cerebrate-file test.txt --prompt "Make this greeting more formal"
```

## Updating

### Upgrade to Latest Version

```bash
# With pip
pip install --upgrade cerebrate-file

# With uv
uv pip install --upgrade cerebrate-file
```

### Check Current Version

```bash
cerebrate-file --version
# or
python -c "import cerebrate_file; print(cerebrate_file.__version__)"
```

## Uninstall

Remove Cerebrate File:

```bash
# With pip
pip uninstall cerebrate-file

# With uv
uv pip uninstall cerebrate-file
```

## Troubleshooting

### Common Errors

#### Python Version Too Old
```
ERROR: cerebrate-file requires Python >=3.9
```
**Fix**: Upgrade Python.

#### Missing Dependencies
```
ModuleNotFoundError: No module named 'cerebras_cloud_sdk'
```
**Fix**: Reinstall:
```bash
pip install --force-reinstall cerebrate-file
```

#### Permission Denied
```
ERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied
```
**Fix**: Install for current user:
```bash
pip install --user cerebrate-file
```

#### SSL Certificate Error
```
ssl.SSLCertVerificationError: certificate verify failed
```
**Fix**: Update certificates or bypass verification:
```bash
pip install --trusted-host pypi.org cerebrate-file
```

### Need Help?

If issues persist:

1. Review the [Troubleshooting Guide](troubleshooting/)
2. Search [GitHub Issues](https://github.com/twardoch/cerebrate-file/issues)
3. Open a new issue including:
   - Python version
   - Installation method
   - Full error message
   - Steps to reproduce

## Next Steps

After installation, explore:
- [Usage Guide](usage/) - How to use Cerebrate File
- [Configuration](configuration/) - Customize settings
- [Examples](examples/) - Real-world workflows

--- 

This edit removes fluff, simplifies structure, tightens technical descriptions, and adds a subtle dry humor where appropriate without losing any critical information. Let me know if you'd like a markdown-to-HTML version or want this tailored for a specific audience.
</document_content>
</document>

<document index="23">
<source>docs/quick-start.md</source>
<document_content>
---
layout: default
title: Quick Start
nav_order: 2
parent: Usage Guide
---

# Quick Start Guide
{: .no_toc }

Get up and running with Cerebrate File in 5 minutes
{: .fs-6 .fw-300 }

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## 1. Install Cerebrate File

```bash
# Using pip
pip install cerebrate-file

# Using uv (faster)
uv pip install cerebrate-file
```

## 2. Set Your API Key

Get your API key from [cerebras.ai](https://cerebras.ai) and set it:

```bash
export CEREBRAS_API_KEY="csk-your-api-key-here"
```

## 3. Process Your First File

### Simple Processing

```bash
# Process a single file (overwrites original)
cerebrate-file document.md --prompt "Improve clarity and grammar"
```

### Save to New File

```bash
# Process and save to a new file
cerebrate-file input.md --output improved.md --prompt "Fix typos and improve flow"
```

## 4. Common Use Cases

### Summarize a Document

```bash
cerebrate-file report.md \
  --prompt "Summarize to 500 words with key points" \
  --output summary.md
```

### Improve Code Documentation

```bash
cerebrate-file script.py \
  --prompt "Add comprehensive docstrings and comments" \
  --data_format code \
  --output documented.py
```

### Translate Content

```bash
cerebrate-file article.md \
  --prompt "Translate to Spanish, keep formatting" \
  --output articulo.md
```

### Process Multiple Files

```bash
# Process all markdown files in current directory
cerebrate-file . \
  --recurse "*.md" \
  --prompt "Add table of contents" \
  --output ./processed/
```

## 5. Essential Options

### Chunking Options

```bash
# For large documents
cerebrate-file large_doc.md --chunk_size 48000

# For code files
cerebrate-file app.py --data_format code

# For articles
cerebrate-file article.txt --data_format semantic
```

### Model Parameters

```bash
# More creative output
cerebrate-file story.md --temp 0.9

# More consistent output
cerebrate-file technical.md --temp 0.3
```

### Debug and Test

```bash
# See what's happening
cerebrate-file doc.md --verbose

# Test without API calls
cerebrate-file doc.md --dry_run
```

## 6. Advanced Features

### Recursive Processing

Process entire directory trees:

```bash
# Process all Python files recursively
cerebrate-file ./src \
  --recurse "**/*.py" \
  --prompt "Add type hints" \
  --output ./typed/ \
  --workers 4
```

### Using Instruction Files

For complex instructions:

```bash
# Create instruction file
cat > instructions.md << EOF
1. Fix all grammar and spelling errors
2. Improve sentence structure
3. Add section summaries
4. Ensure consistent tone
EOF

# Use instruction file
cerebrate-file document.md \
  --file_prompt instructions.md \
  --output edited.md
```

### Parallel Processing

Speed up multiple files:

```bash
# Process with 8 parallel workers
cerebrate-file . \
  --recurse "**/*.md" \
  --workers 8 \
  --output ./processed/
```

## 7. Monitor Progress

The tool shows:
- Progress bar with percentage
- Current file being processed
- Files completed
- Remaining API calls

## 8. Check Your Results

After processing:

```bash
# View the output
cat output.md

# Compare with original
diff input.md output.md

# Check remaining API calls
cerebrate-file small.txt --verbose | grep "Remaining"
```

## 9. Troubleshooting Quick Fixes

### API Key Not Found
```bash
echo 'CEREBRAS_API_KEY=csk-...' > .env
```

### Rate Limited
```bash
# Use fewer workers
cerebrate-file . --recurse "**/*.md" --workers 2
```

### File Too Large
```bash
# Use smaller chunks
cerebrate-file large.md --chunk_size 16000
```

### Out of Memory
```bash
# Process sequentially
cerebrate-file . --recurse "**/*.md" --workers 1
```

## 10. Next Steps

Now that you're up and running:

1. **Explore More Options**: See [CLI Reference](../cli-reference/)
2. **Learn Best Practices**: Read [Configuration Guide](../configuration/)
3. **See Examples**: Browse [Real-World Examples](../examples/)
4. **Troubleshoot Issues**: Check [Troubleshooting Guide](../troubleshooting/)

## Quick Reference Card

### Essential Commands

| Task | Command |
|------|---------|
| **Process file** | `cerebrate-file input.md` |
| **Save to new file** | `cerebrate-file input.md -o output.md` |
| **Add instructions** | `cerebrate-file doc.md -p "instructions"` |
| **Process directory** | `cerebrate-file . --recurse "*.md"` |
| **Test chunking** | `cerebrate-file doc.md --dry_run` |
| **Debug mode** | `cerebrate-file doc.md --verbose` |

### Key Parameters

| Parameter | Purpose | Example |
|-----------|---------|---------|
| `--output` | Output path | `--output result.md` |
| `--prompt` | Instructions | `--prompt "Summarize"` |
| `--recurse` | Pattern | `--recurse "**/*.py"` |
| `--workers` | Parallel | `--workers 8` |
| `--chunk_size` | Chunk size | `--chunk_size 32000` |
| `--data_format` | Strategy | `--data_format code` |
| `--temp` | Temperature | `--temp 0.7` |
| `--verbose` | Debug info | `--verbose` |

### Chunking Strategies

| Format | Best For | Example |
|--------|----------|---------|
| `markdown` | Documents | README, docs |
| `code` | Source files | .py, .js, .java |
| `semantic` | Articles | Blog posts, essays |
| `text` | Plain text | CSV, logs, data |

## Getting Help

- **Help command**: `cerebrate-file --help`
- **Documentation**: [Full docs](https://twardoch.github.io/cerebrate-file/)
- **Issues**: [GitHub Issues](https://github.com/twardoch/cerebrate-file/issues)
- **Discussions**: [GitHub Discussions](https://github.com/twardoch/cerebrate-file/discussions)
</document_content>
</document>

<document index="24">
<source>docs/troubleshooting.md</source>
<document_content>
# Troubleshooting

Solutions to common issues and error messages.

## Table of contents

1. TOC
{:toc}

---

## Common Issues

### API Key Issues

#### Error: CEREBRAS_API_KEY not found

**Symptom:**
```
Error: CEREBRAS_API_KEY environment variable not found
```

**Solutions:**

1. Set the environment variable:
   ```bash
   export CEREBRAS_API_KEY="csk-your-key-here"
   ```

2. Create a `.env` file:
   ```bash
   echo 'CEREBRAS_API_KEY=csk-your-key-here' > .env
   ```

3. Pass directly (not recommended):
   ```python
   process_document(input_data="file.md", api_key="csk-...")
   ```

#### Error: Invalid API Key Format

**Symptom:**
```
Warning: API key appears to be a placeholder
```

**Solution:**
- API key must start with `csk-`
- Get a valid key from [cerebras.ai](https://cerebras.ai)
- Check for typos or extra spaces

### Rate Limiting

#### Error: Rate limit exceeded

**Symptom:**
```
RateLimitError: 429 Too Many Requests
```

**Solutions:**

1. **Wait for reset:**
   - Per-minute limits: 60 seconds
   - Daily limits: midnight UTC

2. **Reduce parallel workers:**
   ```bash
   cerebrate-file . --recurse "**/*.md" --workers 2
   ```

3. **Process in batches:**
   ```bash
   # Process 10 files at a time
   find . -name "*.md" | head -10 | xargs -I {} cerebrate-file {}
   ```

4. **Check remaining quota:**
   ```bash
   cerebrate-file small.txt --verbose | grep "Remaining"
   ```

### Token Limit Issues

#### Error: Context length exceeded

**Symptom:**
```
TokenLimitError: Maximum context length is 131072 tokens
```

**Solutions:**

1. **Reduce chunk size:**
   ```bash
   cerebrate-file large.md --chunk_size 24000
   ```

2. **Lower completion ratio:**
   ```bash
   cerebrate-file doc.md --max_tokens_ratio 50
   ```

3. **Reduce sample size:**
   ```bash
   cerebrate-file doc.md --sample_size 100
   ```

4. **Use simpler prompts:**
   - Shorter instructions = fewer tokens
   - Remove redundant instructions

### File Processing Errors

#### Error: File not found

**Symptom:**
```
FileNotFoundError: [Errno 2] No such file or directory
```

**Solutions:**

1. **Check file path:**
   ```bash
   ls -la input.md
   pwd  # Verify current directory
   ```

2. **Use absolute paths:**
   ```bash
   cerebrate-file /full/path/to/file.md
   ```

3. **Check permissions:**
   ```bash
   ls -la file.md
   chmod 644 file.md  # If needed
   ```

#### Error: Permission denied

**Symptom:**
```
PermissionError: [Errno 13] Permission denied
```

**Solutions:**

1. **Check file permissions:**
   ```bash
   chmod 644 input.md  # Read permission
   chmod 755 output_dir/  # Directory access
   ```

2. **Check output directory:**
   ```bash
   mkdir -p output
   chmod 755 output
   ```

3. **Run with appropriate user:**
   ```bash
   sudo chown $USER:$USER file.md
   ```

### Network Issues

#### Error: Connection timeout

**Symptom:**
```
NetworkError: HTTPSConnectionPool timeout
```

**Solutions:**

1. **Check internet connection:**
   ```bash
   ping api.cerebras.ai
   curl https://api.cerebras.ai
   ```

2. **Configure proxy if needed:**
   ```bash
   export HTTPS_PROXY="http://proxy:8080"
   ```

3. **Increase timeout (in code):**
   ```python
   client = CerebrasClient(api_key, timeout=60)
   ```

4. **Retry with verbose mode:**
   ```bash
   cerebrate-file doc.md --verbose
   ```

### Chunking Issues

#### Error: No chunks created

**Symptom:**
```
ValueError: No chunks were created from the input
```

**Solutions:**

1. **Check file content:**
   ```bash
   wc -l input.md  # Check if file has content
   file input.md    # Check file type
   ```

2. **Try different format:**
   ```bash
   cerebrate-file doc.md --data_format text
   ```

3. **Check encoding:**
   ```bash
   file -bi input.md  # Check encoding
   iconv -f ISO-8859-1 -t UTF-8 input.md > input_utf8.md
   ```

#### Error: Chunks too large

**Symptom:**
```
Chunk size exceeds maximum token limit
```

**Solution:**
```bash
cerebrate-file doc.md --chunk_size 16000
```

### Output Issues

#### Problem: Output is truncated

**Solutions:**

1. **Increase token ratio:**
   ```bash
   cerebrate-file doc.md --max_tokens_ratio 150
   ```

2. **Check for rate limiting:**
   - Look for incomplete responses
   - Add `--verbose` to see details

3. **Process smaller chunks:**
   ```bash
   cerebrate-file doc.md --chunk_size 24000
   ```

#### Problem: Output formatting is broken

**Solutions:**

1. **Use appropriate format:**
   ```bash
   cerebrate-file doc.md --data_format markdown
   ```

2. **Preserve frontmatter:**
   ```bash
   cerebrate-file doc.md --explain
   ```

3. **Check prompt instructions:**
   - Ensure prompt doesn't conflict with format
   - Test with simpler prompts first

### Recursive Processing Issues

#### Error: Invalid glob pattern

**Symptom:**
```
ValueError: Invalid pattern: **/*.{md,txt}
```

**Solutions:**

1. **Quote the pattern:**
   ```bash
   cerebrate-file . --recurse "**/*.{md,txt}"
   ```

2. **Use simpler patterns:**
   ```bash
   cerebrate-file . --recurse "**/*.md"
   ```

3. **Test pattern first:**
   ```bash
   find . -name "*.md"  # Verify files exist
   ```

#### Problem: Not finding files

**Solutions:**

1. **Check current directory:**
   ```bash
   pwd
   ls -la
   ```

2. **Use correct pattern:**
   ```bash
   # Current directory only
   --recurse "*.md"

   # All subdirectories
   --recurse "**/*.md"

   # Specific directory
   --recurse "docs/**/*.md"
   ```

3. **Check file extensions:**
   ```bash
   find . -type f | head -20
   ```

### Performance Issues

#### Problem: Processing is very slow

**Solutions:**

1. **Increase workers:**
   ```bash
   cerebrate-file . --recurse "**/*.md" --workers 8
   ```

2. **Use larger chunks:**
   ```bash
   cerebrate-file doc.md --chunk_size 48000
   ```

3. **Reduce sample size:**
   ```bash
   cerebrate-file doc.md --sample_size 100
   ```

4. **Check system resources:**
   ```bash
   top  # Check CPU and memory
   df -h  # Check disk space
   ```

#### Problem: High memory usage

**Solutions:**

1. **Process sequentially:**
   ```bash
   cerebrate-file . --recurse "**/*.md" --workers 1
   ```

2. **Smaller chunks:**
   ```bash
   cerebrate-file large.md --chunk_size 16000
   ```

3. **Process in batches:**
   ```bash
   for file in *.md; do
     cerebrate-file "$file"
     sleep 1  # Brief pause
   done
   ```

## Error Messages Reference

### API Errors

| Error Code | Meaning | Solution |
|------------|---------|----------|
| 400 | Bad Request | Check prompt and parameters |
| 401 | Unauthorized | Verify API key |
| 403 | Forbidden | Check API key permissions |
| 429 | Rate Limited | Wait and retry |
| 500 | Server Error | Retry later |
| 503 | Service Unavailable | API maintenance, retry later |

### Exit Codes

| Code | Meaning | Typical Cause |
|------|---------|---------------|
| 0 | Success | Normal completion |
| 1 | General Error | Various issues |
| 2 | Invalid Arguments | Bad CLI parameters |
| 3 | API Key Not Found | Missing CEREBRAS_API_KEY |
| 4 | File Not Found | Input file doesn't exist |
| 5 | Permission Denied | File access issues |
| 6 | API Error | Cerebras API problem |
| 7 | Rate Limit | Too many requests |
| 8 | Network Error | Connection issues |

## Debugging Techniques

### Enable Verbose Logging

```bash
# Maximum debugging information
cerebrate-file doc.md --verbose

# Save logs to file
cerebrate-file doc.md --verbose 2> debug.log

# Separate stdout and stderr
cerebrate-file doc.md --verbose \
  1> output.txt \
  2> errors.log
```

### Test with Dry Run

```bash
# Test chunking without API calls
cerebrate-file large.md --dry_run --verbose

# Check what would be processed
cerebrate-file . --recurse "**/*.md" --dry_run
```

### Validate Environment

```bash
# Check API key
echo $CEREBRAS_API_KEY | head -c 10

# Test API connection
curl -H "Authorization: Bearer $CEREBRAS_API_KEY" \
  https://api.cerebras.ai/v1/models

# Check Python version
python --version

# Check package version
python -c "import cerebrate_file; print(cerebrate_file.__version__)"
```

### Monitor Processing

```bash
# Watch progress
cerebrate-file doc.md --verbose | tee process.log

# Monitor system resources
watch -n 1 'ps aux | grep cerebrate'

# Check output files
watch -n 2 'ls -la output/'
```

## Getting Help

### Resources

1. **Documentation**: [Full documentation](https://twardoch.github.io/cerebrate-file/)
2. **GitHub Issues**: [Report bugs](https://github.com/twardoch/cerebrate-file/issues)
3. **Discussions**: [Ask questions](https://github.com/twardoch/cerebrate-file/discussions)

### Reporting Issues

When reporting issues, include:

1. **Error message**: Complete error output
2. **Command**: Exact command used
3. **Environment**:
   ```bash
   cerebrate-file --version
   python --version
   echo $CEREBRAS_API_KEY | head -c 10
   ```
4. **File sample**: Small reproducing example
5. **Verbose output**: Run with `--verbose`

### Support Checklist

Before requesting help:

- [ ] Check this troubleshooting guide
- [ ] Update to latest version
- [ ] Test with a small file
- [ ] Try with `--verbose` flag
- [ ] Check API key is valid
- [ ] Verify file permissions
- [ ] Test network connection
- [ ] Review error message carefully

## FAQ

### General Questions

**Q: How much does it cost?**
A: Cerebras offers free tier with daily limits. Check [cerebras.ai](https://cerebras.ai) for pricing.

**Q: What file types are supported?**
A: Any text file. Binary files need conversion to text first.

**Q: What's the maximum file size?**
A: No hard limit, but very large files may take long to process.

**Q: Can I process PDFs?**
A: Convert PDF to text first using tools like `pdftotext`.

### Technical Questions

**Q: Why is processing slow?**
A: Large files, small chunks, or rate limiting. Try increasing chunk size and workers.

**Q: How do I process code files?**
A: Use `--data_format code` for better code-aware chunking.

**Q: Can I use multiple API keys?**
A: Not simultaneously. Process different batches with different keys.

**Q: Does it work offline?**
A: No, requires internet connection to Cerebras API.

### Best Practices

**Q: What's the optimal chunk size?**
A: 32,000-48,000 tokens for most content. Smaller for code.

**Q: How many workers should I use?**
A: 4-8 workers typically optimal. Depends on system and rate limits.

**Q: Should I use streaming?**
A: Yes (default). Provides better progress feedback.

**Q: How do I preserve formatting?**
A: Use appropriate `--data_format` for your content type.

## Next Steps

- Review [Configuration](configuration/) for optimization
- See [Examples](examples/) for working solutions
- Check [API Reference](api-reference/) for programmatic use
- Explore [CLI Reference](cli-reference/) for all options
</document_content>
</document>

<document index="25">
<source>docs/usage.md</source>
<document_content>
---
layout: default
title: Usage Guide
nav_order: 3
---

# Usage Guide
{: .no_toc }

How to use Cerebrate File effectively
{: .fs-6 .fw-300 }

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## Basic Usage

### Processing a Single File

The simplest way to use Cerebrate File is on one document:

```bash
cerebrate-file input.md
```

This overwrites `input.md` with the processed version.

### Specifying Output File

To save the result elsewhere:

```bash
cerebrate-file input.md --output output.md
```

### Adding Instructions

Add instructions for the AI:

```bash
cerebrate-file document.md \
  --prompt "Summarize each section in 2-3 sentences"
```

### Using Instruction Files

For longer or reusable instructions, use a file:

```bash
cerebrate-file report.md \
  --file_prompt instructions.md \
  --output summary.md
```

## Advanced Features

### Recursive Processing

Process multiple files by pattern:

```bash
# All markdown files, recursively
cerebrate-file . --output ./processed --recurse "**/*.md"

# Specific file types
cerebrate-file ./src --output ./docs --recurse "**/*.{py,js,ts}"

# Limit depth
cerebrate-file . --output ./output --recurse "*.txt"      # Current dir only
cerebrate-file . --output ./output --recurse "*/*.txt"     # One level deep
```

### Parallel Processing

Speed up processing with multiple workers:

```bash
# Use 8 workers
cerebrate-file . --output ./output --recurse "**/*.md" --workers 8

# Auto-detect based on CPU cores
cerebrate-file . --output ./output --recurse "**/*.md" --workers 0
```

### Chunking Strategies

Choose the right strategy for your content:

```bash
# Markdown-aware (default)
cerebrate-file doc.md --data_format markdown

# Code-aware for source files
cerebrate-file script.py --data_format code

# Semantic chunking for natural text
cerebrate-file article.txt --data_format semantic

# Plain text
cerebrate-file data.txt --data_format text
```

### Chunk Size Control

Adjust chunk sizes:

```bash
# Smaller chunks = more detail
cerebrate-file large.md --chunk_size 16000

# Larger chunks = more context
cerebrate-file report.md --chunk_size 64000

# Control output size
cerebrate-file doc.md --max_tokens_ratio 50  # Output uses 50% of chunk size
```

### Context Preservation

Control overlap between chunks:

```bash
# More overlap = better continuity
cerebrate-file novel.md --sample_size 500

# Less overlap = faster processing
cerebrate-file data.csv --sample_size 50
```

## Working with Different File Types

### Markdown Documents

```bash
cerebrate-file README.md \
  --prompt "Add emojis to headers" \
  --data_format markdown
```

### Source Code

```bash
cerebrate-file app.py \
  --prompt "Add docstrings" \
  --data_format code \
  --chunk_size 24000
```

### Plain Text

```bash
cerebrate-file article.txt \
  --prompt "Fix grammar and clarify language" \
  --data_format text
```

### Mixed Content

```bash
# Process multiple file types at once
cerebrate-file . --output ./processed \
  --recurse "**/*.{md,py,txt}" \
  --prompt "Improve docs and comments"
```

## Metadata Processing

### Extracting Metadata

Use `--explain` to extract/generate metadata:

```bash
cerebrate-file blog_post.md --explain
```

Extracts:
- Title
- Author
- Document ID
- Type
- Date

### Preserving Frontmatter

Markdown frontmatter is preserved automatically:

```yaml
---
title: My Document
author: John Doe
---
# Content starts here...
```

## Model Parameters

### Temperature Control

Control creativity:

```bash
# High = more creative
cerebrate-file story.md --temp 0.9

# Low = more predictable
cerebrate-file technical.md --temp 0.3
```

### Top-p Sampling

Control vocabulary diversity:

```bash
# Wider range of words
cerebrate-file creative.md --top_p 0.95

# Stick to common words
cerebrate-file formal.md --top_p 0.7
```

## Monitoring and Debugging

### Verbose Mode

See whatâ€™s happening:

```bash
cerebrate-file large.md --verbose
```

Displays:
- Chunk boundaries
- Token usage
- API requests/responses
- Rate limits
- Timing info

### Dry Run

Test chunking without calling the API:

```bash
cerebrate-file huge.md --dry_run --verbose
```

Useful for:
- Checking chunk sizes
- Validating token limits
- Testing file patterns
- Debugging

### Progress Display

The terminal shows:
- Current file
- Progress percentage
- Output path
- Remaining API calls

## Best Practices

### 1. Chunk Sizes

- **Small files (<10K tokens)**: Default 32K chunks work fine
- **Large files (>100K tokens)**: Try 48Kâ€“64K chunks
- **Code files**: 24K chunks help keep functions intact

### 2. Chunking Strategy

- **Markdown**: Use `markdown`
- **Code**: Use `code`
- **Articles**: Use `semantic`
- **Structured data**: Use `text`

### 3. Rate Limits

- Watch remaining requests: `ğŸ“Š Remaining today: X`
- Use `--workers` carefully
- Add delays if hitting limits

### 4. Large Projects

Process in controlled batches:

```bash
# Shell-based batching
find . -name "*.md" -print0 | \
  xargs -0 -n 10 cerebrate-file --output ./processed

# Or with limited parallelism
cerebrate-file . --output ./output \
  --recurse "**/*.md" \
  --workers 4
```

### 5. Preserve Context

For continuous text:

```bash
cerebrate-file book.md \
  --sample_size 500 \
  --chunk_size 48000 \
  --prompt "Keep narrative voice consistent"
```

## Common Workflows

### Document Translation

```bash
cerebrate-file document.md \
  --prompt "Translate to Spanish, keep formatting" \
  --output documento.md
```

### Code Documentation

```bash
cerebrate-file ./src \
  --recurse "**/*.py" \
  --prompt "Add Google-style docstrings" \
  --output ./documented
```

### Content Summarization

```bash
cerebrate-file reports/ \
  --recurse "*.pdf.txt" \
  --prompt "Executive summary, 500 words max" \
  --output summaries/
```

### Style Transformation

```bash
cerebrate-file blog.md \
  --file_prompt style_guide.md \
  --prompt "Rewrite in professional tone" \
  --output blog_professional.md
```

### Batch Processing

```bash
# Apply same instructions to all markdown files
for file in *.md; do
  cerebrate-file "$file" \
    --file_prompt instructions.md \
    --output "processed/${file}"
done
```

## Error Handling

### Rate Limits

Cerebrate File handles them automatically:
- Exponential backoff
- Retries with delays
- Clear status updates

### Network Issues

For flaky connections:

```bash
# Verbose mode helps debug retries
cerebrate-file document.md --verbose
```

### Large Files

If you hit token limits:

```bash
# Reduce chunk size and output ratio
cerebrate-file huge.md \
  --chunk_size 24000 \
  --max_tokens_ratio 50
```

## Tips and Tricks

### 1. Preview Changes

Dry run before processing:

```bash
cerebrate-file doc.md --dry_run --verbose
```

### 2. Save Prompts

Create reusable instruction files:

```bash
echo "Your instructions here" > prompts/summarize.md
cerebrate-file doc.md --file_prompt prompts/summarize.md
```

### 3. Chain Processing

Multi-step workflows:

```bash
# Step 1: Translate
cerebrate-file doc.md --prompt "Translate to Spanish" --output doc_es.md

# Step 2: Summarize
cerebrate-file doc_es.md --prompt "Summarize key points" --output summary_es.md
```

### 4. Use Shell Features

Leverage shell tools:

```bash
# Process files modified today
find . -name "*.md" -mtime -1 -exec cerebrate-file {} \;

# Confirm before processing
for file in *.txt; do
  read -p "Process $file? " -n 1 -r
  echo
  if [[ $REPLY =~ ^[Yy]$ ]]; then
    cerebrate-file "$file"
  fi
done
```

## Next Steps

- [CLI Reference](cli-reference/) â€“ full list of options
- [Examples](examples/) â€“ real-world use cases
- [Troubleshooting](troubleshooting/) â€“ common issues
- [API Reference](api-reference/) â€“ programmatic usage
</document_content>
</document>

<document index="26">
<source>issues/204.md</source>
<document_content>
The simple `./testapi.py` script works and returns a TLDR of CHANGELOG.md as requested

```
[14:04:48] $ ./testapi.py

# Changelog

## [Unreleased] - 2025-09-20

### Changed
- Build: Migrated `tool.uv.dev-dependencies` to `[dependency-groups].dev`
...
```

But using the full `cerebrate-file` tool (the main thing in this repo), we get: 

```
[14:05:01] $ cerebrate-file -i CHANGELOG.md -o CHANGELOG2.md -c 1024 -p "Slightly compress this CHANGELOG: only keep relevant facts, eliminate fluff"
Processing: CHANGELOG.md
ğŸ“„ CHANGELOG.md â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”   0%2025-11-14 14:05:11 | WARNING  | cerebrate_file.cerebrate_file:process_document:292 - Chunk 1 returned zero tokens. Request diagnostics: {'chunk_index': 1, 'chunk_tokens': 9, 'total_input_tokens': 25, 'max_completion_tokens': 9, 'response_tokens': 0, 'response_chars': 0, 'model': 'zai-glm-4.6', 'temperature': 0.98, 'top_p': 0.8, 'rate_requests_remaining': 172761, 'rate_tokens_remaining': 1500000, 'rate_headers_parsed': True}
ğŸ“„ CHANGELOG.md â”â”â”â”â”â•¸â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  14%2025-11-14 14:05:12 | WARNING  | cerebrate_file.cerebrate_file:process_document:292 - Chunk 2 returned zero tokens. Request diagnostics: {'chunk_index': 2, 'chunk_tokens': 18, 'total_input_tokens': 34, 'max_completion_tokens': 18, 'response_tokens': 0, 'response_chars': 0, 'model': 'zai-glm-4.6', 'temperature': 0.98, 'top_p': 0.8, 'rate_requests_remaining': 172760, 'rate_tokens_remaining': 1499960, 'rate_headers_parsed': True}
ğŸ“„ CHANGELOG.md â”â”â”â”â”â”â”â”â”â”â”â•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  29%2025-11-14 14:05:14 | WARNING  | cerebrate_file.cerebrate_file:process_document:292 - Chunk 3 returned zero tokens. Request diagnostics: {'chunk_index': 3, 'chunk_tokens': 735, 'total_input_tokens': 751, 'max_completion_tokens': 735, 'response_tokens': 0, 'response_chars': 0, 'model': 'zai-glm-4.6', 'temperature': 0.98, 'top_p': 0.8, 'rate_requests_remaining': 172759, 'rate_tokens_remaining': 1499902, 'rate_headers_parsed': True}
ğŸ“„ CHANGELOG.md â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  43%2025-11-14 14:05:16 | WARNING  | cerebrate_file.cerebrate_file:process_document:292 - Chunk 4 returned zero tokens. Request diagnostics: {'chunk_index': 4, 'chunk_tokens': 795, 'total_input_tokens': 811, 'max_completion_tokens': 795, 'response_tokens': 0, 'response_chars': 0, 'model': 'zai-glm-4.6', 'temperature': 0.98, 'top_p': 0.8, 'rate_requests_remaining': 172758, 'rate_tokens_remaining': 1498420, 'rate_headers_parsed': True}
ğŸ“„ CHANGELOG.md â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  57%2025-11-14 14:05:18 | WARNING  | cerebrate_file.cerebrate_file:process_document:292 - Chunk 5 returned zero tokens. Request diagnostics: {'chunk_index': 5, 'chunk_tokens': 769, 'total_input_tokens': 785, 'max_completion_tokens': 769, 'response_tokens': 0, 'response_chars': 0, 'model': 'zai-glm-4.6', 'temperature': 0.98, 'top_p': 0.8, 'rate_requests_remaining': 172757, 'rate_tokens_remaining': 1496834, 'rate_headers_parsed': True}
ğŸ“„ CHANGELOG.md â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸â”â”â”â”â”â”â”â”â”â”â”  71%2025-11-14 14:05:20 | WARNING  | cerebrate_file.cerebrate_file:process_document:292 - Chunk 6 returned zero tokens. Request diagnostics: {'chunk_index': 6, 'chunk_tokens': 565, 'total_input_tokens': 581, 'max_completion_tokens': 565, 'response_tokens': 0, 'response_chars': 0, 'model': 'zai-glm-4.6', 'temperature': 0.98, 'top_p': 0.8, 'rate_requests_remaining': 172756, 'rate_tokens_remaining': 1495317, 'rate_headers_parsed': True}
ğŸ“„ CHANGELOG.md â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•ºâ”â”â”â”â”  86%2025-11-14 14:05:21 | WARNING  | cerebrate_file.cerebrate_file:process_document:292 - Chunk 7 returned zero tokens. Request diagnostics: {'chunk_index': 7, 'chunk_tokens': 454, 'total_input_tokens': 470, 'max_completion_tokens': 454, 'response_tokens': 0, 'response_chars': 0, 'model': 'zai-glm-4.6', 'temperature': 0.98, 'top_p': 0.8, 'rate_requests_remaining': 172755, 'rate_tokens_remaining': 1494184, 'rate_headers_parsed': True}
ğŸ“„ CHANGELOG.md â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100%
âœ… Saved: CHANGELOG2.md (172,755 calls remaining)

âŒ Cerebras returned zero tokens for the document â€“ no data was written to CHANGELOG2.md.
   Input file remains unchanged: CHANGELOG.md
   API diagnostics (first 3 zero-output chunks):
    - Chunk 1: input=25 tokens, budget=9, model=zai-glm-4.6, temp=0.98, top_p=0.8, requests_remaining=172761, tokens_remaining=1500000
    - Chunk 2: input=34 tokens, budget=18, model=zai-glm-4.6, temp=0.98, top_p=0.8, requests_remaining=172760, tokens_remaining=1499960
    - Chunk 3: input=751 tokens, budget=735, model=zai-glm-4.6, temp=0.98, top_p=0.8, requests_remaining=172759, tokens_remaining=1499902
    ... and 4 more zero-output chunks
2025-11-14 14:05:21 | ERROR    | cerebrate_file.cli:_report_zero_output_failure:734 - Aborting write because Cerebras returned zero tokens for %s -> %s | diagnostics=%s
~/Developer/vcs/github.twardoch/pub/cerebrate-file
```

The `cerebrate-file` tool used to work. However, Cerebras did some changes. 

TASK: Investigate carefully and systematically this failure and restore `cerebrate-file` to a fully working condition. Use a careful iterative approach. Do real-life tests on the Cerebras API, no need to mock anything. 
</document_content>
</document>

<document index="27">
<source>issues/305.md</source>
<document_content>
$ cerebrate-file -i fontsimi.txt -o fontsimi-tldr.txt -p "TLDR this. Elide all function/method bodies with '...' but keep the signatures. Radically TLDR the prose into just the very entity-dense microsummary. Discard everything that isnâ€™t relevant."; cerebrate-file -i typf.txt -o typf-tldr.txt -p "TLDR this. Elide all function/method bodies with '...' but keep the signatures. Radically TLDR the prose into just the very entity-dense microsummary. Discard everything that isnâ€™t relevant.";
Processing: fontsimi.txt
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.12/bin/cerebrate-file", line 10, in <module>
    sys.exit(main())
             ^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/cerebrate_file/__main__.py", line 19, in main
    fire.Fire(run)
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/cerebrate_file/cli.py", line 335, in run
    if input_data != output_data and Path(output_data).exists() and not force:
                                     ^^^^
UnboundLocalError: cannot access local variable 'Path' where it is not associated with a value
Processing: typf.txt
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.12/bin/cerebrate-file", line 10, in <module>
    sys.exit(main())
             ^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/cerebrate_file/__main__.py", line 19, in main
    fire.Fire(run)
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/cerebrate_file/cli.py", line 335, in run
    if input_data != output_data and Path(output_data).exists() and not force:
                                     ^^^^
UnboundLocalError: cannot access local variable 'Path' where it is not associated with a value

~/Developer/vcs/github.docrepair-fonts/tldr
$
</document_content>
</document>

<document index="28">
<source>md.txt</source>
<document_content>



/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/docs/api-reference.md
/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/docs/cli-reference.md
/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/docs/configuration.md
/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/docs/development.md
/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/docs/examples.md
/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/docs/index.md
/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/docs/installation.md
/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/docs/quick-start.md
/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/docs/README.md
/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/docs/troubleshooting.md
/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/docs/usage.md




/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/README.md
/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/REVIEW.md
/Users/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/prompts/README.md
</document_content>
</document>

<document index="29">
<source>pyproject.toml</source>
<document_content>
# this_file: pyproject.toml
#==============================================================================
# CEREBRATE-FILE PACKAGE CONFIGURATION
# This pyproject.toml defines the package metadata, dependencies, build system,
# and development environment for the cerebrate-file package.
#==============================================================================

#------------------------------------------------------------------------------
# PROJECT METADATA
# Core package information used by PyPI and package managers.
#------------------------------------------------------------------------------
[project]
name = 'cerebrate-file' # Package name on PyPI
description = '' # Short description
readme = 'README.md' # Path to README file
requires-python = '>=3.10' # Minimum Python version
keywords = [
] # Keywords for PyPI search
dynamic = ["version"] # Fields set dynamically at build time

# PyPI classifiers for package categorization
classifiers = [
    'Development Status :: 4 - Beta', # Package maturity level
    'Programming Language :: Python',
    'Programming Language :: Python :: 3.10',
    'Programming Language :: Python :: 3.11',
    'Programming Language :: Python :: 3.12',
    'Programming Language :: Python :: Implementation :: CPython',
    'Programming Language :: Python :: Implementation :: PyPy',
    'Operating System :: OS Independent',
    'License :: OSI Approved :: MIT License',
    'Intended Audience :: Developers',
]

dependencies = [
    "fire>=0.6.0",
    "loguru>=0.7.0",
    "python-dotenv>=1.0.0",
    "tenacity>=8.2.0",
    "cerebras-cloud-sdk>=1.0.0",
    "semantic-text-splitter>=0.13.0",
    "qwen-tokenizer>=0.0.8",
    "rich>=13.0.0",
    "python-frontmatter>=1.1.0",
    "openai>=1.0.0",              # For OpenAI-compatible fallback APIs
    "tomli>=2.0.0; python_version < '3.11'",  # TOML parsing for Python <3.11
]

# Author information
[[project.authors]]
name = 'Adam Twardoch'
email = 'adam+github@twardoch.com'

# License information
[project.license]
text = 'MIT'

# Project URLs
[project.urls]
Documentation = 'https://github.com/twardoch/cerebrate-file#readme'
Issues = 'https://github.com/twardoch/cerebrate-file/issues'
Source = 'https://github.com/twardoch/cerebrate-file'

#------------------------------------------------------------------------------
# OPTIONAL DEPENDENCIES
# Additional dependencies for optional features, development, and testing.
#------------------------------------------------------------------------------
[project.optional-dependencies]

# Development tools
dev = [
    'pre-commit>=4.1.0', # Pre-commit hook manager - Keep pre-commit as is, update if newer pre-commit version is required
    'ruff>=0.9.7', # Linting and formatting - Keep ruff as is, update if newer ruff version is required
    'mypy>=1.15.0', # Type checking - Keep mypy as is, update if newer mypy version is required
    'absolufy-imports>=0.3.1', # Convert relative imports to absolute - Keep absolufy-imports as is, update if newer absolufy-imports version is required
    'pyupgrade>=3.19.1', # Upgrade Python syntax - Keep pyupgrade as is, update if newer pyupgrade version is required
    'isort>=6.0.1', # Sort imports - Keep isort as is, update if newer isort version is required
]

# Testing tools and frameworks
test = [
    'pytest>=8.3.4', # Testing framework - Keep pytest as is, update if newer pytest version is required
    'pytest-cov>=6.0.0', # Coverage plugin for pytest - Keep pytest-cov as is, update if newer pytest-cov version is required
    'pytest-xdist>=3.6.1', # Parallel test execution - Keep pytest-xdist as is, update if newer pytest-xdist version is required
    'pytest-benchmark[histogram]>=5.1.0', # Benchmarking plugin - Keep pytest-benchmark as is, update if newer pytest-benchmark version is required
    'pytest-asyncio>=0.25.3', # Async test support - Keep pytest-asyncio as is, update if newer pytest-asyncio version is required
    'coverage[toml]>=7.6.12',
]

docs = [
    "sphinx>=7.2.6",
    "sphinx-rtd-theme>=2.0.0",
    "sphinx-autodoc-typehints>=2.0.0",
    "myst-parser>=3.0.0", # Markdown support in Sphinx
]

# All optional dependencies combined
all = [
]

#------------------------------------------------------------------------------
# COMMAND-LINE SCRIPTS
# Entry points for command-line executables installed with the package.
#------------------------------------------------------------------------------
[project.scripts]
cerebrate-file = "cerebrate_file.__main__:main"

#------------------------------------------------------------------------------
# BUILD SYSTEM CONFIGURATION
# Defines the tools required to build the package and the build backend.
#------------------------------------------------------------------------------
[build-system]
# Hatchling is a modern build backend for Python packaging
# hatch-vcs integrates with version control systems for versioning
requires = [
    'hatchling>=1.27.0', # Keep hatchling as is, update if newer hatchling version is required
    'hatch-vcs>=0.4.0', # Keep hatch-vcs as is, update if newer hatch-vcs version is required
]
build-backend = 'hatchling.build' # Specifies Hatchling as the build backend


#------------------------------------------------------------------------------
# HATCH BUILD CONFIGURATION
# Configures the build process, specifying which packages to include and
# how to handle versioning.
#------------------------------------------------------------------------------
[tool.hatch.build]
# Include package data files
include = [
    "src/cerebrate_file/py.typed", # For better type checking support
    "src/cerebrate_file/data/**/*", # Include data files if any
    "src/cerebrate_file/prompts/**/*", # Include prompt library files
    "src/cerebrate_file/default_config.toml", # Built-in configuration defaults
]
exclude = ["**/__pycache__", "**/.pytest_cache", "**/.mypy_cache"]

[tool.hatch.build.targets.wheel]
packages = ["src/cerebrate_file"]
reproducible = true


# Version control system hook configuration
# Automatically updates the version file from git tags
[tool.hatch.build.hooks.vcs]
version-file = "src/cerebrate_file/__version__.py"

# Version source configuration for git-tag-based semver
[tool.hatch.version]
source = 'vcs' # Get version from git tags or other VCS info
raw-options = { local_scheme = "no-local-version" }

# Metadata handling configuration
[tool.hatch.metadata]
allow-direct-references = true # Allow direct references in metadata (useful for local dependencies)

#------------------------------------------------------------------------------
# UV PACKAGE MANAGER CONFIGURATION
# Configuration for uv package manager - provides faster installs and better resolution
#------------------------------------------------------------------------------
[dependency-groups]
dev = [
    "pre-commit>=4.1.0",
    "ruff>=0.9.7",
    "mypy>=1.15.0",
    "pytest>=8.3.4",
    "pytest-cov>=6.0.0",
]


#------------------------------------------------------------------------------
# DEVELOPMENT ENVIRONMENTS

[tool.hatch.envs.default]
features = ['dev', 'test', 'all']
dependencies = [
]

# Commands available in the default environment
[tool.hatch.envs.default.scripts]
# Run tests with optional arguments
test = 'pytest {args:tests}'
# Run tests with coverage reporting
test-cov = "pytest --cov-report=term-missing --cov-config=pyproject.toml --cov=src/cerebrate_file --cov=tests {args:tests}"
# Run type checking
type-check = "mypy src/cerebrate_file tests"
# Run linting and formatting
lint = ["ruff check src/cerebrate_file tests", "ruff format --respect-gitignore src/cerebrate_file tests"]
# Format and fix style issues
fmt = ["ruff format --respect-gitignore src/cerebrate_file tests", "ruff check --fix src/cerebrate_file tests"]
fix = ["ruff check --fix --unsafe-fixes src/cerebrate_file tests", "ruff format --respect-gitignore src/cerebrate_file tests"]

# Matrix configuration to test across multiple Python versions

[[tool.hatch.envs.all.matrix]]
python = ["3.10", "3.11", "3.12"]

#------------------------------------------------------------------------------
# SPECIALIZED ENVIRONMENTS
# Additional environments for specific development tasks.
#------------------------------------------------------------------------------

# Dedicated environment for linting and code quality checks
[tool.hatch.envs.lint]
detached = true # Create a separate, isolated environment
features = ['dev'] # Use dev extras  dependencies 

# Linting environment commands
[tool.hatch.envs.lint.scripts]
# Type checking with automatic type installation
typing = "mypy --install-types --non-interactive {args:src/cerebrate_file tests}"
# Check style and format code
style = ["ruff check {args:.}", "ruff format --respect-gitignore {args:.}"]
# Format and fix style issues
fmt = ["ruff format --respect-gitignore {args:.}", "ruff check --fix {args:.}"]
fix = ["ruff check --fix --unsafe-fixes {args:.}", "ruff format --respect-gitignore {args:.}"]
# Run all ops
all = ["style", "typing", "fix"]

# Dedicated environment for testing
[tool.hatch.envs.test]
features = ['test'] # Use test extras as dependencies

# Testing environment commands
[tool.hatch.envs.test.scripts]
# Run tests in parallel
test = "python -m pytest -n auto {args:tests}"
# Run tests with coverage in parallel
test-cov = "python -m pytest -n auto --cov-report=term-missing --cov-config=pyproject.toml --cov=src/cerebrate_file --cov=tests {args:tests}"
# Run benchmarks
bench = "python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only"
# Run benchmarks and save results
bench-save = "python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only --benchmark-json=benchmark/results.json"

# Documentation environment
[tool.hatch.envs.docs]
features = ['docs']

# Documentation environment commands
[tool.hatch.envs.docs.scripts]
build = "sphinx-build -b html docs/source docs/build"

# GitHub Actions workflow configuration
[tool.hatch.envs.ci]
features = ['test']


[tool.hatch.envs.ci.scripts]
test = "pytest --cov=src/cerebrate_file --cov-report=xml"


#------------------------------------------------------------------------------
# CODE QUALITY TOOLS
# Configuration for linting, formatting, and code quality enforcement.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# COVERAGE CONFIGURATION
# Settings for test coverage measurement and reporting.
#------------------------------------------------------------------------------

# Path mapping for coverage in different environments
[tool.coverage.paths]
cerebrate_file = ["src/cerebrate_file", "*/cerebrate-file/src/cerebrate_file"]
tests = ["tests", "*/cerebrate-file/tests"]

# Coverage report configuration
[tool.coverage.report]
# Lines to exclude from coverage reporting
exclude_lines = [
    'no cov', # Custom marker to skip coverage
    'if __name__ == .__main__.:', # Script execution guard
    'if TYPE_CHECKING:', # Type checking imports and code
    'pass', # Empty pass statements
    'raise NotImplementedError', # Unimplemented method placeholders
    'raise ImportError', # Import error handling
    'except ImportError', # Import error handling
    'except KeyError', # Common error handling
    'except AttributeError', # Common error handling
    'except NotImplementedError', # Common error handling
]

[tool.coverage.run]
source_pkgs = ["cerebrate_file", "tests"]
branch = true # Measure branch coverage (if/else statements)
parallel = true # Support parallel test execution
omit = [
    "src/cerebrate_file/__about__.py",
]

#------------------------------------------------------------------------------
# MYPY CONFIGURATION
# Configuration for type checking with mypy.
#------------------------------------------------------------------------------

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true

[[tool.mypy.overrides]]
module = ["tests.*"]
disallow_untyped_defs = false
disallow_incomplete_defs = false

#------------------------------------------------------------------------------
# PYTEST CONFIGURATION
# Configuration for pytest, including markers, options, and benchmark settings.
#------------------------------------------------------------------------------

[tool.pytest.ini_options]
addopts = "-v --durations=10 -p no:briefcase"
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"
console_output_style = "progress"
filterwarnings = ["ignore::DeprecationWarning", "ignore::UserWarning"]
log_cli = true
log_cli_level = "INFO"
markers = [
    "benchmark: marks tests as benchmarks (select with '-m benchmark')",
    "unit: mark a test as a unit test",
    "integration: mark a test as an integration test",
    "permutation: tests for permutation functionality", 
    "parameter: tests for parameter parsing",
    "prompt: tests for prompt parsing",
]
norecursedirs = [
    ".*",
    "build",
    "dist", 
    "venv",
    "__pycache__",
    "*.egg-info",
    "_private",
]
python_classes = ["Test*"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
testpaths = ["tests"]

[tool.pytest-benchmark]
min_rounds = 100
min_time = 0.1
histogram = true
storage = "file"
save-data = true
compare = [
    "min",    # Minimum time
    "max",    # Maximum time
    "mean",   # Mean time
    "stddev", # Standard deviation
    "median", # Median time
    "iqr",    # Inter-quartile range
    "ops",    # Operations per second
    "rounds", # Number of rounds
]

#------------------------------------------------------------------------------
# RUFF CONFIGURATION
# Configuration for Ruff, including linter and formatter settings.
#------------------------------------------------------------------------------ 

# Ruff linter and formatter configuration
[tool.ruff]
target-version = "py310"
line-length = 100
# Configure extend-exclude to ignore specific directories
extend-exclude = [".git", ".venv", "venv", "dist", "build"]

# Linting rules configuration
[tool.ruff.lint]
# Rule sets to enable - sensible defaults for most projects
select = [
    'E', # pycodestyle errors
    'W', # pycodestyle warnings
    'F', # pyflakes
    'I', # isort
    'N', # pep8-naming
    'UP', # pyupgrade
    'B', # flake8-bugbear
    'C4', # flake8-comprehensions
    'SIM', # flake8-simplify
    'RUF', # Ruff-specific rules
    'PT', # flake8-pytest-style
    'PTH', # flake8-use-pathlib
    'ARG', # flake8-unused-arguments
    'PLE', # pylint errors
    'PLW', # pylint warnings
]
# Rules to ignore (with reasons)
ignore = [
    'E501', # Line too long - handled by formatter
    'PLW0603', # Using the global statement - sometimes necessary
    'SIM102', # Nested if statements - sometimes more readable
]
# Rules that should not be automatically fixed
unfixable = [
    'F401', # Don't automatically remove unused imports - may be needed later
]

# isort configuration within Ruff
[tool.ruff.lint.isort]
known-first-party = ['cerebrate_file'] # Treat as first-party imports for sorting

# flake8-tidy-imports configuration within Ruff
[tool.ruff.lint.flake8-tidy-imports]
ban-relative-imports = 'all' # Ban all relative imports for consistency

# Per-file rule exceptions
[tool.ruff.lint.per-file-ignores]
# Tests can use magic values, assertions, and relative imports
'tests/**/*' = [
    'PLR2004', # Allow magic values in tests for readability
    'S101', # Allow assertions in tests
    'TID252'
    # Allow relative imports in tests for convenience
]
</document_content>
</document>

# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/__init__.py
# Language: python

from .__version__ import __version__
from .cli import run
from .models import Chunk, ProcessingState, RateLimitStatus
from .settings import (
    InferenceConfig,
    ModelConfig,
    RateLimitConfig,
    Settings,
    get_settings,
    reload_settings,
)


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/__main__.py
# Language: python

import fire
from .cli import run

def main(()) -> None:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/api_client.py
# Language: python

import json
import time
from datetime import datetime, timedelta
from types import SimpleNamespace
from typing import Any
from loguru import logger
from tenacity import (
    RetryError,
    before_sleep_log,
    retry,
    retry_if_exception_type,
    stop_after_attempt,
    wait_fixed,
)
from .constants import (
    METADATA_SCHEMA,
    APIError,
)
from .models import RateLimitStatus
from .settings import ModelConfig, get_settings
import cerebras.cloud.sdk as cerebras_sdk
from cerebras.cloud.sdk import Cerebras
import openai as openai_sdk
from openai import OpenAI
import cerebras.cloud.sdk

RATE_LIMIT_PATTERNS = =
QUOTA_EXCEEDED_PATTERNS = =

class CerebrasClient:
    def __init__((self, api_key: str, model: str | None = None)) -> None:
    def _get_client((self)):
    def chat_completion((
        self,
        messages: list[dict[str, str]],
        max_completion_tokens: int,
        temperature: float | None = None,
        top_p: float | None = None,
    )) -> tuple[str, RateLimitStatus]:
    def explain_metadata((
        self,
        existing_metadata: dict[str, Any],
        first_chunk_text: str,
        temperature: float | None = None,
        top_p: float | None = None,
    )) -> dict[str, Any]:
    def calculate_delay((self, next_chunk_tokens: int)) -> float:

class FallbackClient:
    def __init__((self, model_config: ModelConfig)) -> None:
    def _get_client((self)):
    def chat_completion((
        self,
        messages: list[dict[str, str]],
        max_completion_tokens: int,
        temperature: float | None = None,
        top_p: float | None = None,
    )) -> tuple[str, RateLimitStatus]:

def _get_sdk_class((name: str)) -> type[Exception]:

def _format_response((response: Any)) -> str:

def _is_rate_limit_error((error: Exception)) -> bool:

def _is_quota_exceeded_error((error: Exception)) -> bool:

def __init__((self, api_key: str, model: str | None = None)) -> None:

def _get_client((self)):

def chat_completion((
        self,
        messages: list[dict[str, str]],
        max_completion_tokens: int,
        temperature: float | None = None,
        top_p: float | None = None,
    )) -> tuple[str, RateLimitStatus]:

def explain_metadata((
        self,
        existing_metadata: dict[str, Any],
        first_chunk_text: str,
        temperature: float | None = None,
        top_p: float | None = None,
    )) -> dict[str, Any]:

def calculate_delay((self, next_chunk_tokens: int)) -> float:

def __init__((self, model_config: ModelConfig)) -> None:

def _get_client((self)):

def chat_completion((
        self,
        messages: list[dict[str, str]],
        max_completion_tokens: int,
        temperature: float | None = None,
        top_p: float | None = None,
    )) -> tuple[str, RateLimitStatus]:

def parse_rate_limit_headers((headers: dict[str, str], verbose: bool = False)) -> RateLimitStatus:

def calculate_backoff_delay((
    rate_status: RateLimitStatus,
    next_chunk_tokens: int,
)) -> float:

def explain_metadata_with_llm((
    client,
    existing_metadata: dict[str, Any],
    first_chunk_text: str,
    model: str,
    temp: float,
    top_p: float,
)) -> dict[str, Any]:

def _make_cerebras_request_impl((
    client,
    messages: list[dict[str, str]],
    model: str,
    max_completion_tokens: int,
    temperature: float,
    top_p: float,
    verbose: bool = False,
)) -> tuple[str, RateLimitStatus]:

def make_cerebras_request((
    client,
    messages: list[dict[str, str]],
    model: str,
    max_completion_tokens: int,
    temperature: float,
    top_p: float,
    verbose: bool = False,
)) -> tuple[str, RateLimitStatus]:

def make_request_with_fallback((
    primary_client,
    messages: list[dict[str, str]],
    model: str,
    max_completion_tokens: int,
    temperature: float,
    top_p: float,
    verbose: bool = False,
)) -> tuple[str, RateLimitStatus, str]:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/cerebrate_file.py
# Language: python

import json
import math
import time
from typing import Any
from loguru import logger
from .api_client import make_request_with_fallback
from .constants import (
    MAX_CONTEXT_TOKENS,
    MAX_OUTPUT_TOKENS,
    MIN_COMPLETION_TOKENS,
    REASONING_COMPLETION_RATIO,
)
from .continuity import (
    build_continuity_block,
    extract_continuity_examples,
    fit_continuity_to_budget,
)
from .error_recovery import format_error_message
from .models import Chunk, ChunkDiagnostics, ProcessingState, RateLimitStatus
from .tokenizer import encode_text
from .api_client import calculate_backoff_delay

def calculate_completion_budget((chunk_tokens: int, max_tokens_ratio: int)) -> int:

def prepare_chunk_messages((
    base_prompt: str,
    chunk: Chunk,
    continuity_block: str,
    base_prompt_tokens: int,
    metadata: dict[str, Any] | None = None,
)) -> tuple[list[dict[str, str]], int]:

def process_document((
    client,
    chunks: list[Chunk],
    base_prompt: str,
    base_prompt_tokens: int,
    model: str,
    temp: float,
    top_p: float,
    max_tokens_ratio: int,
    sample_size: int,
    metadata: dict[str, Any] | None = None,
    verbose: bool = False,
    progress_callback: object | None = None,
)) -> tuple[str, ProcessingState]:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/chunking.py
# Language: python

from loguru import logger
from .constants import CHARS_PER_TOKEN_FALLBACK, COMPILED_BOUNDARY_PATTERNS, ChunkingError
from .models import Chunk
from .tokenizer import encode_text
from semantic_text_splitter import TextSplitter
from semantic_text_splitter import MarkdownSplitter
import xml.etree.ElementTree as ET

class ChunkingStrategy:
    def __init__((self, chunk_size: int)) -> None:
    def chunk((self, content: str)) -> list[Chunk]:
    def _create_chunk((self, text: str)) -> Chunk:
    def _handle_overlong_line((self, line: str, chunks: list[Chunk])) -> None:

class TextChunker(C, h, u, n, k, i, n, g, S, t, r, a, t, e, g, y):
    def chunk((self, content: str)) -> list[Chunk]:

class SemanticChunker(C, h, u, n, k, i, n, g, S, t, r, a, t, e, g, y):
    def chunk((self, content: str)) -> list[Chunk]:

class MarkdownChunker(C, h, u, n, k, i, n, g, S, t, r, a, t, e, g, y):
    def chunk((self, content: str)) -> list[Chunk]:

class CodeChunker(C, h, u, n, k, i, n, g, S, t, r, a, t, e, g, y):
    def __init__((self, chunk_size: int)) -> None:
    def _is_good_split_point((
        self, line_idx: int, line: str, brace_depth: int, paren_depth: int, in_string: bool
    )) -> bool:
    def _track_code_structure((self, line: str)) -> tuple[int, int, bool, str | None]:
    def chunk((self, content: str)) -> list[Chunk]:

class XmlChunker(C, h, u, n, k, i, n, g, S, t, r, a, t, e, g, y):
    def _is_valid_xml((self, content: str)) -> bool:
    def _normalize_to_xml((self, content: str)) -> str:
    def _escape_xml_text((self, text: str)) -> str:
    def _find_element_boundaries((self, content: str)) -> list[tuple[int, int, int]]:
    def chunk((self, content: str)) -> list[Chunk]:
    def _wrap_chunk((self, elements: list[str])) -> str:

def __init__((self, chunk_size: int)) -> None:

def chunk((self, content: str)) -> list[Chunk]:

def _create_chunk((self, text: str)) -> Chunk:

def _handle_overlong_line((self, line: str, chunks: list[Chunk])) -> None:

def chunk((self, content: str)) -> list[Chunk]:

def chunk((self, content: str)) -> list[Chunk]:

def chunk((self, content: str)) -> list[Chunk]:

def __init__((self, chunk_size: int)) -> None:

def _is_good_split_point((
        self, line_idx: int, line: str, brace_depth: int, paren_depth: int, in_string: bool
    )) -> bool:

def _track_code_structure((self, line: str)) -> tuple[int, int, bool, str | None]:

def chunk((self, content: str)) -> list[Chunk]:

def _is_valid_xml((self, content: str)) -> bool:

def _normalize_to_xml((self, content: str)) -> str:

def _escape_xml_text((self, text: str)) -> str:

def _find_element_boundaries((self, content: str)) -> list[tuple[int, int, int]]:

def chunk((self, content: str)) -> list[Chunk]:

def _wrap_chunk((self, elements: list[str])) -> str:

def get_chunking_strategy((data_format: str, chunk_size: int)) -> ChunkingStrategy:

def create_chunks((content: str, data_format: str, chunk_size: int)) -> list[Chunk]:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/cli.py
# Language: python

import builtins
import contextlib
import json
import os
import sys
from pathlib import Path
from cerebras.cloud.sdk import Cerebras
from dotenv import load_dotenv
from loguru import logger
from .api_client import explain_metadata_with_llm
from .cerebrate_file import (
    calculate_completion_budget,
    prepare_chunk_messages,
    process_document,
)
from .chunking import create_chunks
from .config import (
    setup_logging,
    validate_environment,
    validate_inputs,
    validate_recursive_inputs,
)
from .file_utils import (
    build_base_prompt,
    check_metadata_completeness,
    parse_frontmatter_content,
    read_file_safely,
    write_output_atomically,
)
from .models import ProcessingState
from .settings import get_settings
from .tokenizer import encode_text
from .ui import FileProgressDisplay
from .recursive import (
                find_files_recursive,
                pre_screen_files,
                process_files_parallel,
                replicate_directory_structure,
            )
from .ui import MultiFileProgressDisplay
from .models import ProcessingState

def run((
    input_data: str,
    output_data: str | None = None,
    file_prompt: str | None = None,
    prompt: str | None = None,
    chunk_size: int | None = None,
    max_tokens_ratio: int | None = None,
    data_format: str = "markdown",
    sample_size: int | None = None,
    temp: float | None = None,
    top_p: float | None = None,
    model: str | None = None,
    verbose: bool = False,
    explain: bool = False,
    dry_run: bool = False,
    recurse: str | None = None,
    workers: int = 4,
    force: bool = False,
)) -> None:

def _redirect_print_to_stderr(()):

def _streaming_print((*args, **kwargs)):

def _execute(()) -> None:

def process_file_wrapper((input_file: Path, output_file: Path)):

def file_progress_callback((chunks_done: int, remaining_calls: int)):

def update_progress((chunks_completed: int, remaining_calls: int)):

def _show_dry_run_analysis((
    chunks,
    data_format: str,
    base_prompt: str,
    base_prompt_tokens: int,
    sample_size: int,
    max_tokens_ratio: int,
    metadata,
)) -> None:

def _report_zero_output_failure((state: ProcessingState, input_path: str, output_path: str)) -> None:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/config.py
# Language: python

import os
import sys
from pathlib import Path
from loguru import logger
from .constants import (
    MAX_CONTEXT_TOKENS,
    MAX_OUTPUT_TOKENS,
    VALID_DATA_FORMATS,
    ConfigurationError,
    ValidationError,
)
from .settings import get_settings

DEFAULT_LOG_FORMAT = =

class EnvironmentConfig:
    def __init__((self)) -> None:
    def _load_environment((self)) -> None:
    def validate((self, strict: bool = True)) -> bool:
    def get_api_key((self)) -> str:

def __init__((self)) -> None:

def _load_environment((self)) -> None:

def validate((self, strict: bool = True)) -> bool:

def get_api_key((self)) -> str:

def setup_logging((verbose: bool = False, level: str | None = None)) -> None:

def validate_api_key((api_key: str)) -> bool:

def validate_environment((strict: bool = True)) -> None:

def validate_inputs((
    input_data: str,
    chunk_size: int,
    sample_size: int,
    max_tokens_ratio: int,
    data_format: str = "text",
    strict: bool = True,
)) -> None:

def get_environment_info(()) -> dict:

def validate_model_parameters((
    temperature: float,
    top_p: float,
    model: str,
    strict: bool = True,
)) -> None:

def validate_recursive_inputs((
    input_data: str,
    recurse: str,
    workers: int,
    output_data: str | None = None,
    strict: bool = True,
)) -> None:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/constants.py
# Language: python

import re
from re import Pattern
from typing import Any

MAX_CONTEXT_TOKENS = =
MAX_OUTPUT_TOKENS = =
DEFAULT_CHUNK_SIZE = =
MIN_COMPLETION_TOKENS = =
REASONING_COMPLETION_RATIO = =
REQUIRED_METADATA_FIELDS = :
METADATA_SCHEMA = :
CODE_BOUNDARY_PATTERNS = :
COMPILED_BOUNDARY_PATTERNS = :
CHARS_PER_TOKEN_FALLBACK = =
VALID_DATA_FORMATS = :
CONTINUITY_TEMPLATE = =

class CerebrateError(E, x, c, e, p, t, i, o, n):

class TokenizationError(C, e, r, e, b, r, a, t, e, E, r, r, o, r):

class ChunkingError(C, e, r, e, b, r, a, t, e, E, r, r, o, r):

class APIError(C, e, r, e, b, r, a, t, e, E, r, r, o, r):

class ValidationError(C, e, r, e, b, r, a, t, e, E, r, r, o, r):

class ConfigurationError(C, e, r, e, b, r, a, t, e, E, r, r, o, r):

class FileError(C, e, r, e, b, r, a, t, e, E, r, r, o, r):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/continuity.py
# Language: python

from loguru import logger
from .constants import CONTINUITY_TEMPLATE, MAX_CONTEXT_TOKENS
from .tokenizer import decode_tokens_safely, encode_text

class ContinuityManager:
    def __init__((self, sample_size: int = 200)) -> None:
    def update((
        self,
        input_text: str,
        output_text: str,
        input_tokens: list[int] | None = None,
        output_tokens: list[int] | None = None,
    )) -> None:
    def has_context((self)) -> bool:
    def get_continuity_block((self)) -> str | None:
    def get_fitted_continuity((
        self, base_input_tokens: int, max_input_tokens: int = MAX_CONTEXT_TOKENS
    )) -> str:
    def reset((self)) -> None:

def __init__((self, sample_size: int = 200)) -> None:

def update((
        self,
        input_text: str,
        output_text: str,
        input_tokens: list[int] | None = None,
        output_tokens: list[int] | None = None,
    )) -> None:

def has_context((self)) -> bool:

def get_continuity_block((self)) -> str | None:

def get_fitted_continuity((
        self, base_input_tokens: int, max_input_tokens: int = MAX_CONTEXT_TOKENS
    )) -> str:

def reset((self)) -> None:

def extract_continuity_examples((prev_text: str, prev_tokens: list[int], sample_size: int)) -> str:

def build_continuity_block((input_example: str, output_example: str)) -> str:

def fit_continuity_to_budget((
    continuity_block: str,
    base_input_tokens: int,
    max_input_tokens: int = MAX_CONTEXT_TOKENS,
)) -> str:

def calculate_continuity_budget((
    chunk_tokens: int,
    base_prompt_tokens: int,
    sample_size: int,
    max_context_tokens: int = MAX_CONTEXT_TOKENS,
)) -> int:


<document index="30">
<source>src/cerebrate_file/default_config.toml</source>
<document_content>
# this_file: src/cerebrate_file/default_config.toml
# Default configuration for cerebrate-file
#
# This file contains built-in defaults. Users can override these by:
# 1. Setting environment variables (e.g., CEREBRATE_PRIMARY_MODEL)
# 2. Creating a config file at ~/.config/cerebrate-file/config.toml
# 3. Creating a config file in the project directory as .cerebrate-file.toml

# ------------------------------------------------------------------------------
# INFERENCE SETTINGS
# Default parameters for model inference
# ------------------------------------------------------------------------------
[inference]
temperature = 0.98  # Sampling temperature (0.0-2.0)
top_p = 0.8  # Nucleus sampling parameter (0.0-1.0)
max_tokens_ratio = 100  # Completion budget as % of chunk size
chunk_size = 32000  # Target maximum input chunk size in tokens
sample_size = 200  # Number of tokens for continuity examples

# ------------------------------------------------------------------------------
# PRIMARY MODEL CONFIGURATION
# The primary model used for inference (Cerebras by default)
# ------------------------------------------------------------------------------
[models.primary]
name = "zai-glm-4.6"
provider = "cerebras"
api_key_env = "CEREBRAS_API_KEY"  # Environment variable containing API key
# api_base is not needed for Cerebras (uses SDK default)
# Model-specific limits
max_context_tokens = 131000
max_output_tokens = 40960

# ------------------------------------------------------------------------------
# FALLBACK MODELS
# Used when primary model hits rate limits (429) or quota errors
# Fallback chain: fallback1 -> fallback2 -> fallback3 (if configured)
#
# All fallback models use the OpenAI-compatible API format
# ------------------------------------------------------------------------------

[models.fallback1]
enabled = true  # Set to true to enable this fallback
name = "zai-org/GLM-4.6"  # Model name
provider = "chutes"  # Provider type (openai, together, groq, etc.)
api_key_env = "CHUTES_API_KEY"  # Environment variable containing API key
api_base = "https://llm.chutes.ai/v1"  # Optional: custom API base URL for OpenAI-compatible APIs
# Model-specific limits (adjust based on provider)
max_context_tokens = 131000
max_output_tokens = 40960

[models.fallback2]
enabled = true
name = "GLM-4.6"
provider = "arli"
api_key_env = "ARLIAI_TEXT_API_KEY"
api_base = "https://api.arliai.com/v1/"
max_context_tokens = 202752
max_output_tokens = 2048

# ------------------------------------------------------------------------------
# RATE LIMITING CONFIGURATION
# Safety margins and backoff settings
# ------------------------------------------------------------------------------
[rate_limiting]
tokens_safety_margin = 50000  # Reserve tokens for other instances
requests_safety_margin = 100  # Reserve requests for other instances
max_retry_attempts = 2  # Maximum retry attempts before fallback
fallback_on_rate_limit = true  # Whether to use fallback on rate limit errors
fallback_on_quota_exceeded = true  # Whether to use fallback on quota errors

# ------------------------------------------------------------------------------
# LOGGING CONFIGURATION
# ------------------------------------------------------------------------------
[logging]
format = "<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>"
</document_content>
</document>

# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/error_recovery.py
# Language: python

import functools
import json
import time
from collections.abc import Callable
from pathlib import Path
from typing import Any, TypeVar
from .constants import APIError, ValidationError
import random

T = =

class RetryConfig:
    def __init__((
        self,
        max_attempts: int = 3,
        base_delay: float = 1.0,
        max_delay: float = 30.0,
        exponential_base: float = 2.0,
        jitter: bool = True,
    )):
    def get_delay((self, attempt: int)) -> float:

class RecoverableOperation:
    def __init__((
        self,
        operation_name: str,
        checkpoint_interval: int = 10,
        enable_checkpoints: bool = True,
    )):
    def __enter__((self)):
    def __exit__((self, exc_type, exc_val, exc_tb)):
    def update((self, **kwargs)):
    def should_skip((self, item_id: Any)) -> bool:

def __init__((
        self,
        max_attempts: int = 3,
        base_delay: float = 1.0,
        max_delay: float = 30.0,
        exponential_base: float = 2.0,
        jitter: bool = True,
    )):

def get_delay((self, attempt: int)) -> float:

def with_retry((
    func: Callable | None = None,
    *,
    config: RetryConfig | None = None,
    retryable_errors: tuple = (APIError, ConnectionError, TimeoutError),
    on_retry: Callable[[Exception, int], None] | None = None,
)) -> Callable:

def decorator((f: Callable[..., T])) -> Callable[..., T]:

def wrapper((*args, **kwargs)) -> T:

def format_error_with_suggestions((error: Exception)) -> Exception:

def format_error_message((error: Exception)) -> str:

def save_checkpoint((
    data: dict,
    checkpoint_dir: str = ".cerebrate_checkpoints",
    checkpoint_name: str = "checkpoint",
)) -> Path:

def load_checkpoint((
    checkpoint_dir: str = ".cerebrate_checkpoints",
    checkpoint_name: str = "checkpoint",
    max_age_hours: float = 24,
)) -> dict | None:

def check_optional_dependency((
    module_name: str,
    package_name: str | None = None,
    feature_name: str | None = None,
)) -> tuple[bool, str | None]:

def __init__((
        self,
        operation_name: str,
        checkpoint_interval: int = 10,
        enable_checkpoints: bool = True,
    )):

def __enter__((self)):

def __exit__((self, exc_type, exc_val, exc_tb)):

def update((self, **kwargs)):

def should_skip((self, item_id: Any)) -> bool:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/file_utils.py
# Language: python

import contextlib
import sys
import tempfile
from pathlib import Path
from typing import Any
import frontmatter
from loguru import logger
from .constants import REQUIRED_METADATA_FIELDS, FileError
from .tokenizer import encode_text
from .prompt_library import resolve_prompt_file

def read_file_safely((file_path: str | Path)) -> str:

def ensure_parent_directory((file_path: str | Path)) -> None:

def backup_file((file_path: str | Path, backup_suffix: str = ".bak")) -> Path | None:

def write_output_atomically((
    content: str,
    output_path: str | Path,
    metadata: dict[str, Any] | None = None,
    create_backup: bool = False,
)) -> None:

def parse_frontmatter_content((content: str)) -> tuple[dict[str, Any], str]:

def check_metadata_completeness((metadata: dict[str, Any])) -> tuple[bool, list[str]]:

def validate_file_path((file_path: str | Path, must_exist: bool = True)) -> Path:

def get_file_info((file_path: str | Path)) -> dict[str, Any]:

def output_file_exists((input_path: Path, output_path: Path)) -> bool:

def build_base_prompt((file_prompt: str | None, text_prompt: str | None)) -> tuple[str, int]:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/models.py
# Language: python

from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any, Optional

class Chunk:
    def __len__((self)) -> int:
    def is_empty((self)) -> bool:

class ChunkDiagnostics:
    def to_log_dict((self)) -> dict[str, Any]:

class RateLimitStatus:
    def __post_init__((self)) -> None:
    def is_tokens_exhausted((self, next_request_tokens: int = 0)) -> bool:
    def is_requests_exhausted((self)) -> bool:
    def time_until_token_reset((self)) -> float:
    def time_until_request_reset((self)) -> float:

class ProcessingState:
    def update_from_chunk((
        self,
        input_text: str,
        input_tokens: list[int],
        output_text: str,
        output_tokens: list[int],
        total_input_tokens: int,
    )) -> None:
    def get_average_input_tokens((self)) -> float:
    def get_average_output_tokens((self)) -> float:
    def has_previous_context((self)) -> bool:
    def add_chunk_diagnostic((self, diagnostic: ChunkDiagnostics)) -> None:

class ProcessingResult:
    def add_error((self, error: str)) -> None:
    def has_errors((self)) -> bool:
    def get_tokens_per_second((self)) -> float:

class ChunkingConfig:
    def __post_init__((self)) -> None:

class APIConfig:
    def __post_init__((self)) -> None:

def __len__((self)) -> int:

def is_empty((self)) -> bool:

def to_log_dict((self)) -> dict[str, Any]:

def __post_init__((self)) -> None:

def is_tokens_exhausted((self, next_request_tokens: int = 0)) -> bool:

def is_requests_exhausted((self)) -> bool:

def time_until_token_reset((self)) -> float:

def time_until_request_reset((self)) -> float:

def update_from_chunk((
        self,
        input_text: str,
        input_tokens: list[int],
        output_text: str,
        output_tokens: list[int],
        total_input_tokens: int,
    )) -> None:

def get_average_input_tokens((self)) -> float:

def get_average_output_tokens((self)) -> float:

def has_previous_context((self)) -> bool:

def add_chunk_diagnostic((self, diagnostic: ChunkDiagnostics)) -> None:

def add_error((self, error: str)) -> None:

def has_errors((self)) -> bool:

def get_tokens_per_second((self)) -> float:

def __post_init__((self)) -> None:

def __post_init__((self)) -> None:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/prompt_library.py
# Language: python

from pathlib import Path
from loguru import logger
import cerebrate_file

def get_prompt_library_path(()) -> Path:

def resolve_prompt_file((file_prompt: str)) -> Path | None:


<document index="31">
<source>src/cerebrate_file/prompts/README.md</source>
<document_content>
# Prompt Library

This directory contains pre-configured prompts for common use cases with `cerebrate-file`.

## Available Prompts

### fix-pdf-extracted-text.xml
**Purpose**: Clean up poorly extracted PDF text  
**Usage**: `cerebrate-file input.txt --file-prompt fix-pdf-extracted-text.xml`

Fixes common PDF extraction issues:
- Line-ending hyphens (e.g., "docu-\nment" â†’ "document")
- Page numbers, headers, footers
- OCR errors and character substitutions
- Broken paragraph formatting
- Outputs clean Markdown

## Using Prompts

Reference prompts in three ways:

1. **By name** (for library prompts):
   ```bash
   cerebrate-file input.txt --file-prompt fix-pdf-extracted-text.xml
   ```

2. **By absolute path** (for custom prompts):
   ```bash
   cerebrate-file input.txt --file-prompt /path/to/custom-prompt.xml
   ```

3. **By relative path** (for project-specific prompts):
   ```bash
   cerebrate-file input.txt --file-prompt ./prompts/my-prompt.xml
   ```

## Adding Custom Prompts

Add your own prompts to the library:

1. Create your prompt file with any extension (`.xml`, `.txt`, `.md`, etc.)
2. Place it in this directory
3. Reinstall the package to make it available by name

## Prompt Format

Prompts can be any text format. The POML format used in `fix-pdf-extracted-text.xml` provides structured instructions, but plain text works fine too.

## Combining Prompts

Combine library prompts with additional instructions:

```bash
cerebrate-file input.txt \
  --file-prompt fix-pdf-extracted-text.xml \
  --prompt "Also translate to Spanish"
```

The file prompt loads first, then the text prompt.
</document_content>
</document>

<document index="32">
<source>src/cerebrate_file/prompts/fix-pdf-extracted-text.xml</source>
<document_content>
<poml><role>You are a meticulous document restoration specialist who cleans up poorly extracted PDF        text while preserving every word of the original content.</role><task>Clean and format extracted PDF text into proper Markdown while maintaining absolute        fidelity to the original content.</task><h>Processing Instructions</h><stepwise-instructions><list listStyle="decimal"><item><b>Line Merging:</b><list><item>Join lines that were artificially broken mid-sentence by PDF column width</item><item>Preserve intentional line breaks between paragraphs</item><item>Maintain list structures and indentation where clearly intended</item></list></item><item><b>Structure & pagination:</b><list><item>Remove empty paragraphs</item><item>Remove visible page numbers, headers, and footers</item><item>If page numbers or page breaks exist in the source, only retain then in                        form of a free-standing separate line that says `<a id="page_NNN"></a>`                        (where NNN is the page number), with a newline above and a newline below,                        and move them down (that is, place them before the first paragraph of the                        page, separating with a newline).</item><item>Join paragraphs that were artificially broken, especially due to column or                        page breaks. If a page break existed mid-paragraph, move the page break                        after the paragraph.</item><item>Preserve all narrative content parts, including table-of-contents,                        footnotes, and other content that is not part of the main text. Only remove                        visible page numbers, headers, and footers that make no sense in a                        non-paginated document.</item></list></item><item><b>Artifact Removal:</b><list><item>Remove hard hyphenation at line endings (e.g., "docu-\nment" â†’ "document")</item><item>Delete page numbers, headers, and footers that repeat across pages</item><item>Remove garbled character sequences that are clearly extraction errors                        (e.g., "â– â–¡â–ªâ–«" or "????")</item><item>Clean up spacing artifacts (multiple spaces, tabs mixed with spaces)</item></list></item><item><b>OCR Correction:</b><list><item>Fix obvious character substitution errors (e.g., "rn" misread as "m", "cl"                        as "d")</item><item>Correct clearly misspelled words only when the intended word is                        unambiguous</item><item>Fix number/letter confusion in obvious contexts (e.g., "0" vs "O", "1" vs                        "l")</item><item>If itâ€™s obvious from the context, fix the writing system of the text (Ğ¡Ğ¡Ğ¡Ğ                         and not CCCP)</item><item>If itâ€™s obvious from the context, enrich text with diacritics that have                        been omitted lazily (e.g. write WaÅ‚Ä™sa and not Walesa)</item></list></item><item><b>Orthotypography:</b><list><item>Use proper high-end punctuation, especially the correct typographic                        quotation marks appropriate for the language of the text.</item><item>Use em dashes appropriately, but ALWAYS separate them by spaces from                        neighboring text on left and right. Never glue an em dash directly to a                        word.</item><item>Use en dashes (without surrounding spaces) to indicate ranges or spans.</item><item>However, do not overcorrect punctuation.</item></list></item><item><b>Markdown Formatting (Conservative):</b><list><item>Add heading markers (#, ##, etc.) ONLY for text that is clearly a title or                        section header</item><item>Use **bold** ONLY where emphasis was clearly intended in the original</item><item>Format obvious lists with - or 1. notation</item><item>Use code blocks for clearly technical content or code samples</item><item>Add blockquotes (>) for clearly quoted material</item><item>Use Markdown tables if you know what youâ€™re doing</item></list></item></list></stepwise-instructions><cp caption="Critical Preservation Rules"><list><item>NEVER delete sentences, phrases, or meaningful words</item><item>NEVER paraphrase or rewrite sentences for clarity</item><item>NEVER add explanatory text or context</item><item>NEVER change technical terms, proper nouns, or specialized vocabulary</item><item>NEVER merge or split paragraphs unless fixing obvious extraction errors</item><item>PRESERVE all numerical data exactly as written</item></list></cp><examples><example caption="Line merge correction"><input>The quick brown fox jum-                ped over the lazy dog which                was sleeping in the garden.</input><output>The quick brown fox jumped over the lazy dog which was sleeping in the garden.</output></example><example caption="OCR and formatting"><input>Chapter l: lntroduction                This chapfer discusses the rnain concepts...</input><output># Chapter 1: Introduction                This chapter discusses the main concepts...</output></example><example caption="Artifact removal"><input>The reportâ– â–¡â–ª shows that sales                - - - Page 42 - - -                increased by 15% this quarter.</input><output>The report shows that sales increased by 15% this quarter.</output></example></examples><cp caption="Decision Framework"><p>When uncertain about whether text is an error or intentional:</p><list><item>If it could be meaningful content â†’ KEEP IT</item><item>If clearly garbled/repeated/artifactual â†’ REMOVE IT</item><item>If unsure about formatting â†’ LEAVE UNFORMATTED</item><item>If unsure about spelling â†’ KEEP ORIGINAL</item></list></cp><output-format>Clean Markdown text with proper paragraph separation, conservative heading        hierarchy, minimal formatting markup, all original content preserved</output-format></poml>
</document_content>
</document>

# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/recursive.py
# Language: python

import re
from collections.abc import Callable
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from loguru import logger
from .models import ProcessingState
from .file_utils import output_file_exists

class ProcessingResult:
    def __init__((self)) -> None:

def __init__((self)) -> None:

def pre_screen_files((file_pairs: list[tuple[Path, Path]], force: bool)) -> list[tuple[Path, Path]]:

def expand_brace_patterns((pattern: str)) -> list[str]:

def find_files_recursive((
    input_dir: Path, pattern: str, output_dir: Path | None = None
)) -> list[tuple[Path, Path]]:

def replicate_directory_structure((file_pairs: list[tuple[Path, Path]])) -> None:

def process_single_file((
    input_path: Path,
    output_path: Path,
    processing_func: Callable[[Path, Path], ProcessingState],
    progress_callback: Callable[[str, int], None] | None = None,
)) -> tuple[Path, Path, ProcessingState, Exception | None]:

def process_files_parallel((
    file_pairs: list[tuple[Path, Path]],
    processing_func: Callable[[Path, Path], ProcessingState],
    workers: int = 4,
    progress_callback: Callable[[str, int], None] | None = None,
)) -> ProcessingResult:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/settings.py
# Language: python

import os
from dataclasses import dataclass, field
from functools import lru_cache
from pathlib import Path
from typing import Any
from loguru import logger
import tomllib
import tomli as tomllib

class ModelConfig:
    def get_api_key((self)) -> str | None:
    def is_available((self)) -> bool:

class InferenceConfig:

class RateLimitConfig:

class Settings:
    def get_model_by_name((self, name: str)) -> ModelConfig | None:
    def get_available_fallbacks((self)) -> list[ModelConfig]:
    def get_default_model_name((self)) -> str:

def get_api_key((self)) -> str | None:

def is_available((self)) -> bool:

def get_model_by_name((self, name: str)) -> ModelConfig | None:

def get_available_fallbacks((self)) -> list[ModelConfig]:

def get_default_model_name((self)) -> str:

def _load_toml_file((path: Path)) -> dict[str, Any]:

def _deep_merge((base: dict[str, Any], override: dict[str, Any])) -> dict[str, Any]:

def _parse_model_config((data: dict[str, Any], key: str = "primary")) -> ModelConfig | None:

def _parse_fallback_models((models_data: dict[str, Any])) -> list[ModelConfig]:

def _apply_env_overrides((settings: Settings)) -> None:

def _load_settings_impl(()) -> Settings:

def get_settings(()) -> Settings:

def reload_settings(()) -> Settings:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/tokenizer.py
# Language: python

from loguru import logger
from .constants import CHARS_PER_TOKEN_FALLBACK, TokenizationError
from qwen_tokenizer import get_tokenizer

class TokenizerManager:
    def __init__((self, model_name: str = "qwen-max", strict: bool = False)) -> None:
    def _initialize_tokenizer((self)) -> None:
    def encode((self, text: str)) -> list[int]:
    def decode((self, tokens: list[int])) -> str:
    def estimate_tokens((self, text: str)) -> int:
    def get_info((self)) -> dict:

def __init__((self, model_name: str = "qwen-max", strict: bool = False)) -> None:

def _initialize_tokenizer((self)) -> None:

def is_available((self)) -> bool:

def is_fallback((self)) -> bool:

def encode((self, text: str)) -> list[int]:

def decode((self, tokens: list[int])) -> str:

def estimate_tokens((self, text: str)) -> int:

def get_info((self)) -> dict:

def get_tokenizer_manager(()) -> TokenizerManager:

def encode_text((text: str)) -> list[int]:

def decode_tokens_safely((tokens: list[int])) -> str:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/ui.py
# Language: python

from loguru import logger
from rich.console import Console
from rich.progress import BarColumn, Progress, TextColumn
from rich.text import Text

class FileProgressDisplay:
    def __init__((self, console: Console | None = None)):
    def start_file_processing((self, input_path: str, output_path: str, total_chunks: int)) -> None:
    def update_progress((self, chunks_completed: int, remaining_calls: int = 0)) -> None:
    def finish_file_processing((self)) -> None:
    def _update_display((self)) -> None:
    def _show_completion((self)) -> None:

class MultiFileProgressDisplay:
    def __init__((self, console: Console | None = None)):
    def start_overall_processing((self, total_files: int)) -> None:
    def start_file((self, input_path: str, output_path: str, total_chunks: int)) -> None:
    def update_file_progress((
        self, input_path: str, chunks_completed: int, remaining_calls: int = 0
    )) -> None:
    def finish_file((self, input_path: str)) -> None:
    def finish_overall_processing((self)) -> None:

def __init__((self, console: Console | None = None)):

def start_file_processing((self, input_path: str, output_path: str, total_chunks: int)) -> None:

def update_progress((self, chunks_completed: int, remaining_calls: int = 0)) -> None:

def finish_file_processing((self)) -> None:

def _update_display((self)) -> None:

def _show_completion((self)) -> None:

def __init__((self, console: Console | None = None)):

def start_overall_processing((self, total_files: int)) -> None:

def start_file((self, input_path: str, output_path: str, total_chunks: int)) -> None:

def update_file_progress((
        self, input_path: str, chunks_completed: int, remaining_calls: int = 0
    )) -> None:

def finish_file((self, input_path: str)) -> None:

def finish_overall_processing((self)) -> None:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/src/cerebrate_file/validators.py
# Language: python

import contextlib
import os
from pathlib import Path
from .constants import MAX_CONTEXT_TOKENS, ValidationError

MIN_CHUNK_SIZE = =
MAX_CHUNK_SIZE = =
MIN_TEMPERATURE = =
MAX_TEMPERATURE = =
MIN_TOP_P = =
MAX_TOP_P = =
MAX_FILE_SIZE_MB = =
MAX_FILE_SIZE_BYTES = =

def validate_chunk_size((chunk_size: int)) -> int:

def validate_temperature((temperature: float)) -> float:

def validate_top_p((top_p: float)) -> float:

def validate_file_size((file_path: str)) -> None:

def validate_file_path_safe((file_path: str)) -> Path:

def validate_model_parameters((
    chunk_size: int,
    temperature: float,
    top_p: float,
    max_tokens_ratio: int,
)) -> tuple[int, float, float, int]:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/test_retry_mechanism.py
# Language: python

import sys
from unittest.mock import Mock
from cerebrate_file.constants import APIError
from cerebrate_file.api_client import make_cerebras_request

def test_503_retry(()):

def side_effect((*args, **kwargs)):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/testapi.py
# Language: python

import os
import sys
from pathlib import Path
from cerebras.cloud.sdk import Cerebras

def main(()) -> int:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_api_retry.py
# Language: python

from unittest.mock import Mock, patch
import pytest
from cerebrate_file.api_client import make_cerebras_request
from cerebrate_file.constants import APIError
from cerebrate_file.models import RateLimitStatus
from cerebrate_file.api_client import make_request_with_fallback

class MockAPIStatusError(E, x, c, e, p, t, i, o, n):
    def __init__((self, status_code, response)):

class DummyStream(l, i, s, t):

def __init__((self, status_code, response)):

def test_503_error_triggers_retry(()):

def test_non_retryable_errors_not_converted(()):

def test_retryable_status_codes(()):

def test_successful_request(()):

def test_full_retry_flow((mocker)):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_brace_patterns.py
# Language: python

import pytest
from cerebrate_file.recursive import expand_brace_patterns

class TestBracePatternExpansion:
    def test_simple_brace_pattern((self)):
    def test_complex_brace_pattern((self)):
    def test_single_extension((self)):
    def test_no_braces((self)):
    def test_empty_options((self)):
    def test_whitespace_in_options((self)):
    def test_nested_directories((self)):
    def test_multiple_directory_levels((self)):
    def test_mixed_patterns((self)):
    def test_malformed_braces((self)):
    def test_empty_braces((self)):
    def test_numeric_extensions((self)):

def test_simple_brace_pattern((self)):

def test_complex_brace_pattern((self)):

def test_single_extension((self)):

def test_no_braces((self)):

def test_empty_options((self)):

def test_whitespace_in_options((self)):

def test_nested_directories((self)):

def test_multiple_directory_levels((self)):

def test_mixed_patterns((self)):

def test_malformed_braces((self)):

def test_empty_braces((self)):

def test_numeric_extensions((self)):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_cerebrate_file.py
# Language: python

import math
from cerebrate_file.cerebrate_file import calculate_completion_budget
from cerebrate_file.constants import (
    MAX_OUTPUT_TOKENS,
    MIN_COMPLETION_TOKENS,
    REASONING_COMPLETION_RATIO,
)

def test_calculate_completion_budget_enforces_minimum_floor(()) -> None:

def test_calculate_completion_budget_applies_reasoning_multiplier(()) -> None:

def test_calculate_completion_budget_caps_at_max_output(()) -> None:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_chunking.py
# Language: python

import pytest
from cerebrate_file.chunking import (
    ChunkingStrategy,
    CodeChunker,
    MarkdownChunker,
    SemanticChunker,
    TextChunker,
    create_chunks,
    get_chunking_strategy,
)
from cerebrate_file.models import Chunk, ChunkingConfig
from cerebrate_file.tokenizer import get_tokenizer_manager

def sample_text(()):

def sample_markdown(()):

def sample_code(()):

def chunking_config(()):

def test_text_chunker_creation(()):

def test_text_chunker_basic_chunking((sample_text)):

def test_semantic_chunker_creation(()):

def test_markdown_chunker_creation(()):

def test_markdown_chunker_with_headers((sample_markdown)):

def test_code_chunker_creation(()):

def test_code_chunker_with_functions((sample_code)):

def test_create_chunks_function((sample_text)):

def test_create_chunks_with_different_formats((sample_text)):

def test_get_chunking_strategy(()):

def test_chunking_with_empty_text(()):

def test_chunking_with_very_large_chunk_size((sample_text)):

def test_chunking_with_very_small_chunk_size(()):

def test_chunk_token_counts((sample_text)):

def test_chunk_text_content((sample_text)):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_cli_streams.py
# Language: python

import io
from types import SimpleNamespace
from unittest.mock import patch
import pytest
from cerebrate_file.cli import run as cli_run

def stubbed_chunks(()) -> list:

def _stub_state(()) -> SimpleNamespace:

def test_cli_run_streams_stdin_to_stdout((
    monkeypatch: pytest.MonkeyPatch, stubbed_chunks: list, capsys: pytest.CaptureFixture[str]
)) -> None:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_constants.py
# Language: python

import pytest
from cerebrate_file.constants import (
    CODE_BOUNDARY_PATTERNS,
    COMPILED_BOUNDARY_PATTERNS,
    DEFAULT_CHUNK_SIZE,
    MAX_CONTEXT_TOKENS,
    MAX_OUTPUT_TOKENS,
    METADATA_SCHEMA,
    REQUIRED_METADATA_FIELDS,
    APIError,
    CerebrateError,
    ChunkingError,
    TokenizationError,
    ValidationError,
)

def test_constants_values(()):

def test_required_metadata_fields(()):

def test_metadata_schema(()):

def test_error_classes(()):

def test_boundary_patterns(()):

def test_cerebrate_error(()):

def test_specific_error_classes(()):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_error_recovery.py
# Language: python

import json
import tempfile
import time
from pathlib import Path
from unittest.mock import Mock, patch
import pytest
from cerebrate_file.constants import APIError, ValidationError
from cerebrate_file.error_recovery import (
    RecoverableOperation,
    RetryConfig,
    check_optional_dependency,
    format_error_message,
    format_error_with_suggestions,
    load_checkpoint,
    save_checkpoint,
    with_retry,
)

def test_retry_config_default(()):

def test_retry_config_get_delay(()):

def test_retry_config_max_delay(()):

def test_with_retry_success_first_try(()):

def test_func(()):

def test_with_retry_success_after_failures(()):

def test_func(()):

def test_with_retry_all_attempts_fail(()):

def test_func(()):

def test_with_retry_non_retryable_error(()):

def test_func(()):

def test_format_error_with_suggestions_api_error(()):

def test_format_error_with_suggestions_file_error(()):

def test_format_error_with_suggestions_validation_chunk_size(()):

def test_format_error_message(()):

def test_save_and_load_checkpoint(()):

def test_load_checkpoint_not_found(()):

def test_load_checkpoint_expired(()):

def test_check_optional_dependency_available(()):

def test_check_optional_dependency_missing(()):

def test_check_optional_dependency_with_feature(()):

def test_recoverable_operation_no_checkpoint(()):

def test_recoverable_operation_with_checkpoint(()):

def test_recoverable_operation_should_skip(()):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_file_utils.py
# Language: python

import io
import tempfile
from pathlib import Path
import pytest
from cerebrate_file.file_utils import read_file_safely, write_output_atomically

def temporary_text_file(()) -> Path:

def test_read_file_safely_when_path_dash_reads_from_stdin((monkeypatch: pytest.MonkeyPatch)) -> None:

def test_write_output_atomically_when_path_dash_writes_to_stdout((
    monkeypatch: pytest.MonkeyPatch,
)) -> None:

def test_write_output_atomically_when_path_dash_preserves_metadata((
    monkeypatch: pytest.MonkeyPatch,
)) -> None:

def test_read_file_safely_reads_regular_files((temporary_text_file: Path)) -> None:

def test_write_output_atomically_writes_regular_files((monkeypatch: pytest.MonkeyPatch)) -> None:


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_force_option.py
# Language: python

import tempfile
from pathlib import Path
from unittest.mock import patch
import pytest
from cerebrate_file.cli import run as cli_run

def sample_input_file(()):

def existing_output_file(()):

def temp_directory(()):

def test_force_option_when_output_exists_single_file((sample_input_file, existing_output_file)):

def test_force_option_when_output_exists_force_true((sample_input_file, existing_output_file)):

def test_force_option_when_input_equals_output((sample_input_file)):

def test_force_option_when_output_does_not_exist((sample_input_file)):

def test_force_option_recursive_mode((temp_directory)):

def test_force_option_dry_run_mode((sample_input_file, existing_output_file)):

def test_force_option_parameter_validation(()):

def test_force_option_logged_messages((sample_input_file, existing_output_file, capsys)):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_integration.py
# Language: python

import os
import tempfile
from pathlib import Path
from unittest.mock import Mock, patch
import pytest
from cerebrate_file.cerebrate_file import process_document
from cerebrate_file.chunking import create_chunks
from cerebrate_file.config import setup_logging, validate_inputs
from cerebrate_file.file_utils import read_file_safely, write_output_atomically
from cerebrate_file.models import APIConfig, ChunkingConfig
from cerebrate_file.cli import run as cli_run
from cerebrate_file.cli import run as cli_run
from cerebrate_file.cli import run as cli_run
from cerebrate_file.cli import run as cli_run

def sample_text_file(()):

def mock_api_response(()):

def test_full_pipeline_dry_run((sample_text_file)):

def test_file_io_operations((sample_text_file)):

def test_chunking_pipeline(()):

def test_configuration_validation(()):

def test_api_client_integration((mock_client_class, sample_text_file)):

def test_error_handling_pipeline(()):

def test_markdown_with_frontmatter(()):

def test_code_chunking_integration(()):

def test_large_file_handling(()):

def test_continuity_preservation(()):

def test_cli_environment_integration(()):

def test_explain_mode_integration(()):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_issue_104.py
# Language: python

import tempfile
from pathlib import Path
import pytest
from cerebrate_file.api_client import parse_rate_limit_headers
from cerebrate_file.file_utils import write_output_atomically
from cerebrate_file.models import Chunk, ProcessingState, RateLimitStatus
from cerebrate_file.file_utils import check_metadata_completeness

def test_call_counting_bug(()):

def test_frontmatter_missing_when_metadata_empty(()):

def test_frontmatter_not_written_when_metadata_none(()):

def test_chunk_processing_double_processing_issue(()):

def mock_llm_call((chunk_text)):

def test_progress_callback_uses_correct_remaining_count(()):

def mock_progress_callback((chunks_completed, remaining_calls)):

def test_call_counting_issue_debug(()):

def test_explain_mode_metadata_completeness_check(()):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_models.py
# Language: python

from datetime import datetime, timedelta
import pytest
from cerebrate_file.models import (
    APIConfig,
    Chunk,
    ChunkDiagnostics,
    ChunkingConfig,
    ProcessingResult,
    ProcessingState,
    RateLimitStatus,
)

def test_chunk_creation(()):

def test_chunk_with_metadata(()):

def test_chunk_empty(()):

def test_rate_limit_status(()):

def test_processing_state(()):

def test_processing_result(()):

def test_chunking_config(()):

def test_api_config(()):

def test_chunk_diagnostics_to_log_dict(()):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_package.py
# Language: python

import cerebrate_file

def test_version(()):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_pre_screening.py
# Language: python

from pathlib import Path
from unittest.mock import patch
import pytest
from cerebrate_file.file_utils import output_file_exists
from cerebrate_file.recursive import pre_screen_files

class TestOutputFileExists:
    def test_output_file_exists_when_same_path((self, tmp_path)):
    def test_output_file_exists_when_output_exists((self, tmp_path)):
    def test_output_file_exists_when_output_missing((self, tmp_path)):
    def test_output_file_exists_handles_permission_error((self, tmp_path)):

class TestPreScreenFiles:
    def test_pre_screen_files_with_force_true((self, tmp_path)):
    def test_pre_screen_files_with_force_false_no_existing_outputs((self, tmp_path)):
    def test_pre_screen_files_with_force_false_some_existing_outputs((self, tmp_path)):
    def test_pre_screen_files_with_force_false_all_existing_outputs((self, tmp_path)):
    def test_pre_screen_files_with_empty_list((self)):
    def test_pre_screen_files_with_in_place_processing((self, tmp_path)):
    def test_pre_screen_files_logs_appropriately((self, tmp_path)):

def test_output_file_exists_when_same_path((self, tmp_path)):

def test_output_file_exists_when_output_exists((self, tmp_path)):

def test_output_file_exists_when_output_missing((self, tmp_path)):

def test_output_file_exists_handles_permission_error((self, tmp_path)):

def test_pre_screen_files_with_force_true((self, tmp_path)):

def test_pre_screen_files_with_force_false_no_existing_outputs((self, tmp_path)):

def test_pre_screen_files_with_force_false_some_existing_outputs((self, tmp_path)):

def test_pre_screen_files_with_force_false_all_existing_outputs((self, tmp_path)):

def test_pre_screen_files_with_empty_list((self)):

def test_pre_screen_files_with_in_place_processing((self, tmp_path)):

def test_pre_screen_files_logs_appropriately((self, tmp_path)):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_pre_screening_integration.py
# Language: python

from unittest.mock import MagicMock, patch
import pytest
from cerebrate_file.cli import run

class TestPreScreeningIntegration:
    def test_recursive_pre_screening_with_existing_outputs((self, tmp_path, capsys)):
    def test_recursive_pre_screening_with_force_true((self, tmp_path, capsys)):
    def test_recursive_pre_screening_all_files_filtered((self, tmp_path, capsys)):
    def test_recursive_pre_screening_dry_run_mode((self, tmp_path, capsys)):
    def test_recursive_pre_screening_in_place_processing((self, tmp_path, capsys)):

def test_recursive_pre_screening_with_existing_outputs((self, tmp_path, capsys)):

def test_recursive_pre_screening_with_force_true((self, tmp_path, capsys)):

def test_recursive_pre_screening_all_files_filtered((self, tmp_path, capsys)):

def test_recursive_pre_screening_dry_run_mode((self, tmp_path, capsys)):

def test_recursive_pre_screening_in_place_processing((self, tmp_path, capsys)):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_prompt_library.py
# Language: python

from pathlib import Path
from unittest.mock import MagicMock, patch
import pytest
from cerebrate_file.file_utils import build_base_prompt
from cerebrate_file.prompt_library import (
    get_prompt_library_path,
    resolve_prompt_file,
)
from cerebrate_file.cli import run

class TestPromptLibrary:
    def test_get_prompt_library_path((self)):
    def test_resolve_prompt_file_direct_path((self, tmp_path)):
    def test_resolve_prompt_file_from_library((self)):
    def test_resolve_prompt_file_not_found((self)):
    def test_resolve_prompt_file_with_path_fallback((self)):
    def test_build_base_prompt_with_library_file((self)):
    def test_build_base_prompt_with_direct_file((self, tmp_path)):
    def test_build_base_prompt_with_missing_file((self)):

class TestPromptLibraryIntegration:
    def test_cli_can_use_library_prompt((self, tmp_path)):
    def test_prompt_library_listing((self, capsys)):

def test_get_prompt_library_path((self)):

def test_resolve_prompt_file_direct_path((self, tmp_path)):

def test_resolve_prompt_file_from_library((self)):

def test_resolve_prompt_file_not_found((self)):

def test_resolve_prompt_file_with_path_fallback((self)):

def test_build_base_prompt_with_library_file((self)):

def test_build_base_prompt_with_direct_file((self, tmp_path)):

def test_build_base_prompt_with_missing_file((self)):

def test_cli_can_use_library_prompt((self, tmp_path)):

def test_prompt_library_listing((self, capsys)):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_recursive.py
# Language: python

import tempfile
from pathlib import Path
from unittest.mock import MagicMock, Mock, patch
import pytest
from cerebrate_file.models import ProcessingState
from cerebrate_file.recursive import (
    ProcessingResult,
    find_files_recursive,
    process_files_parallel,
    process_single_file,
    replicate_directory_structure,
)

class TestFindFilesRecursive:
    def test_find_files_with_simple_pattern((self)):
    def test_find_files_with_recursive_pattern((self)):
    def test_find_files_with_output_directory((self)):
    def test_find_files_no_matches((self)):
    def test_find_files_nonexistent_directory((self)):
    def test_find_files_not_directory((self)):

class TestReplicateDirectoryStructure:
    def test_replicate_simple_structure((self)):
    def test_replicate_existing_directories((self)):
    def test_replicate_empty_list((self)):

class TestProcessSingleFile:
    def test_process_successful((self)):
    def test_process_with_exception((self)):

class TestProcessFilesParallel:
    def test_parallel_processing_success((self)):
    def test_parallel_processing_with_failures((self)):
    def test_parallel_processing_empty_list((self)):
    def test_parallel_processing_with_progress((self)):

class TestProcessingResult:
    def test_initialization((self)):

class TestRecursiveIntegration:

def test_find_files_with_simple_pattern((self)):

def test_find_files_with_recursive_pattern((self)):

def test_find_files_with_output_directory((self)):

def test_find_files_no_matches((self)):

def test_find_files_nonexistent_directory((self)):

def test_find_files_not_directory((self)):

def test_replicate_simple_structure((self)):

def test_replicate_existing_directories((self)):

def test_replicate_empty_list((self)):

def test_process_successful((self)):

def test_process_with_exception((self)):

def test_parallel_processing_success((self)):

def mock_process((input_path: Path, output_path: Path)):

def test_parallel_processing_with_failures((self)):

def mock_process((input_path: Path, output_path: Path)):

def test_parallel_processing_empty_list((self)):

def test_parallel_processing_with_progress((self)):

def mock_process((input_path: Path, output_path: Path)):

def test_initialization((self)):

def test_full_recursive_workflow((self, mock_executor)):

def mock_process((input_path: Path, output_path: Path)):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_recursive_integration.py
# Language: python

import tempfile
from pathlib import Path
import pytest
from cerebrate_file.models import ProcessingState
from cerebrate_file.recursive import (
    ProcessingResult,
    find_files_recursive,
    process_files_parallel,
    replicate_directory_structure,
)

class TestRecursiveIntegration:
    def test_simple_markdown_processing((self, temp_dir_structure)):
    def test_complex_glob_patterns((self, temp_dir_structure)):
    def test_directory_structure_replication((self, temp_dir_structure)):
    def test_pattern_edge_cases((self, temp_dir_structure)):
    def test_in_place_processing((self, temp_dir_structure)):
    def test_parallel_processing_mock((self, temp_dir_structure)):
    def test_parallel_processing_with_failures((self, temp_dir_structure)):
    def test_empty_directory_handling((self)):
    def test_special_characters_in_filenames((self)):
    def test_error_handling_invalid_directory((self)):
    def test_progress_callback_integration((self, temp_dir_structure)):
    def test_worker_count_variation((self, temp_dir_structure)):
    def test_large_file_set_simulation((self)):

def temp_dir_structure((self)):

def test_simple_markdown_processing((self, temp_dir_structure)):

def test_complex_glob_patterns((self, temp_dir_structure)):

def test_directory_structure_replication((self, temp_dir_structure)):

def test_pattern_edge_cases((self, temp_dir_structure)):

def test_in_place_processing((self, temp_dir_structure)):

def test_parallel_processing_mock((self, temp_dir_structure)):

def mock_processing_func((input_path: Path, output_path: Path)) -> ProcessingState:

def test_parallel_processing_with_failures((self, temp_dir_structure)):

def mock_processing_func((input_path: Path, output_path: Path)) -> ProcessingState:

def test_empty_directory_handling((self)):

def test_special_characters_in_filenames((self)):

def test_error_handling_invalid_directory((self)):

def test_progress_callback_integration((self, temp_dir_structure)):

def progress_callback((file_path: str, completed: int)):

def mock_processing_func((input_path: Path, output_path: Path)) -> ProcessingState:

def test_worker_count_variation((self, temp_dir_structure)):

def mock_processing_func((input_path: Path, output_path: Path)) -> ProcessingState:

def test_large_file_set_simulation((self)):

def mock_processing_func((input_path: Path, output_path: Path)) -> ProcessingState:


<document index="33">
<source>tests/test_sample.txt</source>
<document_content>
This is a test document for cerebrate-file CLI testing.

It contains multiple paragraphs to test the chunking functionality.

The chunking system should handle this text properly and process it through the configured pipeline.

This paragraph helps test whether the system maintains context across chunks when processing larger documents.

Final paragraph to ensure proper handling of document endings.
</document_content>
</document>

# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_tokenizer.py
# Language: python

from unittest.mock import patch
import pytest
from cerebrate_file.constants import TokenizationError
from cerebrate_file.tokenizer import (
    TokenizerManager,
    decode_tokens_safely,
    encode_text,
    get_tokenizer_manager,
)

def test_tokenizer_manager_initialization(()):

def test_tokenizer_manager_fallback_mode(()):

def test_encode_text_function(()):

def test_decode_tokens_safely_function(()):

def test_decode_tokens_safely_with_empty_list(()):

def test_get_tokenizer_manager(()):

def test_tokenizer_manager_estimate_tokens(()):

def test_tokenizer_manager_with_empty_text(()):

def test_tokenizer_fallback_approximation(()):

def test_tokenizer_manager_decode(()):

def test_tokenizer_edge_cases(()):

def test_tokenizer_properties(()):

def test_encode_text_with_long_text(()):

def test_encode_text_with_special_characters(()):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_ui.py
# Language: python

from io import StringIO
import pytest
from rich.console import Console
from cerebrate_file.ui import FileProgressDisplay, MultiFileProgressDisplay

class TestFileProgressDisplay:
    def test_init_default_console((self)):
    def test_init_custom_console((self)):
    def test_start_file_processing((self)):
    def test_update_progress((self)):
    def test_update_progress_no_active_task((self)):
    def test_finish_file_processing((self)):
    def test_complete_workflow((self)):

class TestMultiFileProgressDisplay:
    def test_init_default_console((self)):
    def test_init_custom_console((self)):
    def test_start_overall_processing((self)):
    def test_start_file((self)):
    def test_update_file_progress((self)):
    def test_update_file_progress_unknown_file((self)):
    def test_finish_file((self)):
    def test_finish_overall_processing((self)):
    def test_complete_multi_file_workflow((self)):

class TestUIIntegration:
    def test_progress_display_renders_without_error((self)):
    def test_ui_with_edge_case_paths((self)):

def test_init_default_console((self)):

def test_init_custom_console((self)):

def test_start_file_processing((self)):

def test_update_progress((self)):

def test_update_progress_no_active_task((self)):

def test_finish_file_processing((self)):

def test_complete_workflow((self)):

def test_init_default_console((self)):

def test_init_custom_console((self)):

def test_start_overall_processing((self)):

def test_start_file((self)):

def test_update_file_progress((self)):

def test_update_file_progress_unknown_file((self)):

def test_finish_file((self)):

def test_finish_overall_processing((self)):

def test_complete_multi_file_workflow((self)):

def test_progress_display_renders_without_error((self)):

def test_ui_with_edge_case_paths((self)):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_validators.py
# Language: python

import tempfile
from pathlib import Path
import pytest
from cerebrate_file.constants import ValidationError
from cerebrate_file.validators import (
    validate_chunk_size,
    validate_file_path_safe,
    validate_file_size,
    validate_model_parameters,
    validate_temperature,
    validate_top_p,
)

def test_validate_chunk_size_valid(()):

def test_validate_chunk_size_too_small(()):

def test_validate_chunk_size_too_large(()):

def test_validate_chunk_size_invalid_type(()):

def test_validate_temperature_valid(()):

def test_validate_temperature_too_low(()):

def test_validate_temperature_too_high(()):

def test_validate_temperature_invalid_type(()):

def test_validate_top_p_valid(()):

def test_validate_top_p_too_low(()):

def test_validate_top_p_too_high(()):

def test_validate_file_size_small_file(()):

def test_validate_file_size_nonexistent_file(()):

def test_validate_file_path_safe_valid(()):

def test_validate_file_path_safe_nonexistent(()):

def test_validate_file_path_safe_directory(()):

def test_validate_model_parameters_valid(()):

def test_validate_model_parameters_invalid_ratio(()):

def test_validate_model_parameters_multiple_invalid(()):


# File: /Volumes/adam/Developer/vcs/github.twardoch/pub/cerebrate-file/tests/test_zero_output_guard.py
# Language: python

from pathlib import Path
from types import SimpleNamespace
from unittest.mock import patch
import pytest
from loguru import logger
from cerebrate_file.cerebrate_file import process_document
from cerebrate_file.cli import run as cli_run
from cerebrate_file.models import Chunk, ChunkDiagnostics, RateLimitStatus

def test_process_document_logs_diagnostics_for_zero_token_chunk((
    monkeypatch: pytest.MonkeyPatch,
)) -> None:

def fake_request((*_args, **_kwargs)):

def _sink((message)):

def test_cli_aborts_before_overwriting_when_total_output_zero((
    tmp_path: Path, monkeypatch: pytest.MonkeyPatch, capsys: pytest.CaptureFixture[str]
)) -> None:


</documents>